#!/bin/bash
#export SSH_AUTH_SOCK=/tmp/ssh-HgUgDH2809/agent.2809
#export SSH_AGENT_PID=2810

# Run as:
#   /home/production/devtest/cvstree/base/drms/replication/subscribe_series/subscribe_series /home/production/devtest/cvstree/proj/replication/etc/repclient.shoom.cfg subscribe_list.cfg /home/production/.ssh-agent_rs

function SSexit {
  exitstat="$1"

  rm -f "$kLocalWorkingDir/clientsublock.txt"
  
  if [ -e "$kLocalWorkingDir/clientsublock.txt" ] 
  then
      logwrite "ERROR: Unable to remove subscribe lock file $kLocalWorkingDir/clientsublock.txt"
  fi

  exit $exitstat
}

function RM {

  cmd="/bin/rm";
  args="$@"

  $cmd $@
  if [ $? -ne 0 ]
  then
    logecho "error running command [$cmd $args]"
    return 1;
  else
    logwrite "successful rm command [$cmd $args]"
    return 0;
  fi
}

## shell wrappers declaration - From Igor (slight mod by Art)
function MV {

  cmd="/bin/mv";
  args="$@"

  $cmd $@
  if [ $? -ne 0 ]
  then
    logecho "error running command [$cmd $args]"
    return 1;
  else
    logwrite "successful mv command [$cmd $args]"
    return 0;
  fi
}

function SCP {

  cmd="scp";
  args="$@"

  $cmd $@
  if [ $? -ne 0 ]
  then
    logecho "error running command [$cmd $args]"
    return 1;
  else
    logwrite "successful scp command [$cmd $args]"
    return 0
  fi
}

function SSH {

  cmd="ssh";
  args="$@"

  $cmd $@
  if [ $? -ne 0 ]
  then
    logecho "error running command [$cmd $args]"
    return 1;
  else
    logwrite "successful ssh command [$cmd $args]"
    return 0;
  fi
}

# If there is a second argument to logwrite, regardless of 
# what that argument is, an empty date line will be written
logwrite () {
        echo `date +"%m-%d-%Y %H:%M:%S - "` "$1" >> "$logfile"
        if [ ! $2 == "" ]
        then
        	echo `date +"%m-%d-%Y %H:%M:%S - "` >> "$logfile"
        fi
}

## logs to log file and stdout!                                                               
function logecho {
  if [ ! -z "$logfile" ]
  then
    echo $1 | tee -a $logfile;
  fi
}

function TableExists () {
    exists=0
    ns=$1
    relname=$2
    seq=$3

    if [ $seq -ne 0 ]
    then
        cmd="\ds"
    else
        cmd="\dt"
    fi

    psql -p "$pg_port" -h "$pg_host" -U "$pg_user" -t -c "$cmd $ns.$relname" "$pg_dbname" > sqlcheck.tmp 2>&1

    result=`egrep 'No matching' sqlcheck.tmp`

    if [ -z "$result" ]
    then
        exists=1
    fi

    return $exists
}

function SetState() {
    state=$1;
    logwrite "Setting state to $state."
    echo "$state" > "$statefile"
}

function GetState() {
    if [ ! -f $statefile ] 
    then
        state=start
    else
        state=`awk '{print $1}' "$statefile"`;
    fi
    logwrite "Getting state $state."
}

# This function will attempt to download a file from the server. If the download is incomplete,
# five attempts will be made to resume and complete the download by downloading partial files.
function ManagedDownload() {
    src=$1
    tgt=$2
    err=0
    srcsz=0
    tgtsz=0
    srcbak="$src"'.ssbak'
    tgtbak="$tgt"'.ssbak'

    if [ -f $tgt ]
    then
        RM -f $tgt
    fi

    # First, compare file sizes (cheap/easy way to see if the file has been completely downloaded,
    # I'm sure some kind of hash would be better).
    srcsz=`SSH "$kRSUser@$kRSServer" 'stat -c%s '"$src"`
    if [ $? -ne 0 ]
    then
        # Some error calling ssh
        logwrite "Error running stat in ManagedDownload()"
        err=1
    fi

    if [ $err -eq 0 ]
    then
        attempt=1
        while [ 1 -eq 1 ]
        do
            if [ $attempt -gt 5 ]
            then
                logwrite "ManagedDownload() exceeded 5 attempts; bailing."
                err=1
                break
            fi

            if [ ! -f $tgt ]
            then
                tgtsz=0
            else
                tgtsz=`stat -c%s "$tgt"`
            fi

            logwrite "source size $srcsz; target size $tgtsz"

            if [ $srcsz -gt $tgtsz ]
            then
                # Incomplete download
                # Rename original file, copy just the part needed, then download the copied part
               
                if [ $attempt -eq 1 ]
                then
                    `SCP "$kRSUser@$kRSServer:$src $tgt"`
                else
                    `SSH "$kRSUser@$kRSServer" 'dd if='"$src"' of='"$srcbak"' ibs='"$tgtsz"' skip=1'`
                    if [ $? -eq 0 ]
                    then
                        # Copy $srcbak locally
                        `SCP "$kRSUser@$kRSServer:$srcbak $tgtbak"`
                    fi

                    if [ $? -eq 0 ]
                    then
                        # Append $tgtbak to $tgt
                        logwrite "Appending $tgtbak to $tgt."
                        cat $tgtbak >> $tgt 
                    fi
                fi

                attempt=$(( $attempt + 1 ))
            elif [ $tgtsz -gt $srcsz ]; then
                # Some fatal error
                logwrite "Target file size is larger than source size - something screwy is going on"
                err=1
                break
            else
                # The two files are the same size, so quit
                break
            fi

            sleep 1
        done
    fi

    # Clean up remote and local backup files
    # The remote file may not exist, but the -f flag will suppress the error
    `SSH "$kRSUser@$kRSServer" 'rm -f '"$srcbak"`
    if [ -f $tgtbak ]
    then
        logwrite "Cleaning up local backup (partial) file '$tgtbak'"
        RM -f $tgtbak
    fi

    return $err
}

function CheckSchema () {
    # Add check for slony cluster schema (eg, _jsoc), and don't proceed if it exists
    # If entry in admin.ns exists, do not apply createns.sql. However, 
    # we cannot assume that the drms_* tables and sequence exist. If any of these
    # tables is missing, bail.
    #   name - schema of series being subscribed to
    #   owner - PG user that owns this series (should be slony)

    nsname=$1

    adminnsexist=0
    schemaexist=0

    # Check for schema existence
    logwrite "Executing [psql -p $pg_port -h $pg_host -U $pg_user -t -c SELECT * FROM pg_catalog.pg_namespace WHERE nspname = '$nsname' $pg_dbname]"
    psql -p "$pg_port" -h "$pg_host" -U "$pg_user" -t -c "SELECT * FROM pg_catalog.pg_namespace WHERE nspname = '$nsname'" "$pg_dbname" > sqlcheck.tmp 2>&1
    result=`egrep '.' sqlcheck.tmp`
    if [ ! -z "$result" ]
    then
        schemaexist=1
    fi

    # Check for admin.ns entry existence
    logwrite "Executing [psql -p $pg_port -h $pg_host -U $pg_user -t -c SELECT * FROM admin.ns WHERE name = '$nsname' AND owner = '$pg_user' $pg_dbname]"
    psql -p "$pg_port" -h "$pg_host" -U "$pg_user" -t -c "SELECT * FROM admin.ns WHERE name = '$nsname' AND owner = '$pg_user'" "$pg_dbname" > sqlcheck.tmp 2>&1
    result=`egrep '.' sqlcheck.tmp`
    if [ ! -z "$result" ]
    then
        adminnsexist=1
    fi

    logwrite "Table schema check: $schemaexist; schema adminns entry check: $adminnsexist."

    # If one or the other exists, then we can't apply createns.sql AND the schema, admin.ns entry, drms_* tables must exist
    check=good
    docreatens=1
    if [ $schemaexist -ne 0 -o $adminnsexist -ne 0 ]
    then
        docreatens=0
        if [ $schemaexist -eq 0 -o $adminnsexist -eq 0 ]
        then
            check=failed
            logecho "Missing schema or entry in the admin.ns table; failing."
        else
                # Search for tables
            TableExists $nsname "drms_series" 0
            result=$?

            if [ ! $result ]
            then
                check=failed
            fi

            if [ ! $check == "failed" ]
            then
                TableExists $nsname "drms_keyword" 0
                result=$?
            fi
            
            if [ ! $result ]
            then
                check=failed
            fi

            if [ ! $check == "failed" ]
            then
                TableExists $nsname "drms_link" 0
                result=$?
            fi
            
            if [ ! $result ]
            then
                check=failed
            fi

            if [ ! $check == "failed" ]
            then
                TableExists $nsname "drms_segment" 0
                result=$?
            fi
            
            if [ ! $result ]
            then
                check=failed
            fi

            if [ ! $check == "failed" ]
            then
                TableExists $nsname "drms_session" 0
                result=$?
            fi
            
            if [ ! $result ]
            then
                check=failed
            fi

            if [ ! $check == "failed" ]
            then
                TableExists $nsname "drms_sessionid_seq" 1
                result=$?
            fi
            
            if [ ! $result ]
            then
                check=failed
            fi

            if [ $check == "failed" ]
            then
                logecho "Incomplete set of schema drms_* tables; failing."
            fi
        fi
    fi

    RM -f sqlcheck.tmp

    if [ $check == "failed" ]
    then
        return 0
    elif [ $docreatens -eq 0 ]; then
        return 1
    else
        return 2
    fi
}

# returns -1 if user doesn't want to delete the series
# 0 if series deleted
# 1 if series couldn't be deleted, but an attempt was made to delete it
function DeleteSeries () {
    series=$1;
    goahead=0

    # Prompt user before deleting
    while [ 1 -eq 1 ]
    do
        echo -n "Would you like to delete series $series? (Y/N)"
        read answer
        
        if [ $answer == "Y" -o $answer == "y" ]
        then
            goahead=1
            break
        elif [ $answer == "N" -o $answer == "n" ]
        then
            break
        fi
    done
    
    if [ $goahead -eq 1 ]
    then
        logwrite "Running $delseriesprog $series JSOC_DBUSER=slony."
        echo "yes"$'\n'"yes"$'\n' | "$delseriesprog" "$series" JSOC_DBUSER=slony
        if [ $? -ne 0 ]
        then
            logwrite "Failure to delete series $series."
            return 1
        else
            return 0
        fi
    fi

    return -1
}

#--------------------------------------------------------------------
# syntax check
#--------------------------------------------------------------------
if [ $# -ge 3 ]
then
	config_file="$1"
	subscribe_file="$2"
	rsFile="$3"
else
	error="ERROR: Usage: $0 <configuration file> <subscribe request file> <ssh-agent_rs file> [-r]"
	echo $error
	exit 1
fi

# -r means to resume from where you left off (if there was an error on the previous run, you
# can attempt to correct the cause of the problem, then re-run from where you left off).
if [ "$4" == "-r" ]
then
    wipestate=0
else
    wipestate=1
fi

. "$config_file"

#--------------------------------------------------------------------
# Setting up the log
#--------------------------------------------------------------------

## checks if a preferred LOCAL_LOG_DIR has been specified in the $config_file

# use basename of script
scrbase=`perl -e 'if ($ARGV[0] =~ /.*\/([^\/]+)/) { print $1; } else { print $ARGV[0]; }' $0`

if [ -z "$kLocalLogDir" ]
then
  logfile=../log/$scrbase.log
else
  logfile="$kLocalLogDir/$scrbase.log"
fi

if [ -z "$kMaxLog" ]
then
  maxlog=1048576
else
  maxlog="$kMaxLog"
fi

if [ ! -f "$logfile" ]
then
  touch "$logfile"
  if [ $? -ne 0 ]
  then
    logecho "Couldn't touch log file [$logfile] ... exiting."
    exit 1;
  fi
else
  # log exists, truncate if getting too big
  sz=`stat -c%s $logfile`
  if [ $sz -ge $maxlog ]
  then
    : > "$logfile"
    if [ $? -ne 0 ]
      then
        logecho "Couldn't truncate log file [$logfile] ... exiting."
      exit 1;
    fi
  fi
fi

#--------------------------------------------------------------------
# disallow simultaneous runs of this script
#--------------------------------------------------------------------
restartmsg="You can try running the exact same subscribe_series command with the -r flag (retry) appended to continue processing from where you left off. Please ensure that the subscription-request file remains unchanged."

if ( set -o noclobber; echo "$$" > "$kLocalWorkingDir/clientsublock.txt") 2> /dev/null;
then
    trap 'rm -f "$kLocalWorkingDir/clientsublock.txt"; echo "$restartmsg"; exit 1' INT TERM HUP
else
    logwrite "Could not acquire the subscription lock; exiting"
    exit 1
fi

logwrite "Starting $0 from $scriptdir" nl

# Make this relative to working dir
statefile=$kLocalWorkingDir/ssstate.txt

#--------------------------------------------------------------------
# Set up ssh keys
#--------------------------------------------------------------------
# Look for "export" in the env file
export_check=`cat $rsFile | grep "export" | wc -l`
if [[ $export_check -gt "0" ]]
then
    ssh_bash=1
fi

# Look for "setenv" in the env file
setenv_check=`cat $rsFile | grep "setenv" | wc -l`
if [[ $setenv_check -gt "0" ]]
then
    ssh_csh=1
fi

# Set the environment variables based on the type of file
if [[ $ssh_bash -eq "1" && $ssh_csh -ne "1" ]]
then
    # It's a bash file
    . $rsFile
elif [[ $ssh_csh -eq "1" && $ssh_bash -ne "1" ]]
then
    # It's a cshell file
    grep "setenv" $rsFile > $kLocalWorkingDir/temp_rsFile
    sed 's/ /=/g' $kLocalWorkingDir/temp_rsFile > $kLocalWorkingDir/temp_rsFile2
    sed 's/setenv=/export /g' $kLocalWorkingDir/temp_rsFile2 > $kLocalWorkingDir/temp_rsFile3
    . $kLocalWorkingDir/temp_rsFile3
    rm -f $kLocalWorkingDir/temp_rsFile $kLocalWorkingDir/temp_rsFile2 $kLocalWorkingDir/temp_rsFile3
else
    error="Couldn't determine if the file was either bash or cshell"
    echo "$error"
    logwrite "ERROR: $error"
    SSexit 1
fi

if [ -z $SSH_AGENT_PID ]
then
    echo "Couldn't find ssh-agent.\n"
    SSexit 1
fi

if [ -z "$kSQLIngestionProgram" ]
then
  ingestprog=get_slony_logs.pl
else
  ingestprog="$kSQLIngestionProgram"
fi

if [ -z "$kDeleteSeriesProgram" ]
then
  delseriesprog=delete_series
else
  delseriesprog="$kDeleteSeriesProgram"
fi

# Check for a log reprocessing request
reproreq=`cat $subscribe_file | egrep '^[^#[:space:]]' | grep -wi repro`

if [ ! -z $reproreq ] 
then
    # Do a log-reprocessing request - call a perl script (easier for me)
    SetState "repro"
    "$kRepDir/subscribe_series/req.pl" "$subscribe_file" "$logfile" "$kLocalWorkingDir"
    # clean up log file (in case it got really big for some reason when reqrepro.pl was called
    if [ $? -ne 0 ] 
    then
        logecho "Couldn't process log-re-parsing request."
        SSexit 1;
    else
        logwrite "Re-parsing request issued."
        SetState "end"
    fi
else
# extract seriesname from the $subscribe_file file
# XXX - ART
# Create an array of series - the createns check must be on a per-series basis.
# We only care about series being subscribed to (and not being dropped from subscription)
    subserieslst=`cat $subscribe_file | egrep '^[^#[:space:]]' | grep -wi subscribe | awk '{print $1}'`
    unsubserieslst=`cat $subscribe_file | egrep '^[^#[:space:]]' | grep -i unsubscribe | awk '{print $1}'`

    logwrite "Series being subscribed to:"

    ctr=0
    while [ 1 -eq 1 ]
    do
        index=$(( $ctr + 1 ))
        awkscr='{print $'"$index"'}'
        str=`echo $subserieslst | awk "$awkscr"`
        if [ -z "$str" ]
        then
            break
        fi
        subseries[$ctr]=$str
        logwrite "$str ($ctr)"
        ctr=$(( $ctr + 1 ))
    done

    logwrite "Series being dropped from subscription:"
    ctr=0
    while [ 1 -eq 1 ]
    do
        index=$(( $ctr + 1 ))
        awkscr='{print $'"$index"'}'
        str=`echo $unsubserieslst | awk "$awkscr"`
        if [ -z "$str" ]
        then
            break
        fi
        unsubseries[$ctr]=$str
        logwrite "$str ($ctr)"
        ctr=$(( $ctr + 1 ))
    done

# extract action from subscribe_list.cfg (if at least one action is unsubscribe, then we need to 
# force get_slony_logs.pl after the die file has been removed)

    if [ ${#unsubseries[@]} -gt 0 ]
    then
        unsubscribe=1
    else
        unsubscribe=0
    fi
fi

#--------------------------------------------------------------------
# Get state of previous subscribe_series run
#--------------------------------------------------------------------
GetState
if [ $state == "end" -o $wipestate -eq 1 ]
then
    # Prevous run completely successfully, set to start
    SetState "start"

    # If the .sqldone file exists from a previous, aborted run, we need to
    # delete it. Otherwise, this script will send the initial trigger file
    # to the server, and see the old, aborted .sqldone file and attempt
    # to download the .sql file, which won't be there.
    # So, remove the .sqldone file. The ssh call will fail if it doesn't exist
    # but that is okay - as long as the .sqldone file is removed if it exists.
    logwrite "Removing sqldone trigger file from webdb"
    SSH "$kRSUser@$kRSServer" 'rm -f '"'$kRSTriggerDir/$node.subscribe_series.sqldone'"
fi

#--------------------------------------------------------------------
# Check to see if the series being subscribed to exists already.
# If so, the user cannot continue, unless they move the existing
# tables out of the way. Give the user the option of deleting
# the series and continuing.
#--------------------------------------------------------------------

if [ $state == "start" ]
then
    iseries=0

    # Check each series being subscribed to

    while [ $iseries -lt ${#subseries[@]} ]
    do
        seriesns=`perl -e 'if ($ARGV[0] =~ /(.+)\./) { print $1; }' ${subseries[$iseries]}`
        seriestab=`perl -e 'if ($ARGV[0] =~ /\.(.+)/) { print $1; }' ${subseries[$iseries]}`

        logwrite "Checking for existence of series ${subseries[$iseries]}."
        logwrite "Executing [psql -p $pg_port -U $pg_user $pg_dbname -c '\dt ${subseries[$iseries]}' | egrep $seriesns[[:space:]]+\|[[:space:]]+$seriestab]"
        check=`psql -p "$pg_port" -U "$pg_user" "$pg_dbname" -c "\dt ${subseries[$iseries]}" | egrep "${seriesns}[[:space:]]+\|[[:space:]]+${seriestab}"`
        
        if [ ! -z "$check" ]
        then
            logwrite "series exists"
            # Series already exists. Ask user if they want to delete it.
            echo "Attempting to subscribe to series that already exists (${subseries[$iseries]})."
            echo "To continue, you must unsubscribe to ${subseries[$iseries]} first,"
            echo "and delete ${subseries[$iseries]} or move it (the unsubscribe"
            echo "process will provide the opportunity to delete it)."
            SSexit 1
        else
            logwrite "series does NOT exist"
        fi
        
        iseries=$(($iseries + 1))
    done
fi

#--------------------------------------------------------------------
# Prepare trigger file
#--------------------------------------------------------------------
tmptgr="$kLocalWorkingDir/temp.tgr"

if [ $state == "start" ]
then
    echo > "$tmptgr"
    logwrite "Created $tmptgr"
    echo "archive $archive" >> "$tmptgr"
    echo "retention $retention" >> "$tmptgr"
    echo "tapegroup $tapegroup" >> "$tmptgr"
    echo "node $node" >> "$tmptgr"

    cat "$subscribe_file" | grep -v "\#" >> "$tmptgr"
    SetState "crtrigger_comp"
fi

#--------------------------------------------------------------------
# Check to see if the schema and database exists on the subscribers database
#--------------------------------------------------------------------

if [ $state == "crtrigger_comp" ]
then
    logwrite "Executing [psql -p $pg_port -U $pg_user $pg_dbname -c '\dt admin.*' | grep \" ns \"]"
    check=`psql -p "$pg_port" -U "$pg_user" "$pg_dbname" -c '\dt admin.*' | grep " ns "`
    
    if [ ! "$check" == "" ]
    then
	logwrite "admin schema and table ns exist" 
    else
	logwrite "ERROR: admin schema and table ns do NOT exist" 
	logwrite "ABORTING"
	logwrite "Removing $tmptgr"
	RM -f "$tmptgr"
	logwrite "Exiting $0"
	SSexit 1
    fi
fi


#--------------------------------------------------------------------
# Stopping ingestion script and copy trigger file to Manager
#--------------------------------------------------------------------

if [ $state == "crtrigger_comp" ]
then
    logwrite "Stopping the ingestion script (creating die file)"
    logwrite "Creating get_slony_logs.$node.die in $ingestion_path" nl
    echo > "$ingestion_path/get_slony_logs.$node.die"
    triggerfile="$kLocalWorkingDir/$node.subscribe_series.tgr"
    logwrite "Renaming $tmptgr to $triggerfile" nl
    MV -f "$tmptgr" "$triggerfile"


    logwrite "Copying $triggerfile to $kRSUser@$kRSServer:$kRSTriggerDir" nl

# XXX - ART
# What we want to do is to use file locking so that the server
# doesn't try to read the trigger file until the client is done with
# it. The client (this script) should lock the file, then 
# scp it, then chgrp/chmod it (this script should do the
# chgrp/chmod).
#
# Even easier - just add a "__EOF__" line to the end of the trigger
# file - the server ignores the file, unless it sees this __EOF__
# string
    chmod g+w "$triggerfile"
    SCP -p "$triggerfile" "$kRSUser@$kRSServer:$kRSTriggerDir/."

    logwrite "Removing $triggerfile" nl

    RM -f "$triggerfile"
    SetState "crdie_comp"
fi

#--------------------------------------------------------------------
# Loop waiting for sqldone file to continue (meaning sql is ready to be applied)
#--------------------------------------------------------------------

if [ $state == "crdie_comp" ]
then
    logecho -n "Waiting to retrieve the sql file from the subscription manager"
    counter=0
    while [ 1 -eq 1 ]
    do	
	if [ $counter -ge $attempts ] 
	then
	    logecho "ERROR: Did not find $node.subscribe_series.sqldone after $attempts tries"
	    logecho "ERROR: Couldn't find the sql file required to continue!"
	    logecho "ABORTING - exiting $0"
            logecho "*** It is possible that this timeout was not sufficiently long to accommodate"
            logecho "*** a long-running table dump on the server, or a long-running file transfer"
            logecho "*** to the client. You can try running the exact same subscribe_series command"
            logecho "*** with the -r flag (retry) appended to continue processing from where you left off."
            logecho "*** Please ensure that the subscription-request file remains unchanged."
	    SSexit 1
	fi

        result=`SSH "$kRSUser@$kRSServer" 'ls '"'$kRSTriggerDir'"`;

        ## error on SSH; couldn't find $kRSTriggerDir                                                 
        error=`echo $result | grep -i error`;
        if [ ! -z "$error" ]
        then
            logecho "Couldn't find $kRSTriggerDir directory ... exiting";
            SSexit 1;
        fi

        check=`echo $result | grep "$node.subscribe_series.sqldone"`;
	
	if [ ! -z "$check" ]
	then
	    logwrite "Found $node.subscribe_series.sqldone, continuing"
	    logecho
	    logecho "Subscription manager finished creating the sql file, retrieving it."
	    break
	else
	    counter=$(( $counter + 1 ))
	    logwrite "Did not find $node.subscribe_series.sqldone, sleeping for five seconds"
	    logecho -n "."
	    sleep 5
	fi

    done


    unset check
    unset error
    unset result

# Checking trigger file for failure code
    result=`SSH $kRSUser@$kRSServer 'cat '"'$kRSTriggerDir/$node.subscribe_series.sqldone'"`;

## Check for error in remote ssh command; trigger file not found or failed SSH
    error=`echo $result | grep -i error`;
    if [ ! -z $error ] ;
    then
        logecho "Fail cat $kRSTriggerDir/$node.subscribe_series.sqldone"
        SSexit 1;
    fi

    check=`echo $result | grep failure`;

    if [ ! "$check" == "" ]
    then
	logecho "ERROR: One or more of the schemas did not exist on the webdb"
	logecho "ERROR: ABORTING!" nl
	logwrite "Removing sqldone trigger file from webdb"
        SSH "$kRSUser@$kRSServer" 'rm -f '"'$kRSTriggerDir/$node.subscribe_series.sqldone'"
	logwrite "Restarting the ingestion script"
	logwrite "Removing ingestion.die in $ingestion_path" nl
	RM -f "$ingestion_path/get_slony_logs.$node.die"
	SSexit 1;
    fi

    SetState "crsql_comp"
fi

unset check
unset error
unset result

# sqldone file found, transferring sql file to local machine
logwrite "Copying and removing $node.sql.tar.gz file from $kRSUser@$kRSServer"

success=true

ManagedDownload "$kRSTriggerDir/$node.sql.tar.gz" "./$node.sql.tar.gz"
if [ $? -eq 0 ]
then
    SetState "dlsql_comp"

    logwrite "Executing: tar -xzvf $node.sql.tar.gz"
    tar -xzvf "$node.sql.tar.gz"

    logwrite "Removing $node.sql.tar.gz" nl
    RM -f "$node.sql.tar.gz"
else
    # Major problem, must tell server to clean up
    success=false
fi

# We did all we could to download the sql file, so remove it.
# If the user killed this script while downloading was happening
# then the following line will not be executed, and 
# downloading can resume from where it left off.
SSH "$kRSUser@$kRSServer" 'rm -f '"'$kRSTriggerDir/$node.sql.tar.gz'"
if [ $? -ne 0 ]
then
    # Fatal error - if the .sql file doesn't get cleaned up
    # then this might confuse subsequent runs of this script
    SSexit 1
fi

#--------------------------------------------------------------------
# Execute the SQL files, return a value 
#--------------------------------------------------------------------

if [ $state == "dlsql_comp" ]
then
    if [ $success == "true" ]
    then
        # Get all the namespace names
        ctr=0
        while [ $ctr -lt ${#subseries[@]} ]
        do
            onename=`echo ${subseries[$ctr]%%.*}`
            allnames="$allnames"$'\n'"$onename"
            ctr=$(( $ctr + 1 ))
        done

        # Find unique ones
        nsnameslst=`echo "$allnames" | awk '!x[$0]++'`

        # Make an array of the unique ns names
        logwrite "Namespaces of series being subscribed to:"
        ctr=0
        while [ 1 -eq 1 ]
        do
            index=$(( $ctr + 1 ))
            awkscr='{print $'"$index"'}'
            str=`echo $nsnameslst | awk "$awkscr"`
            if [ -z "$str" ]
            then
                break
            fi
            nsnames[$ctr]=$str
            logwrite "$str"
            ctr=$(( $ctr + 1 ))
        done

        logwrite "  (${#nsnames[@]} namespaces total)"
        
        ctr=0
        while [ $ctr -lt ${#nsnames[@]} ]
        do
            logwrite "series namespace is ${nsnames[$ctr]}"
            CheckSchema ${nsnames[$ctr]}
            result=$?

            logwrite "CheckSchema return value is $result."

            if [ $result -eq 0 ]
            then
                # Check failed
                logwrite "CheckSchema detected corrupted schema ${nsnames[$ctr]}"
                check=failed
            elif [ $result -eq 1 ]; then
                # Check succeeded, don't apply createns
                docreatens=0
                check=good
            else
                # Check succeeded, apply createns
                docreatens=1
                check=good
            fi

            if [ ! $check == "failed" ]
            then
                if [ $docreatens -ne 0 ]
                then
                    logecho "Applying SQL file $node.${nsnames[$ctr]}.createns.sql to database"
                    logwrite "Executing [psql -p $pg_port -h $pg_host -U $pg_user -ef $node.${nsnames[$ctr]}.createns.sql $pg_dbname]"
                    psql -p "$pg_port" -h "$pg_host" -U "$pg_user" -ef "$node.${nsnames[$ctr]}.createns.sql" "$pg_dbname" > sqlcheck.tmp 2>&1
                    result=`cat sqlcheck.tmp`
                    logwrite $result

                    # XXX - ART
                    # no check of results of application of createns.sql (must check the output!!!)
                    logwrite "Removing the $node.${nsnames[$ctr]}.createns.sql file"
                else
                    logwrite "Check for existing schema $nsname succeeded - no need to apply $node.${nsnames[$ctr]}.createns.sql"
                fi
                RM -f "$node.${nsnames[$ctr]}.createns.sql"
            else
                success=false
                break;
            fi

            ctr=$(( $ctr + 1 ))
        done

        unset check

        if [ $success == "true" ]
        then
            logecho "Applying SQL file $node.subscribe_series.sql to database"
            logwrite "Executing [psql -p $pg_port -h $pg_host -U $pg_user -ef $node.subscribe_series.sql $pg_dbname]"
            psql -p "$pg_port" -h "$pg_host" -U "$pg_user" -ef "$node.subscribe_series.sql" "$pg_dbname" > sqlcheck.tmp 2>&1
            result=`cat sqlcheck.tmp`
            logwrite $result

            check=`cat sqlcheck.tmp | grep "ERROR:"`
            logwrite "Checking for errors with $node.subscribe_series.sql"
            logwrite "Found errors: [$check]" nl

            if [  ! "$check" == "" ] 
            then
	        logwrite "Failed to apply $node.subscribe_series.sql"
	        logwrite "Rolling back to previous state"
	        success=false
            else
	        logwrite "Application of $node.subscribe_series.sql succeded, continuing"
                logwrite "Removing the $node.subscribe_series.sql file"
                RM -f "$node.subscribe_series.sql"
	        success=true
            fi
        fi

        RM -f sqlcheck.tmp

        if [ $success == "true" ]
        then
            SetState "applsql_comp"
        fi
    fi
fi

# The following code should always run, regardless of errors above.
# It triggers the clean-up of the server files.
if [ $success == "true" ]
then
	# SQL applictaion was a success, appending [success true] to the cfg file on webdb
	logwrite "SQL application successful, appending [success=true] to the cfg file on webdb"
	SSH "$kRSUser@$kRSServer" 'echo '"success true"' >> '"'$kRSTriggerDir/$node.subscribe_series.cfg'"
else
	# SQL application was unsuccessful, appending [success false] to the cfg file on webdb
	logwrite "SQL application unsuccessful, appending [success=false] to the cfg file on webdb"
        logecho "Failure to apply SQL file '$node.subscribe_series.sql' from server: ABORTING!"
	SSH "$kRSUser@$kRSServer" 'echo '"success false"' >> '"'$kRSTriggerDir/$node.subscribe_series.cfg'"
fi

SSH "$kRSUser@$kRSServer" 'cp -f '"'$kRSTriggerDir/$node.subscribe_series.cfg'"' '"'$kRSTriggerDir/$node.subscribe_series.sqlapplied'"

unset result
unset check

#--------------------------------------------------------------------
# Loop waiting for done file to continue (which signifies that manager is done and has cleaned up)
#--------------------------------------------------------------------

if [ $state == "applsql_comp" ]
then
    logecho -n "Waiting for the subscription manager to finish updating the subscription parser, complete, and clean-up"
    counter=0
    while [ 1 -eq 1 ]
    do	
	if [ "$counter" -ge "$attempts" ] 
	then
	    logwrite "ERROR: Did not find $node.subscribe_series.done after $attempts tries"
	    logwrite "ERROR: Exiting $0 " nl
	    logecho "ERROR: The subscription manager has not reported it has finished updating the subscription parser after $attempts tries!"
	    logecho "ABORTING!"
	    SSexit 1;
	fi		

        result=`SSH "$kRSUser@$kRSServer" 'ls '"'$kRSTriggerDir'"`;

        logwrite "result is $result"

        ## Check for error in remote ssh command; Couldn't find $kRSTriggerDir directory
        error=`echo $result | grep -i error`;
        if [ ! -z $error ] ;
        then
            logecho "Couldn't find $kRSTriggerDir directory or broken SSH ... exiting"
            SSexit 1;
        fi

	check=`echo $result | grep "$node.subscribe_series.done"`
	
	if [ ! "$check" == "" ]
	then
	    logwrite "Found $node.subscribe_series.done, continuing"
	    logecho
	    logecho "Subscription manager has finished updating the parser and cleaned-up."
	    break
	else
	    counter=$(( $counter + 1 ))
	    logwrite "Did not find $node.subscribe_series.done, sleeping for five seconds"
	    logecho -n "."
	    sleep 5
	fi

    done

    SetState "crdone_comp"
fi

unset check
unset error
unset result

#--------------------------------------------------------------------
# Starting the ingestion script (by removing the die file)
#--------------------------------------------------------------------

if [ $state == "crdone_comp" ]
then
    logwrite "Starting the ingestion script"
    logwrite "Removing ingestion.die in $ingestion_path" nl
    RM -f "$ingestion_path/get_slony_logs.$node.die"
    if [ $? -ne 0 ]
    then
        logwrite "Unable to remove die file '$ingestion_path/get_slony_logs.$node.die'"
        success=false
    else
        logwrite "Cleaning up the done file '$kRSTriggerDir/$node.subscribe_series.done' (which the server cleanup file wrote)" nl
        SSH "$kRSUser@$kRSServer" 'rm -f '"'$kRSTriggerDir/$node.subscribe_series.done'"
        
        if [ $? -eq 0 ]
        then
            SetState "rmdie_comp"
        else
            success=false
        fi
    fi
fi

#--------------------------------------------------------------------
# Force ingestion script (if unsubscribing to a series)
#   If any series is being removed from subscription, then
#   get_slony_logs.pl must be run to force application
#   of all logs that contain the series being removed. After
#   this happens, then it is safe to remove the series
#   (with the delete_series program run as user slony).
#--------------------------------------------------------------------
if [ $state == "rmdie_comp" ]
then
    if [ $unsubscribe -eq 1 ]
    then
        logwrite "At least one series was removed from subscription; run ingest program, then delete series removed from subscription."
        logwrite "Running $ingestprog $config_file."
        "$ingestprog" "$config_file"
        if [ $? -ne 0 ]
        then
            logwrite "SQL-log-ingestion failure - unable to delete series $series."
            success=false
        else
            SetState "forceing_comp"

            # Delete all series in the unsubscribe list
            ctr=0
            while [ $ctr -lt ${#unsubseries[@]} ]
            do
                # Make sure to ask if the user want to delete the series, if not
                # then they need to manually delete before re-subscribing
                echo "Before re-subscribing to this series, you will need to either delete it, or move it out of the way."
                DeleteSeries ${unsubseries[$ctr]}

                if [ $? -eq 1 ]
                then
                    success=false
                    # but continue with other series
                fi

                ctr=$(( $ctr + 1 ))
            done

            if [ $success == "true" ]
            then
                SetState "delseries_comp"
            fi
        fi
    fi 
fi

#--------------------------------------------------------------------
# Finish
#--------------------------------------------------------------------
logwrite "$0 complete"
logecho

if [ $success  == "true" ]
then
    SetState "end"
    logecho "Subscription process completed successfully!"
else
    logecho "Subscription process did not complete successfully!"
fi


#--------------------------------------------------------------------
# Release lock
#--------------------------------------------------------------------
rm -f "$kLocalWorkingDir/clientsublock.txt"

if [ -e "$kLocalWorkingDir/clientsublock.txt" ] 
then
    logwrite "ERROR: Unable to remove subscribe lock file $kLocalWorkingDir/clientsublock.txt"
fi

trap - INT TERM HUP
