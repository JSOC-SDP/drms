#!/usr/bin/env python3

import sys

if sys.version_info < (3, 2):
    raise Exception('You must run the 3.2 release, or a more recent release, of Python.')

import re
import os
import stat
import filecmp
import logging
import psycopg2
import threading
import fcntl
from datetime import datetime, timedelta, timezone
from dateutil import parser as dateparser # in anaconda
from distutils import util as distroutil # in anaconda
import urllib.request
import json
import signal
import time
from copy import deepcopy
import shutil
import random
import argparse
import inspect
from queue import Queue, Empty, Full
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../../../include'))
from drmsparams import DRMSParams
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../../../base/libs/py'))
from drmsCmdl import CmdlParser
from drmsLock import DrmsLock
from subprocess import check_output, check_call, CalledProcessError, Popen, PIPE, TimeoutExpired

# This script runs as a daemon at the site that has requested an SU that does not belong to the site. It is responsible for contacting
# the owning site and requesting the path to the desired SUs. The owning site must be running the rs.sh CGI to respond to the requesting
# site's request.

# There are three database tables: 1., a DRMS site table, 2., a request table, and 3., an SU table (sunum, starttime, status, errmsg)
# The site table (sitename, sitecode, baseurl) provides
# the information needed to query the providing site for the information needed to scp the requested SUs to the requesting site. The URL to the cgi
# program that provides scp information is formed by appending "rs.py" to baseurl. There are two parameters for this cgi: 1., "requestid", and 2., "sunums".
# During the initial request to the providing site, the requesting site will provide a requestid of "none", and a comma-separated list of SUNUMs
# in the sunums argument. Should the providing site have all the requested SUs online, then it will return the scp information needed to access those
# SUs, and a status of "complete". If, however, the SUs are not all online, the initial request will start an asynchronous tape-read of the offline SUs,
# returning a request ID that identifies the initial request, and a status of "pending". The requesting site must then poll for completion by
# periodically calling the cgi with a status request. To make a status request, the requestid argument contains the requestid returned by the
# inital CGI call, and the sunums argument contains "none". While the data are not ready, the status request returns a status of "pending". When
# the data are online, the status request returns a status of "complete".
#
# The request table (requestid, sunums, status) is populated by drms_storageunit.c. For all SUs that are offline and are not owned by the running
# DRMS/SUMS, the code inserts a record into the request table. The requestid is a UUID (within the running DRMS/SUMS) generated by a sequence table.
# The list of SUNUMs is put in sunums, and the initial status is set to 'N' (New request). drms_storageunit.c chunks such SUNUMs into
# manageable-sized requests. After inserting one or more such records into the request table, drms_storageunit.c then polls these records,
# waiting for the status to become 'C' (Complete request). After that happens, drms_storageunit.c then calls SUM_get() again on these SUs
# to obtain their paths. This daemon, rsumsd.py, periodically and reads all records in the request table. For each SU in each 'N' record
# (a single request, which could be requesting multiple SUs) the daemon first checks if the SU is already being processed. If so, then
# the SU table is not modified. The status of the record in the request table is set to 'P'. If the SU is not in the SU table, then
# this can mean one of two things. The daemon has never processed this SU, or the daemon has already processed this SU. When the daemon has completed
# processing an SU, it deletes the record for the SU from the SU table. If the latter is true, the daemon should not re-process the same SU. To distinguish
# between these two possibilities, the daemon first checks to see if the SU is already present in SUMS (it calls show_info -o sunum=SUNUM).
# If the SU is online, then the daemon does nothing. But if it is offline, then the daemon inserts a record for the SU into the SU table, and starts
# processing that SU. The status of that SU-table record is set to 'P', as is the status of the request record containing that SUNUM.
#
# For each SU in each 'P' request record, the daemon searches for records in the SU table. If one or more such records exist in the SU table, then
# the request record is left in the pending state. The next time the daemon scans the request records, it will again check the SU table looking
# for completion of all SUs. When that occurs, the status of the request record is set to 'C', indicating that the request is complete. The
# drms_storageunit.c code will then call SUMS to get the newly created paths to the requested SUs.

# Locks and thread synchronization
# The main thread looks for new and pending requests in the requests table. Since there is only a single thread accessing the requests
# table, there is no need to lock the requests table or its individual requests.
#
# The Storage Unit status, on the other hand, is accessed by both the Downloader threads and the ScpWorker threads. The latter queries the
# former for 'working' SUs - these are SUs that a Downloader thread has requested that an ScpWorker thread download. Each SU is assigned to a 
# single ScpWorker. Care must be taken so that two or more ScpWorkers do not operate on the same SU. The change of an SU's status from
# W to D by the ScpWorker thread must not be interrupted by another ScpWorker's call to getNextNWorking(). If an ScpWorker calls
# getNextNWorking() (which returns SUs with a status of W), but does not change the SUs statuses to D before a second ScpWorker
# calls getNextNWorking(), then both ScpWorkers could get assigned the same SU. The solution is for each ScpWorker to lock each SU
# before it checks its status for W, then change the status to D, then release the SU lock. To facilitate this locking, each ScpWorker
# thread first locks the SU Table, then it iterates through all SUs, locking each one, then checking its status. Once it collects
# all SUs with a status of W, it releases the SU Table lock, but it continues to hold on to the SU locks so it can change the statuses
# from W to D without interruption by the Downloader thread (see next paragraph).

# Both the Downloader and ScpWorker can change the status of an SU. Each thread must ensure that it does not overwrite a status change made
# by the other thread. If an ScpWorker sees an SU with a status of W, it will set the status to D before starting an scp. In the meantime, 
# the Downloader could set the status to S to signify a that the worker should be stopped. Without locks, the change to S by the 
# Downloader could be overwritten by the change to D by the ScpWorker. The solution is for both threads to acquire the SU lock, then 
# read the status before changing the status. So the ScpWorker thread will acquire the lock, see the W, set the status to D and then 
# start the scp and release the SU lock. The Downloader will acquire the SU lock before changing the status to S. In this manner, 
# the Downloader's change to S cannot be overwritten by the ScpWorker's change of status from W to D.

# SU status life cycle: 
#   dispatcher thread sets to 'P' (in Dispather::run()) - pending
#   Downloader sets to 'W' - waiting (to be assigned to an ScpWorker)
#   ScpWorker sets to 'D' - ScpWorker is downloading the SU
#   Scpworker sets to 'F' - ScpWorker has finished downloading, back to Downloader
#   Downloader sets to 'C' - complete
#   If an error or time-out happens anywhere in this life cycle, then the status is set to 'E'

# You can measure the total rate of download for a rsumsd.py session like this:
# 1. start up rsumsd.py anew with the --loglevel=debug flag, first moving or deleting the existing log
# 2. make many Remote SUMS requests; the rsums-clientd.py program is one way to do this
# 3. stop rsumsd.py with the kill -2 command and wait for rsumsd.py to finish processing the existing requests
# 4. run this command, first replacing rslog_20180530.txt with the log file created during the current run:
#   grep -Ire 'Payload is' rslog_20180530.txt | perl -ne 'my($input) = $_; if ($input =~ m/(\S+)\s(\S+)\s.+Payload\sis\s(\d+)[.]/) { print $1 . " " . " " . $2 . " " . " " . $3 . "\n"; }' | awk '{ if (beg == "") { beg = $1 " " $2 }; end = $1 " " $2; s+=$3} END {print beg " to " end " " s}'
# 5. the first two columns of the output of this command are a begin date and time, followed by 'to', followed by 
#    the end date and time, followed by the total number of bytes downloaded and ingested into SUMS


RET_SUCCESS = 0
RET_UNKNOWN_ERROR = 1
RET_UNKOWN_DRMSPARAMETER = 2
RET_INVALID_REMOTE_SUMS_ARGUMENT = 3
RET_INVALID_ARGUMENT = 4
RET_SU_NOT_REFERENCED = 5
RET_WORKER_REFERENCE_ERROR = 6
RET_UNABLE_TO_ACQUIRE_LOCK = 7
RET_UNABLE_TO_LOCK_OBJECT = 8
RET_UNABLE_TO_READ_REQTABLE = 11
RET_UNABLE_TO_WRITE_REQTABLE = 12
RET_UNABLE_TO_READ_SITETABLE = 13
RET_DUPLICATE_SUNUM = 14
RET_UNKNOWN_SUNUM = 15
RET_ERROR_CALLING_SUMS_API = 16
RET_UNKNOWN_REQUESTID = 17
RET_DUPLICATE_REQUESTID = 18
RET_UNABLE_TO_GET_SERIES_INFO = 19
RET_INVALID_SUNUM = 20
RET_UNKNOWN_SITE_CODE = 21
RET_UNABLE_TO_DOWNLOAD_SU = 22
RET_SHUTDOWN_REQUESTED = 23
RET_NO_SUS_TO_DOWNLOAD = 24
RET_DOWNLOADER = 25
RET_SUPATH_CGI = 26
RET_UNABLE_TO_START_THREAD = 27
RET_QUEUE_FULL = 28
RET_DUPLICATE_DISPATCHER_TYPE = 29
RET_TOO_MANY_THREADS = 30
RET_UNABLE_TO_CONNECT_TO_DB = 31
RET_UNEXPECTED_DB_RESPONSE = 32
RET_USER_TERMINATED = 33

LOG_FILE_BASE_NAME = 'rslog'

SUM_MAIN = 'public.sum_main'
SUM_PARTN_ALLOC = 'public.sum_partn_alloc'

# decreasing priority is by increasing index
REQTYPE_CODES = [ 'U', 'M', 'G' ]
REQTYPE_TEXT = [ 'USER', 'MIRROR', 'GENERIC' ] # generic implies that the system does not specify a request type (it is an older system that did not differentiate request types)
REQTYPE_PRIORITY = [ 0, 10, 100 ]
REQTYPE_DOWNLOADER = [ 'HighPriorityDownloader', 'Downloader', 'Downloader' ]

# SUMS archive type codes (archive substatus)
DAAEDDP = 32
DAADP = 128


def terminator(signo, frame):
    # Raise the SystemExit exception (which will be caught by the __exit__() method below).
    sys.exit(0)

class TerminationHandler(object):
    def __new__(cls, thContainer):
        return super(TerminationHandler, cls).__new__(cls)

    def __init__(self, thContainer):
        self.container = thContainer
        self.arguments = thContainer[0]
        self.pidStr = thContainer[1]
        self.log = thContainer[2]
        
        self.lockFile = self.arguments.lockfile
        self.dbname = self.arguments.dbname
        self.dbuser = self.arguments.dbuser
        self.dbhost = self.arguments.dbhost
        self.dbport = self.arguments.dbport
        self.conn = None
        
        self.sumsdbname = self.arguments.sumsdbname
        self.sumsdbuser = self.arguments.sumsdbuser
        self.sumsdbhost = self.arguments.sumsdbhost
        self.sumsdbport = self.arguments.sumsdbport
        self.sumsconn = None
        
        self.savedSignals = None

        super(TerminationHandler, self).__init__()
        
    def __enter__(self):    
        self.enableInterrupts()

        # Acquire locks.
        self.rsLock = DrmsLock(self.lockFile, self.pidStr, False)
        if not self.rsLock.acquireLock():
            raise LockException('remote SUMS already running')
            
        self.log.writeCritical([ 'starting up remote-SUMS daemon' ])
        self.log.writeCritical([ 'logging threshold level is ' + self.log.getLevel() ]) # Critical - always write the log level to the log
        self.log.writeCritical([ 'arguments:' ])
        self.arguments.dump(rslog)
        
        # Make main DB connection to RS database. We also have to connect to the SUMS database, so connect to that too.
        # The connections are NOT in autocommit mode. If changes need to be saved, then conn.commit() must be called.
        # Do this instead of using BEGIN and END/COMMIT statements, cuz I don't know if the psycopg2/libpq interaction
        # supports this properly.
        try:
            self.conn = psycopg2.connect(database=self.dbname, user=self.dbuser, host=self.dbhost, port=self.dbport)
            self.log.writeInfo([ 'Connected to DRMS database ' + self.dbname + ' on ' + self.dbhost + ':' + str(self.dbport) + ' as user ' + self.dbuser + '.' ])

            self.sumsconn = psycopg2.connect(database=self.sumsdbname, user=self.sumsdbuser, host=self.sumsdbhost, port=self.sumsdbport)
            self.log.writeInfo([ 'Connected to SUMS database ' + self.sumsdbname + ' on ' + self.sumsdbhost + ':' + str(self.sumsdbport) + ' as user ' + self.sumsdbuser + '.' ])            
        except psycopg2.DatabaseError as exc:
            self.__exit__(*sys.exc_info()) # clean up
            raise DBConnectionException('Unable to connect to a database.')
        except psycopg2.Error as exc:
            self.__exit__(*sys.exc_info()) # clean up
            raise DBConnectionException('Unable to connect to a database.')

        return self

    # Normally, __exit__ is called if an exception occurs inside the with block. And since SIGINT is converted
    # into a KeyboardInterrupt exception, it will be handled by __exit__(). However, SIGTERM will not - 
    # __exit__() will be bypassed if a SIGTERM signal is received. Use the signal handler installed in the
    # __enter__() call to handle SIGTERM.
    def __exit__(self, etype, value, traceback):
        self.log.writeDebug([ 'TerminationHandler.__exit__() called' ])
        if etype is not None:
            # If the context manager was exited without an exception, then etype is None
            import traceback
            self.log.writeDebug([ traceback.format_exc(5) ])

        print('Remote SUMS shutting down...')
        self.finalStuff()
        
        # Clean up lock
        try:     
            self.rsLock.releaseLock()   
            self.rsLock.close()
            self.rsLock = None
        except IOError:
            pass
            
        self.log.writeDebug([ 'Exiting TerminationHandler.' ])
        
        if etype == SystemExit:
            print('and done')
            raise TerminationException('Termination signal handler called.')
            
    def saveSignal(self, signo, frame):
        if self.savedSignals == None:
            self.savedSignals = []

        self.savedSignals.append((signo, frame))
        self.log.writeDebug([ 'saved signal ' +  str(signo) ])

    def disableInterrupts(self):
        signal.signal(signal.SIGINT, self.saveSignal)
        signal.signal(signal.SIGTERM, self.saveSignal)
        signal.signal(signal.SIGHUP, self.saveSignal)
        
    def enableInterrupts(self):
        signal.signal(signal.SIGINT, terminator)
        signal.signal(signal.SIGTERM, terminator)
        signal.signal(signal.SIGHUP, terminator)
        
        if type(self.savedSignals) is list:
            for signalReceived in self.savedSignals:
                terminator(*signalReceived)
        
        self.savedSignals = None

    def finalStuff(self):
        self.log.writeInfo([ 'halting threads' ])
        
        # shut-down Dispatchers
        Dispatcher.lock.acquire()
        try:
            for dispatcher in Dispatcher.tList:
                # send lastitem queue item to dispatchers
                lastitem = DispatcherQueueItem(cgi=None, sunums=None, sutable=None, dbuser=None, reqtable=None, request=None, binpath=None, hastapesys=None, tmpdir=None, lastitem=True, expiration=None, archive=None, tapegroup=None, log=self.log)
                dispatcher.queue.put_nowait(lastitem)
                self.log.writeInfo([ 'waiting for Dispatcher ' + dispatcher.name + ' to halt' ])
        finally:
            Dispatcher.lock.release()

        while True:
            Dispatcher.lock.acquire()
            try:
                if len(Dispatcher.tList) > 0:
                    dispatcher = Dispatcher.tList[0]
                else:
                    break
            finally:
                Dispatcher.lock.release()

            if dispatcher and isinstance(dispatcher, (Dispatcher)) and dispatcher.isAlive():
                # wait for pending Dispatcher tasks to complete
                dispatcher.queue.join()
                dispatcher.join()

        # Shut-down ScpWorker threads. Send the sdEvent to all threads first, then wait after they have ALL received the message.
        # Otherwise, later threads could try to download SUs whose download was aborted by earlier threads.
        gotLock = False
        try:
            gotLock = ScpWorker.lock.acquire()
            if gotLock:
                for scpWorker in ScpWorker.tList:
                    self.log.writeInfo([ 'telling Scp Worker (ID ' + str(scpWorker.id) + ') to halt' ])
                    scpWorker.stop()
        finally:
            if gotLock:
                ScpWorker.lock.release()

        while True:
            gotLock = False
            scpWorker = None
            try:
                gotLock = ScpWorker.lock.acquire()
                # got lock - can't get here otherwise

                if len(ScpWorker.tList) > 0:
                    scpWorker = ScpWorker.tList[0]
                else:
                    break
            except:
                break
            finally:
                if gotLock:
                    ScpWorker.lock.release()

            if scpWorker and isinstance(scpWorker, (ScpWorker)) and scpWorker.isAlive():
                # can't hold worker lock here - when the worker terminates, it acquires the same lock
                self.log.writeInfo([ 'waiting for Scp Worker (ID ' + str(scpWorker.id) + ') to halt' ])
                scpWorker.join() # will block, possibly for ever

        # shut-down HighPriorityDownloader threads
        gotLock = False
        try:
            gotLock = HighPriorityDownloader.lock.acquire()
            if gotLock:
                for downloader in HighPriorityDownloader.tList:
                    self.log.writeInfo([ 'Waiting for Downloader (SUNUM ' + str(downloader.su.sunum) + ') to halt.' ])
                    downloader.stop()
        finally:
            if gotLock:
                HighPriorityDownloader.lock.release() 

        while True:
            gotLock = False
            try:
                gotLock = HighPriorityDownloader.lock.acquire()
                # got lock - can't get here otherwise

                if len(HighPriorityDownloader.tList) > 0:
                    downloader = HighPriorityDownloader.tList[0]
                else:
                    break 
            finally:
                if gotLock:
                    HighPriorityDownloader.lock.release()
                    
            if downloader and isinstance(downloader, (HighPriorityDownloader)) and downloader.isAlive():
                downloader.join() 
        
        # shut-down Downloader threads
        gotLock = False
        try:
            gotLock = Downloader.lock.acquire()
            if gotLock:
                for downloader in Downloader.tList:
                    self.log.writeInfo([ 'Waiting for Downloader (SUNUM ' + str(downloader.su.sunum) + ') to halt.' ])
                    downloader.stop()
        finally:
            if gotLock:
                Downloader.lock.release() 

        while True:
            gotLock = False
            try:
                gotLock = Downloader.lock.acquire()
                # got lock - can't get here otherwise

                if len(Downloader.tList) > 0:
                    downloader = Downloader.tList[0]
                else:
                    break 
            finally:
                if gotLock:
                    Downloader.lock.release()
                    
            if downloader and isinstance(downloader, (Downloader)) and downloader.isAlive():
                downloader.join()

        if self.sumsconn:
            self.sumsconn.close()
            self.sumsconn = None
                
        if self.conn:
            self.conn.close()
            self.conn = None
    
        self.log.flush()
        

    def rsConn(self):
        return self.conn

    def sumsConn(self):
        return self.sumsconn


class SumsDrmsParams(DRMSParams):
    def __init__(self):
        super(SumsDrmsParams, self).__init__()

    def get(self, name):
        val = super(SumsDrmsParams, self).get(name)

        if val is None:
            raise DrmsParamsException('Unknown DRMS parameter: ' + name + '.')
        return val


class Arguments(object):

    def __init__(self, parser):
        # This could raise in a few places. Let the caller handle these exceptions.
        self.parser = parser
        
        # Parse the arguments.
        self.parse()
        
        # Set all args.
        self.setAllArgs()
        
    def parse(self):
        try:
            self.parsedArgs = self.parser.parse_args()      
        except Exception as exc:
            if len(exc.args) == 2:
                type, msg = exc
                  
                if type != 'CmdlParser-ArgUnrecognized' and type != 'CmdlParser-ArgBadformat':
                    raise # Re-raise

                raise RSArgsException(msg)
            else:
                raise # Re-raise

    def setArg(self, name, value):
        if not hasattr(self, name):
            # Since Arguments is a new-style class, it has a __dict__, so we can
            # set attributes directly in the Arguments instance.
            setattr(self, name, value)
        else:
            raise RSArgsException('Attempt to set an argument that already exists: ' + name + '.')

    def setAllArgs(self):
        for key,val in list(vars(self.parsedArgs).items()):
            self.setArg(key, val)
        
    def getArg(self, name):
        try:
            return getattr(self, name)
        except AttributeError as exc:
            raise RSArgsException('Unknown argument: ' + name + '.')
            
    def dump(self, log):
        attrList = []
        for attr in sorted(vars(self)):
            attrList.append('  ' + attr + ':' + str(getattr(self, attr)))
        log.writeDebug([ '\n'.join(attrList) ])
        
    @classmethod
    def checkArg(cls, argName, exc, default, **kwargs):
        val = None
        if argName in kwargs:
            val = kwargs[argName]
        elif exc is not None:
            raise exc
        else:
            val = default
        return val


class Log(object):
    """Manage a logfile."""
    def __init__(self, file, level, formatter):
        self.fileName = file
        self.log = logging.getLogger()
        self.log.setLevel(level)
        self.fileHandler = logging.FileHandler(file)
        self.fileHandler.setLevel(level)
        self.fileHandler.setFormatter(formatter)
        self.log.addHandler(self.fileHandler)
        
    def close(self):
        if self.log:
            if self.fileHandler:
                self.log.removeHandler(self.fileHandler)
                self.fileHandler.flush()
                self.fileHandler.close()
                self.fileHandler = None
            self.log = None
            
    def flush(self):
        if self.log and self.fileHandler:
            self.fileHandler.flush()
            
    def getLevel(self):
        # Hacky way to get the level - make a dummy LogRecord
        logRecord = self.log.makeRecord(self.log.name, self.log.getEffectiveLevel(), None, '', '', None, None)
        return logRecord.levelname
        
    def __prependFrameInfo(self, msg):
        frame, fileName, lineNo, fxn, context, index = inspect.stack()[2]
        return os.path.basename(fileName) + ':' + str(lineNo) + ': ' + msg

    def writeDebug(self, text):
        if self.log:
            for line in text:                
                self.log.debug(self.__prependFrameInfo(line))
            self.fileHandler.flush()
            
    def writeInfo(self, text):
        if self.log:
            for line in text:
                self.log.info(self.__prependFrameInfo(line))
        self.fileHandler.flush()
    
    def writeWarning(self, text):
        if self.log:
            for line in text:
                self.log.warning(self.__prependFrameInfo(line))
            self.fileHandler.flush()
    
    def writeError(self, text):
        if self.log:
            for line in text:
                self.log.error(self.__prependFrameInfo(line))
            self.fileHandler.flush()
            
    def writeCritical(self, text):
        if self.log:
            for line in text:
                self.log.critical(self.__prependFrameInfo(line))
            self.fileHandler.flush()


class RemoteSumsException(Exception):

    def __init__(self, msg):
        super(RemoteSumsException, self).__init__(msg)
        self.msg = msg # also in args[0] due to base-class constructor
        self.retcode = RET_UNKNOWN_ERROR

class DrmsParamsException(RemoteSumsException):

    def __init__(self, msg):
        super(DrmsParamsException, self).__init__(msg)
        self.retcode = RET_UNKOWN_DRMSPARAMETER
        
class RSArgsException(RemoteSumsException):

    def __init__(self, msg):
        super(RSArgsException, self).__init__(msg)
        self.retcode = RET_INVALID_REMOTE_SUMS_ARGUMENT

class InvalidArgumentException(RemoteSumsException):

    def __init__(self, msg):
        super(InvalidArgumentException, self).__init__(msg)
        self.retcode = RET_INVALID_ARGUMENT
        
class NoSUReferenceException(RemoteSumsException):

    def __init__(self, msg):
        super(NoSUReferenceException, self).__init__(msg)
        self.retcode = RET_SU_NOT_REFERENCED
        
class WorkerReferenceException(RemoteSumsException):

    def __init__(self, msg):
        super(WorkerReferenceException, self).__init__(msg)
        self.retcode = RET_WORKER_REFERENCE_ERROR

class LockException(RemoteSumsException):

    def __init__(self, msg):
        super(LockException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_ACQUIRE_LOCK
        
class LockAndHoldException(RemoteSumsException):

    def __init__(self, msg):
        super(LockAndHoldException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_LOCK_OBJECT
        
class ReqtableReadException(RemoteSumsException):

    def __init__(self, msg):
        super(ReqtableReadException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_READ_REQTABLE
        
class ReqtableWriteException(RemoteSumsException):

    def __init__(self, msg):
        super(ReqtableWriteException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_WRITE_REQTABLE
        
class SitetableReadException(RemoteSumsException):

    def __init__(self, msg):
        super(SitetableReadException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_READ_SITETABLE
        
class DuplicateSUException(RemoteSumsException):

    def __init__(self, msg):
        super(DuplicateSUException, self).__init__(msg)
        self.retcode = RET_DUPLICATE_SUNUM

class UnknownSunumException(RemoteSumsException):

    def __init__(self, msg):
        super(UnknownSunumException, self).__init__(msg)
        self.retcode = RET_UNKNOWN_SUNUM
        
class SumsAPIException(RemoteSumsException):

    def __init__(self, msg):
        super(SumsAPIException, self).__init__(msg)
        self.retcode = RET_ERROR_CALLING_SUMS_API
        
class UnknownRequestidException(RemoteSumsException):

    def __init__(self, msg):
        super(UnknownRequestidException, self).__init__(msg)
        self.retcode = RET_UNKNOWN_REQUESTID

class DuplicateRequestidException(RemoteSumsException):

    def __init__(self, msg):
        super(DuplicateRequestidException, self).__init__(msg)
        self.retcode = RET_DUPLICATE_REQUESTID

class GetSeriesInfoException(RemoteSumsException):

    def __init__(self, msg):
        super(GetSeriesInfoException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_GET_SERIES_INFO
        
class InvalidSunumException(RemoteSumsException):

    def __init__(self, msg):
        super(InvalidSunumException, self).__init__(msg)
        self.retcode = RET_INVALID_SUNUM

class UnknownSitecodeException(RemoteSumsException):

    def __init__(self, msg):
        super(UnknownSitecodeException, self).__init__(msg)
        self.retcode = RET_UNKNOWN_SITE_CODE
        
class ScpSUException(RemoteSumsException):

    def __init__(self, msg):
        super(ScpSUException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_DOWNLOAD_SU
        
class ShutDownException(RemoteSumsException):

    def __init__(self, msg):
        super(ShutDownException, self).__init__(msg)
        self.retcode = RET_SHUTDOWN_REQUESTED
        
class NoSusForDlException(RemoteSumsException):

    def __init__(self, msg):
        super(NoSusForDlException, self).__init__(msg)
        self.retcode = RET_NO_SUS_TO_DOWNLOAD
        
class DownloaderException(RemoteSumsException):

    def __init__(self, msg):
        super(DownloaderException, self).__init__(msg)
        self.retcode = RET_DOWNLOADER

class SUPathCGIException(RemoteSumsException):

    def __init__(self, msg):
        super(SUPathCGIException, self).__init__(msg)
        self.retcode = RET_SUPATH_CGI
        
class RSIOException(RemoteSumsException):

    def __init__(self, msg):
        super(RSIOException, self).__init__(msg)
        self.retcode = RET_IO_ERROR
        
class StartThreadException(RemoteSumsException):

    def __init__(self, msg):
        super(StartThreadException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_START_THREAD

class QueueFullException(RemoteSumsException):

    def __init__(self, msg):
        super(QueueFullException, self).__init__(msg)
        self.retcode = RET_QUEUE_FULL
        
class DuplicateDispatcherType(RemoteSumsException):

    def __init__(self, msg):
        super(DuplicateDispatcherType, self).__init__(msg)
        self.retcode = RET_DUPLICATE_DISPATCHER_TYPE
        
class MaxThreadsException(RemoteSumsException):

    def __init__(self, msg):
        super(MaxThreadsException, self).__init__(msg)
        self.retcode = RET_TOO_MANY_THREADS
        
class DBConnectionException(RemoteSumsException):

    def __init__(self, msg):
        super(DBConnectionException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_CONNECT_TO_DB
        
class DBResponseException(RemoteSumsException):

    def __init__(self, msg):
        super(DBResponseException, self).__init__(msg)
        self.retcode = RET_UNEXPECTED_DB_RESPONSE
        
class TimeoutException(RemoteSumsException):

    def __init__(self, msg):
        super(TimeoutException, self).__init__(msg)
        
        # do not set retcode - this error is never fatal

class TerminationException(RemoteSumsException):

    def __init__(self, msg):
        super(TerminationException, self).__init__(msg)
        self.retcode = RET_USER_TERMINATED


class NotTimeToLogException(RemoteSumsException):
    def __init__(self):
        super(NotTimeToLogException, self).__init__('')

class CheckTimer(object):
    """context manager for checking for time-to-write, and updating last write time"""
    def __init__(self, iLogger, fxn, updateTime):
        self.iLogger = iLogger
        self.fxn = getattr(self.iLogger.log, fxn)
        self.updateTime = updateTime
        self.wrote = False

    def __enter__(self):
        return self

    def __exit__(self, etype, value, traceback):
        if etype == None:
            if self.updateTime and self.wrote:
                self.iLogger.updateLastWriteTime()
            return True
        else:
            return etype == NotTimeToLogException # swallow NotTimeToLogException exception
            
    def call(self, text):
        if not self.iLogger.timeToLog():
            raise NotTimeToLogException()
        self.fxn(text)
        self.wrote = True
    

class IntervalLogger(object):
    """create one object per loop"""
    def __init__(self, log, logInterval):
        self.log = log
        self.logInterval = logInterval
        self.lastWriteTime = None

    def timeToLog(self):        
        if self.lastWriteTime is None:
            return True
        else:
            timeNow = datetime.now(timezone.utc)
            if timeNow > self.lastWriteTime + self.logInterval:
                return True
            else:
                return False
            
    def updateLastWriteTime(self):
        if self.timeToLog():
            # update last print time only if the interval between last print and now has elapsed
            self.lastWriteTime = datetime.now(timezone.utc)

    def writeDebug(self, text, updateTime=True):
        with CheckTimer(self, 'writeDebug', updateTime) as ct:
            ct.call(text)

    def writeInfo(self, text, updateTime=True):
        with CheckTimer(self, 'writeInfo', updateTime) as ct:
            ct.call(text)

    def writeWarning(self, text, updateTime=True):
        with CheckTimer(self, 'writeWarning', updateTime) as ct:
            ct.call(text)

    def writeError(self, text, updateTime=True):
        with CheckTimer(self, 'writeError', updateTime) as ct:
            ct.call(text)

    def writeCritical(self, text, updateTime=True):
        with CheckTimer(self, 'writeCritical', updateTime) as ct:
            ct.call(text)

        
class StorageUnit(object):
    def __init__(self, sunum, starttime, refcount, status, errmsg):
        self.sunum = sunum
        self.starttime = starttime
        self.refcount = refcount
        self.status = status
        self.errmsg = errmsg
        self.suSize = None
        self.worker = None
        
    def getSunum(self):
        return self.sunum
        
    def getSeries(self):
        return self.series
            
    def setSeries(self, value):
        if not isinstance(value, (str)):
            raise InvalidArgumentException('setSeries(): argument must be a str')

        self.series = value
        
    def getExpiration(self):
        if self.expiration < datetime.now():
            self.expiration = datetime.now()

        return self.expiration

    def setExpiration(self, value):
        if not isinstance(value, (datetime)):
            raise InvalidArgumentException('setExpiration(): argument must be a datetime')
            
        if value < datetime.now():
            self.expiration = datetime.now()
        else:            
            self.expiration = value
        
    def getArchive(self):
        return self.archive
        
    def setArchive(self, value):
        if not isinstance(value, (bool)):
            raise InvalidArgumentException('setArchive(): argument must be a bool')

    def getTapegroup(self):
        return self.tapegroup
        
    def setTapegroup(self, value):
        if not isinstance(value, (int)):
            raise InvalidArgumentException('setTapegroup(): argument must be an int')
            
        self.tapegroup = value

    def getStarttime(self):
        return self.starttime
    
    def setStarttime(self, value):
        if not isinstance(value, (datetime)):
            raise InvalidArgumentException('setStarttime(): argument must be a datetime')
            
        self.starttime = value
        
    def touch(self):
        self.setStarttime(datetime.now(timezone.utc))
    
    def getStatus(self):
        return self.status
    
    # Set properties that are saved to the DB.
    def setStatus(self, codeValue, msgValue):
        if not isinstance(codeValue, (str)):
            raise InvalidArgumentException('setStatus(): fist argument must be a str.')
            
        if not isinstance(msgValue, (str)) and msgValue is not None:
            raise InvalidArgumentException('setStatus(): second argument must be a str or None.')
            
        self.status = codeValue
        if msgValue is not None:
            self.errmsg = msgValue
        else:
            self.errmsg = ''
                
    def getPath(self):
        path = None
        if hasattr(self, 'path'):
            path = self.path
        return path
        
    def setPath(self, value):
        if not isinstance(value, (str)) and value is not None:
            raise InvalidArgumentException('setPath(): argument must be a str or None')
            
        self.path = value
        
    def getSize(self):
        return self.suSize
            
    def setSize(self, value):
        if not isinstance(value, (int)):
            raise InvalidArgumentException('setSize(): argument must be an int')
            
        self.suSize = value
    
    def getWorker(self):
        return self.worker
        
    def setWorker(self, value):
        if not isinstance(value, (Downloader)):
            raise InvalidArgumentException('setWorker(): argument must be a Downloader')
            
        if self.worker:
            raise WorkerReferenceException('cannot set worker for SU ' + str(self.sunum) + '; worker already exists')
            
        self.worker = value
        
    def removeWorker(self):
        self.worker = None
        
    def stopWorker(self):
        if hasattr(self, 'worker') and self.worker and isInstance(self.worker, (Downloader)) and self.worker.isAlive():
            self.worker.stop()
            if self.worker.isAlive():
                # Give the worker 15 seconds to self-terminate.
                self.worker.join(15)
            if self.worker.isAlive():
                # Apparently, there is no way to kill a thread from another thread. So, we are just going to
                # orphan the thread (so it doesn't use up our maxThreads quota).
                try:
                    self.worker.lock.acquire()
                    if self.worker in self.worker.tList:
                        self.worker.tList.remove(self.worker) # This thread is no longer one of the running threads.
                        if len(self.worker.tList) <= self.worker.maxThreads - 1:
                            # Fire event so that main thread can add new SUs to the download queue.
                            self.worker.eventMaxThreads.set()
                            # Clear event so that main will block the next time it calls wait.
                            self.worker.eventMaxThreads.clear()
                finally:
                    self.worker.lock.release()

            self.removeWorker()        


class SuTable:
    rsConn = None
    rsDbLock = None # There is one global lock for the rs connection. Since the main thread and the Downloader and ScpWorker threads
                    # all share the rs connection, they all need to use the same lock.

    sumsConn = None
    sumsDbLock = None # Since all Downloader threads and the main thread share the same connection, their cursors 
                      # on these connections are not isolated. Use a lock to ensure a consistent view in the
                      # offline() method.

    def __init__(self, timeOut, reqtable, log):
        self.timeOut = timeOut # A timedelta object - the length of time to wait for a download to complete.
        self.lock = threading.Lock()
        self.reqtable = reqtable # the table of requests that the contained SUs map to (map: 1 SU Table <--> 1 Req Table)
        self.log = log
        self.suDict = {}
        self.queue = Queue(0) # non-blocking, infinite sized
        self.suMap = {} # map an SU to a ReqTable request id

    def acquireLock(self):
        return self.lock.acquire()
        # self.log.writeDebug(['Acquired SU-Table lock.'])
    
    def releaseLock(self):
        self.lock.release()
        # self.log.writeDebug(['Released SU-Table lock.'])
    
    # main and dispatcher threads only
    def addSUs(self, **kwargs):
        sunums = Arguments.checkArg('sunums', None, None, **kwargs)
        locktable = Arguments.checkArg('locktable', None, True, **kwargs)
        initialStatus = Arguments.checkArg('status', None, 'P', **kwargs)
        
        existingSUs = []
        newSUs = []

        # must lock the SU Table, either here, or in the enclosing block of code
        sus, missingSunums = self.getSUs(sunums=sunums, lockTable=locktable, releaseTableLock=False)
        try:
            existingSUs.extend(sus)

            # increment refcount of existing SUs
            self.__incrementRefcount(sunums=[ su.sunum for su in sus ], locktable=False)

            # create new SU objects for SUs that do not currently exist
            for sunum in missingSunums:
                # sets refcount to 1
                su = StorageUnit(sunum, datetime.now(timezone.utc), 1, initialStatus, '')
                newSUs.append(su)
    
                self.suDict[str(su.sunum)] = su
        finally:
            if locktable:
                self.releaseLock()
            
        # return a list of all SUs identified by the sunums argument  
        return (existingSUs, newSUs)
                
    def removeSUs(self, **kwargs):
        sunums = Arguments.checkArg('sunums', None, None, **kwargs)
        locktable = Arguments.checkArg('locktable', None, True, **kwargs)

        # increment refcount of existing SUs
        self.__decrementRefcount(sunums=sunums, locktable=locktable)

    def setStatus(self, sunums, code, msg=None):
        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False)
        try:
            for su in sus:
                su.setStatus(code, msg)
        finally:
            self.releaseLock()

    def setSeries(self, sunums, series):
        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False)
        try:
            for su in sus:
                su.setSeries(series)
        finally:
            self.releaseLock()

    def setExpiration(self, sunums, expiration):    
        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False)
        try:
            for su in sus:
                su.setExpiration(expiration)
        finally:
            self.releaseLock()

    def setStarttime(self, sunums, starttime):
        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False)
        try:
            for su in sus:
                su.setStarttime(starttime)
        finally:
            self.releaseLock()

    def __incrementRefcount(self, **kwargs):
        sunums = Arguments.checkArg('sunums', None, None, **kwargs)
        locktable = Arguments.checkArg('locktable', None, True, **kwargs)

        sus, missingSunums = self.getSUs(sunums=sunums, lockTable=locktable, releaseTableLock=False)
        try:
            for su in sus:
                refCount = su.refcount + 1
                su.refcount = refCount
                self.log.writeDebug([ 'incremented refcount for ' + str(su.sunum) + '; refcount is now ' + str(refCount) ])
        finally:
            if locktable:
                self.releaseLock()

    def __decrementRefcount(self, **kwargs):
        sunums = Arguments.checkArg('sunums', None, None, **kwargs)
        locktable = Arguments.checkArg('locktable', None, True, **kwargs)

        sus, missingSunums = self.getSUs(sunums=sunums, lockTable=locktable, releaseTableLock=False)
        try:
            for su in sus:
                refCount = su.refcount - 1
                su.refcount = refCount
                self.log.writeDebug([ 'decremented refcount for ' + str(su.sunum) + '; refcount is now ' + str(refCount) ])

                if su.refcount == 0:
                    del self.suDict[str(su.sunum)]
                    self.log.writeDebug([ 'refcount 0 - deleted SU ' + str(su.sunum) ])
        finally:
            if locktable:
                self.releaseLock()

    def setWorker(self, sunum, worker):
        sunumStr = str(sunum)

        sus, missingSunums = self.getSUs(sunums=[ sunum ], releaseTableLock=False)
        try:
            if len(sus) == 1:
                su = sus[0]
                su.setWorker(worker)
            else:
                raise WorkerReferenceException('cannot set worker for SU ' + str(self.sunum) + '; SU does not exist')
        finally:
            self.releaseLock()

    # class private, to prevent code outside this class from calling this method without first locking the table;
    # we need to lock the table since it reads self.suDict
    def __get(self, sunums=None):
        # DOES NOT acquire table lock; this method is called by SUTable.getSUs(), which acquires the
        # table lock
        foundSUs = []
        notfoundSunums = []
        
        if sunums is None:
            for sunumStr, su in self.suDict.items():
                foundSUs.append(su)
        else:
            for asunum in sunums:
                sunumStr = str(asunum)
    
                try:
                    if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                        raise UnknownSunumException('(__get) no SU-table record exists for SU ' + sunumStr)
                    foundSUs.append(self.suDict[sunumStr])
                except:
                    notfoundSunums.append(asunum)

        return (foundSUs, notfoundSunums)

    # some SUs may not exist; return a tuple - the first element is a list of existing SUs, and the second element is
    # a list of invalid SUNUMs
    def getSUs(self, **kwargs):
        lockTable = Arguments.checkArg('lockTable', None, True, **kwargs)
        releaseTableLock = Arguments.checkArg('releaseTableLock', None, True, **kwargs)
        sunums = Arguments.checkArg('sunums', None, None, **kwargs)
        filter = Arguments.checkArg('filter', None, None, **kwargs)

        sus = [] # known SUs
        missingSunums = [] # missing SUs

        if lockTable:
            self.acquireLock()
        try:
            # lock acquired (can't get here otherwise)
            sus, missingSunums = self.__get(sunums)
            
            if filter:
                filteredSus, deletedSus = filter(sus)
                if len(deletedSus) > 0:
                    missingSunums.extend(deletedSus)

                sus = filteredSus
        finally:
            # Always release lock.
            if lockTable and releaseTableLock:
                self.releaseLock()
                
        return (sus, missingSunums)

    # Returns a list of SU objects.
    # NOT THREAD SAFE! This method is called by the main thread on start-up, before any other threads have been started.
    def getPending(self):
        pending = []
        
        for sunumStr, su in self.suDict.items():                
            if su.status == 'P':
                su.touch()
                pending.append(su)

        # Sorts in place - and returns None. The SUs will be sorted by starttime later, before Downloader threads are created
        # for them.
        pending.sort(key=lambda ansu : ansu.sunum)

        return pending
        
    # Returns a list of SU objects.
    # NOT THREAD SAFE! This method is called by the main thread on start-up, before any other threads have been started.
    def getWorking(self):
        working = []
        
        for sunumStr, su in self.suDict.items():                
            if su.status == 'W':
                su.touch()
                working.append(su)

        # Sorts in place - and returns None. The SUs will be sorted by starttime later, before Downloader threads are created
        # for them.
        working.sort(key=lambda ansu : ansu.sunum)

        return working
    
    # Returns num SU entries whose status is 'W'. If fewer than num W entries exist, then all W SU entries are returned.
    # Must acquire SU table lock before calling this method. There is no need to lock the individual SUs because the ScpWorker
    # threads must acquire the SU Table lock before calling getNextNWorking(). No other ScpWorker thread can 
    # change a W to a D while this ScpWorker is collecting SUs with a W status.
    #
    # Sort by start time - process the oldest first.
    #
    # All SUs returned MUST have the same scpUser, scpHost, and scpPort.
    def getNextNWorkingSUs(self, id, num, priority):
        # this ScpWorker can collect SUs with 'priority' level priority, or higher
        nworking = []
        scpUser = None
        scpHost = None
        scpPort = None
        scpInfoSet = False

        # get lock because we are reading self.suDict
        self.acquireLock()
        try:
            # filter by priority
            # ReqTable::get() needs to be locked because the main thread refreshes the ReqTable, and that can happen
            # concurrently with the call below to ReqTable::get()
            reqTypeToPriority = dict(zip(REQTYPE_TEXT, REQTYPE_PRIORITY))
            suAndPriority = [ (su, min([ reqTypeToPriority[self.reqtable.get([ reqid ])[0]['type']] for reqid in self.suMap[str(su.sunum)] ])) for su in list(self.suDict.values()) ]
            filteredSUs = list(filter(lambda elem: elem[1] <= priority, suAndPriority))
        
            # do a double sort (priority, start-time)
            sortedSUs = sorted(filteredSUs, key=lambda elem: (elem[1], elem[0].starttime.strftime('%Y-%m-%d %T')))
            
            it = iter(sortedSUs)
            try:
                while num > 0:
                    su, priority = next(it)
                    try:
                        if su.status == 'W':
                            su.touch()
                            if su.worker is None:
                                raise WorkerReferenceException('no worker thread assigned to SU ' + str(su.sunum))
                            if scpInfoSet == False:
                                scpUser = su.worker.scpUser
                                scpHost = su.worker.scpHost
                                scpPort = su.worker.scpPort
                                scpInfoSet = True

                            if su.worker.scpUser == scpUser and su.worker.scpHost == scpHost and su.worker.scpPort == scpPort:
                                nworking.append(su)
                                num -= 1
                    except:
                        # remove su from nworking (if we appended it)
                        if su in nworking:
                            nworking.pop()
                    finally:
                        pass
            except StopIteration:
                pass
        except:
            import traceback
            self.log.writeError([ traceback.format_exc(5) ])
            nworking = []

        return (nworking, (scpUser, scpHost, scpPort))      

    def getTimeout(self):
        return self.timeOut

    def addRequestToSUMap(self, **kwargs):
        for sunum in kwargs['sunums']:
            if str(sunum) not in self.suMap:
                self.suMap[str(sunum)] = []
                
            if kwargs['requestid'] in self.suMap[str(sunum)]:
                raise DuplicateRequestidException('duplicate SU Map entry: requestid = ' + str(kwargs['requestid']) + ', sunum = ' + str(sunum))

            self.suMap[str(sunum)].append(kwargs['requestid'])
        
    def removeRequestFromSUMap(self, **kwargs):
        for su in kwargs['sus']:
            if str(su.sunum) in self.suMap:
                self.suMap[str(su.sunum)].remove(kwargs['requestid'])
                if len(self.suMap[str(su.sunum)]) == 0:
                    del self.suMap[str(su.sunum)]
    
    def presentInSUMap(self, **kwargs):
        sunums = kwargs['sunums']
        requestID = kwargs['requestid']
        answer = True

        for sunum in sunums:
            if str(sunum) not in self.suMap or requestID not in self.suMap[str(sunum)]:
                answer = False
                break
        
        return answer

    @classmethod
    def offline(cls, sunums, log):
        rv = []        

        if len(sunums) > 0:
            # query the SUMS db and check to see which of the SUs in sunums are present in the sum_main/sum_partn_alloc table
            cmd = "SELECT T1.ds_index, T1.online_loc, T1.online_status, T1.archive_status, T1.offsite_ack, T1.history_comment, T1.owning_series, T1.storage_group, T1.bytes, T1.create_sumid, T1.creat_date, T1.username, COALESCE(T1.arch_tape, 'N/A'), COALESCE(T1.arch_tape_fn, 0), COALESCE(T1.arch_tape_date, '1958-01-01 00:00:00'), COALESCE(T1.safe_tape, 'N/A'), COALESCE(T1.safe_tape_fn, 0), COALESCE(T1.safe_tape_date, '1958-01-01 00:00:00'), COALESCE(T2.effective_date, '195801010000'), coalesce(T2.status, 0), coalesce(T2.archive_substatus, 0) FROM " + SUM_MAIN + " AS T1 LEFT OUTER JOIN " + SUM_PARTN_ALLOC + " AS T2 ON (T1.ds_index = T2.ds_index) WHERE T1.ds_index IN (" + ','.join([ str(asunum) for asunum in sunums ]) + ')'

            try:
                gotSumsDbLock = SuTable.sumsDbLock.acquire()
                if gotSumsDbLock:
                    with SuTable.sumsConn.cursor() as cursor:
                        knownSUs = {} # bitmap of SUs known to the SUMS db.
                        try:                    
                            cursor.execute(cmd)
                            log.writeDebug([ 'Successfully queried SUMS db for known SUs.' ])
                        
                            # Put each SU in the result into the bitmap.
                            for row in cursor:
                                knownSUs[str(row[0])] = True
                        
                            # Determine which SUs for which we are going to initiate Downloaders that are not already in SUMS.
                            for ansunum in sunums:                        
                                if str(ansunum) not in knownSUs:
                                    rv.append(ansunum)
                        except psycopg2.Error as exc:
                            # Handle database-command errors. These are all due to problems communicating with the SUMS db.
                            raise SumsAPIException(exc.diag.message_primary + ': ' + cmd + '.') 
                        finally:
                            # Not making changes, so rollback always.
                            SuTable.sumsConn.rollback()
            finally:
                if gotSumsDbLock:
                    SuTable.sumsDbLock.release()

        return rv
    

class ReqTable:
    '''
    '''
    rsConn = None
    rsDbLock = None # There is one global lock for the rs connection. Since the main thread and the Downloader and ScpWorker threads
                    # all share the rs connection, they all need to use the same lock.

    def __init__(self, tableName, timeOut, log):
        self.tableName = tableName
        self.timeOut = timeOut
        self.log = log
        self.reqDict = {}
        self.lock = threading.Lock() # for concurrent access to reqDict (needed to get req type for determining priority)
        
    def acquireLock(self):
        return self.lock.acquire()
    
    def releaseLock(self):
        self.lock.release()

    def read(self):
        # to support SU priority, we had to add a column at some point; not all releases have this column; as a result, we do not know the exact set of columns; so basically we have to deal with a PITA
        try:
            gotRsDbLock = ReqTable.rsDbLock.acquire()
            if gotRsDbLock:
                with ReqTable.rsConn.cursor() as cursor:
                    cmd1 = 'SELECT * FROM ' + self.tableName + ' LIMIT 0'
                    cursor.execute(cmd1)
                    cols = [ desc[0] for desc in cursor.description ]
                    
                    # now we gotta check to make sure all columns are there (but 'type' might not be there, since it was added after remote SUMS went public)
                    if not all(acol in cols for acol in [ 'requestid', 'dbhost', 'dbport', 'dbname', 'starttime', 'sunums', 'status', 'errmsg' ]):
                        raise ReqtableReadException('at least one request table column is missing')
                    
                    cmd2 = 'SELECT ' + ','.join(cols) + ' FROM ' + self.tableName                
                    cursor.execute(cmd2)
        
                    for record in cursor:
                        # psycopg2 converts db type to Python types:
                        # requestid --> integer
                        # dbhost --> text
                        # dbport -> integer
                        # dbname -> text
                        # type --> text
                        # starttime --> datetime.datetime
                        # sunums --> text
                        # status --> text
                        # errmsg --> text

                        requestidStr = str(record[0])

                        self.reqDict[requestidStr] = {}
                        
                        for c, v in zip(cols, record):
                            if c.lower() == 'sunums':
                                self.reqDict[requestidStr][c] = [ int(asunum) for asunum in v.split(',') ]
                            elif c.lower() == 'type':
                                # ensure this is a valid type
                                if v not in REQTYPE_CODES:
                                    raise ReqtableReadException('unknown request type ' + v)
                                self.reqDict[requestidStr][c] = dict(zip(REQTYPE_CODES, REQTYPE_TEXT))[v]
                            else:
                                self.reqDict[requestidStr][c] = v
                                
                        # if type does not exist, set it to generic
                        if 'type' not in self.reqDict[requestidStr]:
                            self.reqDict[requestidStr]['type'] = 'GENERIC'
                        
                        # internal attributes
                        self.reqDict[requestidStr]['todispatch'] = list(set(self.reqDict[requestidStr]['sunums'])).copy() # as sunums are dispatched, they are removed from the 'todispatch' list
                        self.reqDict[requestidStr]['complete'] = []
                        self.reqDict[requestidStr]['dirty'] = False
        except psycopg2.Error as exc:
            raise ReqtableReadException(exc.diag.message_primary)
        finally:
            ReqTable.rsConn.rollback()
            
            if gotRsDbLock:
                ReqTable.rsDbLock.release()

    def tryRead(self):
        nAtts = 0
        while True:
            try:
                self.read()
                break
            except ReqtableReadException:
                if nAtts > 10:
                    raise # Re-raise

            nAtts += 1
            time.sleep(1)

    # This method finds 'N' records inserted since the last time it was run (or since the table was first read). It ignores
    # all other changes to the database table (made from outside this program) that have happened. To read those changes,
    # shut down this program, then make the changes, then start this program again.
    def refresh(self):
        # read the table from the database anew, but put the new request info into a temporary ReqTable
        # SLOW code
        tmpTable = ReqTable(self.tableName, self.timeOut, self.log)
        tmpTable.tryRead()
        # end SLOW code
    
        self.acquireLock()
        try:
            # save attributes not saved in the db
            saved = {}
            for (key, val) in self.reqDict.items():
                if 'todispatch' not in saved:
                    saved['todispatch'] = {}
                
                if 'complete' not in saved:
                    saved['complete'] = {}
                
                saved['todispatch'][key] = val['todispatch']
                saved['complete'][key] = val['complete'] # list of SUs already downloaded for this request

            # replace existing reqDict items with newly read items
            # ART - this could overwrite requests currently being processed; what we need to do is to 
            # shut-down ScpWorkers with stop(), let the Workers quit; the dispatcher queue might have items with the
            # request in them though
            self.reqDict = tmpTable.reqDict.copy()
        
            # we have to restore the things that do not stick in the db (but only for pending requests)
            # no need to hold a lock since only the main thread accesses the request status
            for (key, val) in self.reqDict.items():
                if self.reqDict[key]['status'] != 'N':
                    self.reqDict[key]['todispatch'] = saved['todispatch'][key]
                    self.reqDict[key]['complete'] = saved['complete'][key]
        finally:
            self.releaseLock()

    def getUpdateDBSql(self, requestids=None):
        sql = []

        if requestids:
            # Update the specified records.
            for arequestid in requestids:
                requestidStr = str(arequestid)
            
                if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                    self.log.writeWarning([ 'no request-table record exists for ID ' + requestidStr + '; skipping' ])
                
                if self.reqDict[requestidStr]['dirty']:
                    self.log.writeDebug([ 'updating req table DB for request ' + requestidStr ])
                    # The only columns that this daemon will modify are status and errmsg.
                    sql.append('UPDATE ' + self.tableName + " SET status='" + self.reqDict[requestidStr]['status'] + "', errmsg='" + self.reqDict[requestidStr]['errmsg'] + "' WHERE requestid=" + requestidStr)
                    
                    self.reqDict[requestidStr]['dirty'] = False
        else:
            for requestidStr in self.reqDict:
                if self.reqDict[requestidStr]['dirty']:
                    self.log.writeDebug([ 'updating req table DB for request ' + requestidStr ])
                    # The only columns that this daemon will modify are status and errmsg.
                    sql.append('UPDATE ' + self.tableName + " SET status='" + self.reqDict[requestidStr]['status'] + "', errmsg='" + self.reqDict[requestidStr]['errmsg'] + "' WHERE requestid='" + requestidStr + "'")
                    
                    self.reqDict[requestidStr]['dirty'] = False
                    
        return sql

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes.
    # no lock needed for the requests table (only the main thread access it)
    # returns True if the DB was changed (inside the current, uncommitted transaction), False otherwise
    def updateDB(self, sql):        
        if len(sql) > 0:
            try:
                cmd = ';\n'.join(sql)
                self.log.writeDebug([ 'executing DB command: ' + cmd])
                with ReqTable.rsConn.cursor() as cursor:
                    cursor.execute(cmd)
                # The cursor has been closed, but the transaction has not been committed, as designed.
            except psycopg2.Error as exc:
                import traceback
                
                self.log.writeError([ traceback.format_exc(5) ])
                ReqTable.rsConn.rollback()
                self.log.writeDebug([ 'rolling-back req table DB update' ])
                raise ReqtableWriteException(exc.diag.message_primary)
                
            return True
        else:
            return False
                    
    # This WILL commit changes to the db.
    def updateDbAndCommit(self, requestids=None):
        sql = self.getUpdateDBSql(requestids)
        
        ReqTable.rsDbLock.acquire()
        try:
            if self.updateDB(sql):
                ReqTable.rsConn.commit()
                self.log.writeDebug([ 'committed RS DB changes' ])
            else:
                self.log.writeDebug([ 'no request changes made to DB' ])
        except:
            self.log.writeDebug([ 'rolled-back RS DB changes' ])
            ReqTable.rsConn.rollback()
        finally:
            ReqTable.rsDbLock.release()

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes. Do not call rsConn.commit().
    def deleteDB(self, requestids):
        if len(requestids) > 0:
            for arequestid in requestids:
                requestidStr = str(requestid)
                
                if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                    raise UnknownRequestidException('No request-table record exists for ID ' + requestidStr + '.')

                del self.reqDict[requestidStr]
            
            reqidLstStr = ','.join(requestids)
            
            cmd = 'DELETE FROM ' + self.tableName + ' WHERE requestid=' + reqidLstStr
            
            needsRollback = True
            try:
                gotRsDbLock = ReqTable.rsDbLock.acquire()
                if gotRsDbLock:
                    with ReqTable.rsConn.cursor() as cursor:
                        cursor.execute(cmd)
                    needsRollback = False
                    # The cursor has been closed, but the transaction has not been committed, as designed.
            except psycopg2.Error as exc:
                raise ReqtableWriteException(exc.diag.message_primary + ': ' + cmd)
            finally:
                if needsRollback:
                    ReqTable.rsConn.rollback()
                if gotRsDbLock:
                    ReqTable.rsDbLock.release()

    def setStatus(self, requestids, code, msg=None):
        for arequestid in requestids:
            requestidStr = str(arequestid)
        
            if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                raise UnknownRequestidException('No request-table record exists for ID ' + requestidStr + '.')
            
            self.reqDict[requestidStr]['status'] = code
            if msg:
                self.reqDict[requestidStr]['errmsg'] = msg
            else:
                self.reqDict[requestidStr]['errmsg'] = ''
            
            # Set dirty flag
            self.reqDict[requestidStr]['dirty'] = True

    def get(self, requestids=None):
        toRet = []
    
        if not requestids:
            return list(self.reqDict.values())
        
        for arequestid in requestids:
            requestidStr = str(arequestid)
            
            if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                raise UnknownRequestidException('No request-table record exists for ID ' + requestidStr + '.')
    
            toRet.append(self.reqDict[requestidStr])
    
        return toRet        
    
    def getPending(self):
        pendLst = []

        for requestidStr, reqObj in self.reqDict.items():
            if reqObj['status'] == 'P':
                pendLst.append(reqObj)

        # Sort by start time. Sorts in place - and returns None.
        pendLst.sort(key=lambda dict : dict['starttime'].strftime('%Y-%m-%d %T'))
    
        return pendLst
    
    def getNew(self):
        newLst = []                
                
        for requestidStr, reqObj in self.reqDict.items():
            if reqObj['status'] == 'N':
                newLst.append(reqObj) # reqObj is a dictionary

        # sort by request (priority, start-time), in place
        newLst.sort(key=ReqTable.sortByPriorityAndTime)
        return newLst

    def getDelete(self):
        deleteLst = []
                
        for requestidStr, reqObj in self.reqDict.items():
            if reqObj['status'] == 'D':
                deleteLst.append(reqObj)
                
        deleteLst.sort(key=lambda dict : dict['requestid'])

        return deleteLst

    def getTimeout(self):
        return self.timeOut
    
    @classmethod
    def sortByPriorityAndTime(cls, requestDict):
        # return tuple (priority-index, start-time)
        return (dict(zip(REQTYPE_TEXT, list(range(len(REQTYPE_TEXT)))))[requestDict['type']], requestDict['starttime'].strftime('%Y-%m-%d %T'))


# The site information is stored in a public database table at Stanford. It is accessible by all remote sites
# with the rssites.sh cgi. To obtain information about all sites, the rssites.sh cgi is called with no parameters.
# Otherwise, information about a single site can be obtained by by providing the site name to the 'site' argument.
# The information is stored in drms.rs_sites on hmidb.
class SiteTable:
    def __init__(self, url, log):
        self.url = url # rssites.sh URL
        self.log = log
        self.siteDict = {} # Keyed by name.
        self.siteMap = {} # Map from str(code) to name.

    def read(self):
        natt = 0
        while True:
            try:
                self.log.writeDebug([ 'opening URL ' + self.url ])
                with urllib.request.urlopen(self.url) as response:
                    siteInfoStr = response.read().decode('UTF-8')
                    natt = 0
                break
            except urllib.error.URLError as exc:
                # we want to try again, until we time-out
                natt += 1
                if natt > 2:
                    raise SitetableReadException("unable to access URL " + self.url)
                if type(exc.response) is str:
                    msg = exc.response
                else:
                    msg = ''
                log.writeWarning([ 'failed to access site-table URL (' + self.url + '); trying again.' ])
                time.sleep(1)

        # siteInfoStr is a string, that happens to be json.
        siteInfo = json.loads(siteInfoStr)
        
        if siteInfo['status'] != 'success':
            raise SitetableReadException("Failure calling cgi '" + self.url + "'.")

        # siteInfo is a dictionary, keyed by site name. Each dictionary entry is a dictionay, with two keys: code and baseurl.
        for asite, info in siteInfo.items():
            if asite == 'status':
                # Skip status.
                continue
            self.siteDict[asite] = {}
            self.siteDict[asite]['name'] = asite
            self.siteDict[asite]['code'] = info['code']
            self.siteDict[asite]['baseurl'] = info['baseurl']
            self.siteDict[asite]['cgi-supath'] = info['cgi-supath']
            self.siteMap[str(self.siteDict[asite]['code'])] = asite

            self.log.writeInfo([ 'Reading site info for ' + asite + ': code => ' + str(self.siteDict[asite]['code']) + ', baseurl => ' + self.siteDict[asite]['baseurl'] + ', cgi-supath => ' + self.siteDict[asite]['cgi-supath'] ])

    def tryRead(self):
        nAtts = 0
        while True:
            try:
                self.read()
                break
            except SitetableReadException:
                if nAtts > 10:
                    raise # Re-raise

            nAtts += 1
            time.sleep(1)

    @staticmethod
    def getCode(sunum):
        code = sunum >> 48
        if code & 0xC000 != 0:
            raise InvalidSunumException('The site-code value of SUNUM ' + sunum + ' is out of range (valid range is 0 to 16383).')

        return code

    def getBaseURL(self, sunum):
        code = SiteTable.getCode(sunum)
        
        if not str(code) in self.siteMap or not self.siteMap[str(code)]:
            raise UnknownSitecodeException('There is no site in the site table for code ' + str(code) + '.')
        
        name = self.siteMap[str(code)]
        url = self.siteDict[name]['baseurl']
        return url
        
    def getSuPathCGI(self, sunum):
        code = SiteTable.getCode(sunum)
        
        if not str(code) in self.siteMap or not self.siteMap[str(code)]:
            raise UnknownSitecodeException('There is no site in the site table for code ' + str(code) + '.')

        name = self.siteMap[str(code)]
        url = urllib.parse.urljoin(self.siteDict[name]['baseurl'], self.siteDict[name]['cgi-supath'])
        return url
    
    
class Chunker(object):
    def __init__(self, list, chSize):
        self.chunks = []
        iChunk = -1
        nElem = 1
        
        for elem in list:
            if iChunk == -1 or nElem % chSize == 0:
                iChunk += 1
                self.chunks.append([])
    
            self.chunks[iChunk].append(elem)
            nElem += 1
    
    def __iter__(self):
        return self.iterate()
    
    # Iterate through chunks.
    def iterate(self):
        i = 0
        while i < len(self.chunks):
            yield self.chunks[i]
            i += 1
            
class ScpWorker(threading.Thread):
    tList = [] # A list of running thread IDs.
    maxThreads = 64
    scpNeeded = threading.Event() # event fired by main when a Downloader thread has changed the state of an SU from 'P' to 'W'
    lock = threading.Lock() # Guard tList.
    
    def __init__(self, **kwargs):
        threading.Thread.__init__(self)
        self.id = kwargs['id']
        self.suTable = kwargs['sutable']
        self.tmpdir = kwargs['tmpdir']
        self.maxsus = kwargs['maxsus']
        self.maxpayload = kwargs['maxpayload']
        self.scptimeout = kwargs['scptimeout']
        self.priority = kwargs['priority']
        self.log = kwargs['log']
        self.sdEvent = threading.Event()

    def run(self):
        gotSULock = False
        doDownload = False
        lastDownloadTime = None
        
        self.log.writeDebug([ 'running ScpWorker ' + str(self.id) ])

        try:
            # the finally clause ensures that this thread will remove itself from the static list of threads
            # before it terminates
            while not self.sdEvent.isSet():
                sunums = []
                paths = []

                # Look for an SU whose status is 'W' (which means that a Downloader thread is requesting an ScpWorker thread perform a 
                # download for it). If we find one, set status to 'D' and download the SU. When the download is complete, set the status
                # to 'F' so the requesting Downloader thread can clean-up and set the status to 'C' for the main thread to handle

                # we need to access the reqtable's reqDict in getNextNWorkingSUs(), so we lock it here; then we need to access
                # the sutable's suMap dict in getNextNWorkingSUs(), so we lock the su table in getNextNWorkingSUs(); since
                # we need to modify SUs here, we do not release the su table lock in getNextNWorkingSUs(); after we release
                # the su table lock here, we then release the reqtable lock
                #
                # ALWAYS acquire the reqtable lock before the sutable lock to avoid deadlock
                self.suTable.reqtable.acquireLock()
                try:
                    # acquires SU table lock
                    (workingSUs, (user, host, port)) = self.suTable.getNextNWorkingSUs(self.id, self.maxsus, self.priority)
                    try:
                        # no SU in workingSUs can have errored out at this point
                        susToDownload = []
                        doDownload = False
                        numSUs = len(workingSUs)
                        payload = sum([ su.suSize for su in workingSUs ])
                        currentTime = datetime.now(timezone.utc)

                        if numSUs > 0:
                            self.log.writeDebug([ 'examining ' + str(numSUs) + ' working SUs' ])
                            doDownload = payload > self.maxpayload or numSUs == self.maxsus
                    
                            # Now we need to modify workingSUs if the payload would be too large, or there would be too many SUs for this scp.
                            payload = 0
                            numSUs = 0
                            for su in workingSUs:
                                if (payload + su.suSize > self.maxpayload and numSUs > 0) or numSUs + 1 > self.maxsus:
                                    break
                        
                                susToDownload.append(su)
                                payload += su.suSize
                                numSUs += 1                    
                    
                            self.log.writeDebug([ 'doDownload calc (payload, maxPayLoadSUs, numSUs, maxNumSUs, currentTime, lastDownloadTime, scpTimeOut): ' + str(payload) + ',' + str(self.maxpayload) + ',' + str(numSUs) + ',' + str(self.maxsus) + ',' + str(currentTime) + ',' + str(lastDownloadTime) + ',' + str(self.scptimeout) + ')' ])

                            if doDownload:                            
                                # Set lastDownloadTime. We will keep setting this, until we complete the scp - that is the best place to
                                # set it, but errors before that could cause us to not set it.
                                lastDownloadTime = datetime.now(timezone.utc)
                            else:
                                # Now it could be that at least one SU has been waiting a long time. If that is true, then 
                                # do a download.
                                if lastDownloadTime is None:
                                    lastDownloadTime = datetime.now(timezone.utc)
                            
                                # for the highest priority (priority == 0) do not wait for additional SUs to be requested - download now
                                if currentTime - lastDownloadTime > self.scptimeout or self.priority == 0:
                                    doDownload = True
                        else:
                            doDownload = False
                
                        if doDownload:
                            self.log.writeInfo([ 'ScpWorker ' + str(self.id) + ' - Time for a download! Collected ' + str(len(susToDownload)) + ' for download; payload is ' + str(payload) ])
                    
                            # all SUs are locked so no other thread modifies the SUs while we are processing the download
                            for su in susToDownload:                        
                                sunums.append(su.sunum)                            
                                serverPath = su.worker.path
                                if not serverPath:
                                    raise ScpSUException('server SU path is not known')
                                paths.append(serverPath)
                    
                                # Set status to D to prevent another ScpWorker from processing the download. Must do this
                                # before the SU Table lock is released, otherwise another ScpWorker could grab the same
                                # SU that this ScpWorker just grabbed.
                                self.log.writeInfo([ 'ScpWorker setting SU ' + str(su.sunum) + ' status to D' ])
                                su.setStatus('D', None)
                                
                            if len(sunums) == 0:
                                doDownload = False
                    finally:
                        # release SU Table lock - now other ScpWorkers can look for W SUs
                        self.suTable.releaseLock()
                finally:
                    self.suTable.reqtable.releaseLock()

                if doDownload:
                    try:
                        self.log.writeInfo([ 'ScpWorker ' + str(self.id) + ' downloading SUs ' + ','.join([ str(asunum) for asunum in sunums ]) + '.' ])                        

                        # Don't forget to make the temporary directory first.
                        if not os.path.exists(self.tmpdir):
                            self.log.writeInfo([ 'Creating temporary download directory ' + self.tmpdir + '.' ])
                            os.mkdir(self.tmpdir)

                        lastDownloadTime = datetime.now(timezone.utc)
                    
                        cmd = 'scp -r -P ' + port + ' ' + user + '@' + host + ':"' + ' '.join(paths) + '" ' + self.tmpdir
                        self.log.writeInfo([ 'ScpWorker ' + str(self.id) + ' running ' + cmd + '.' ])
                        try:
                            # check_call(cmdList)
                            # The scp process will inherit stdin, stdout, and stderr from this script.
                            # proc = Popen(cmdList, stdout=PIPE, stderr=PIPE)
                            proc = Popen(cmd, shell=True, stdout=PIPE, stderr=PIPE, start_new_session=True)
                        except OSError as exc:
                            import traceback
                            self.log.writeError([ traceback.format_exc(5) ])
                            raise ScpSUException('Cannot run scp command.')
                        except ValueError as exc:
                            import traceback
                            self.log.writeError([ traceback.format_exc(5) ])
                            raise ScpSUException('scp command called with invalid arguments.')

                        # Poll for completion
                        remainingSunums = sunums
                        while True:
                            # The Python documentation is confusing at best. I think we have to look at the proc.returncode attribute
                            # to determine if the child process has completed. None means it hasn't. If the value is not None, then 
                            # the child process has terminated, and the value is the child process's return code.
                            lastDownloadTime = datetime.now(timezone.utc)
                        
                            proc.poll()
                            if proc.returncode is not None:                        
                                # the scp has completed
                                out, err = proc.communicate()
                                self.log.writeInfo([ 'ScpWorker ' + str(self.id) + ' - scp process exited with return code ' + str(proc.returncode) + '.' ])
                                lastDownloadTime = datetime.now(timezone.utc)
                                if proc.returncode != 0:
                                    msg = 'Command "' + cmd + '" returned non-zero status code ' + str(proc.returncode) + '.'
                                    if err is not None:
                                        self.log.writeError([ 'scp stderr msg: ' + err.decode('UTF8') ])
                                    raise ScpSUException(msg)
                                break

                            allTimedOut = True

                            # this locks and releases the SU Table
                            sus, missingSunums = self.suTable.getSUs(sunums=remainingSunums)
                            for su in sus:
                                # check for SU download time-out; we keep doing the download, unless all SUs have timed out
                                timeNow = datetime.now(su.starttime.tzinfo)
                                if timeNow > su.starttime + self.suTable.getTimeout():
                                    self.log.writeInfo([ 'download of SUNUM ' + str(su.sunum) + ' timed-out in ScpWorker' ])
                                    # communicate result to Worker - the Worker will see a D status (and no shutdown event), and know that
                                    # there was a download time-out
                                    remainingSunums.remove(su.sunum)
                                    scpComplete = su.worker.getScpComplete()
                                    with scpComplete:
                                        # class Downloader will see the D, not F, status and know that the download timed-out
                                        # and will set the status to E, download timed-out
                                        scpComplete.notify()
                                else:
                                    allTimedOut = False

                            if self.sdEvent.isSet():
                                # kill the download and also exit the ScpWorker thread.
                                self.log.writeDebug([ 'ScpWorker ' + str(self.id) + ' received sdEvent; killing scp'])
                                proc.kill()

                                try:
                                    proc.communicate(timeout=5)
                                    self.log.writeInfo([ 'successfully killed ScpWorker ' + str(self.id) + ' download' ])
                                except TimeoutExpired:
                                    self.log.writeWarning([ 'unable to kill scp for ScpWorker ' + str(self.id) ])
                                
                                raise ShutDownException('ScpWorker ' + str(self.id) + ' is observing the global shutdown and exiting now')
                        
                            if allTimedOut:
                                # go on to the next set of requested SUs; don't exit the ScpWorker thread
                                proc.kill()
                                raise NoSusForDlException('the downloads of all SUs in the payload have timed-out')

                            time.sleep(1) # In scp process poll loop.
                            # end proc-wait loop

                        # this locks and releases the SU Table
                        sus, missingSunums = self.suTable.getSUs(sunums=remainingSunums)
                        for su in sus:
                            self.log.writeInfo([ 'ScpWorker setting SU ' + str(su.sunum) + ' status to F' ])
                            su.setStatus('F', None)
                            remainingSunums.remove(su.sunum)
                            scpComplete = su.worker.getScpComplete()
                            with scpComplete:
                                scpComplete.notify()

                        self.log.writeInfo([ 'ScpWorker ' + str(self.id) + ' - scp command succeeded for SUs ' + ','.join([ str(asunum) for asunum in sunums ]) ])
                    except ScpSUException as exc:                        
                        # these errors should not cause the ScpWorker thread to exit; set status to 'E'
                        self.log.writeError([ exc.args[0] ])
                        
                        # this locks and releases the SU Table
                        # ALL SUs errored-out
                        sus, missingSunums = self.suTable.getSUs(sunums=sunums)
                        for su in sus:
                            self.log.writeInfo([ 'ScpWorker setting SU ' + str(su.sunum) + ' status to E' ])
                            su.setStatus('E', exc.args[0])
                            remainingSunums.remove(su.sunum)
                            scpComplete = su.worker.getScpComplete()
                            with scpComplete:
                                scpComplete.notify()
                    except NoSusForDlException as exc:
                        # the SU statuses are all D, which tells the Downloaders that all SU downloads timed-out
                        self.log.writeInfo([ exc.args[0] ])
                    except ShutDownException as exc:
                        self.log.writeInfo([ exc.args[0] ])
                        
                        # this locks and releases the SU Table
                        # do not notify Downloaders for SUs that have already timed-out
                        sus, missingSunums = self.suTable.getSUs(sunums=remainingSunums)
                        for su in sus:
                            remainingSunums.remove(su.sunum)
                            scpComplete = su.worker.getScpComplete()
                            with scpComplete:
                                scpComplete.notify()

                        # do not communicate anything back to Downloaders since they will see the shutdown event and 
                        # then check the SU status (which could be D, F, or E)
                else:
                    # There were fewer than scpBatchSize requests for an SU download. Wait for more with ScpWorker.scpNeeded.wait().
                    # Set a timeout so we can gracefully exit if the shutdown event has been triggered (just in case this thread
                    # blocks on wait - when the shutdown happens, the scpNeeded event will be triggered, however).
                
                    # It could be the case that the last Downloader has fired scpNeeded, but there still aren't enough SUs
                    # to trigger a download. If that is the case, then we must let scpNeeded time-out before we do check to see
                    # if it is time to do a download. If the scpNeeded.wait() timeout is long, then we won't check for the 
                    # ScpWorker timeout for a long time, even though the ScpWorker timeout might be short.
                    timeOutToUse = min(self.scptimeout, timedelta(seconds=10))
                
                    try:
                        ScpWorker.scpNeeded.wait(timeOutToUse.total_seconds())
                    except RuntimeError:
                        pass
        finally:
            # This thread is about to terminate. 
            # We need to check the class tList variable to update it, so we need to acquire the lock.
            try:
                ScpWorker.lock.acquire()
                ScpWorker.tList.remove(self) # This thread is no longer one of the running threads.
                self.log.writeInfo([ 'Scp Worker (ID ' +  str(self.id) + ') halted.' ])            
            finally:
                ScpWorker.lock.release()        
        
    # Called from main thread
    def stop(self):
        self.log.writeInfo([ 'Stopping ScpWorker ' + str(self.id) + ' - (it may take 10 seconds for the ScpWorker to stop).' ])
        
        # Fire event to stop thread.
        self.sdEvent.set()
        self.log.writeDebug([ 'Set sdEvent in ScpWorker ' + str(self.id) + '.' ])
        
        # Fire scpNeeded event so that the ScpWorker thread will not block on wait.
        ScpWorker.scpNeeded.set()
    
    @classmethod
    def newThread(cls, **kwargs):
        worker = cls(**kwargs)
        cls.tList.append(worker)
        worker.start()

class DownloaderCompleteQueueItem(object):
    def __init__(self, **kwargs):
        self.su = kwargs['su']

    @classmethod
    def addCompleteQueueItemToQueue(cls, **kwargs):
        su = kwargs['su']
        queue = kwargs['queue']
        log = kwargs['log']

        qItem = cls(su=su)
    
        # no need to hold SU Table lock since the queue implementation handles multi-thread access to the queue
        try:
            queue.put_nowait(qItem) # non-blocking
        except:
            log.writeError([ 'unable to put downloader complete item for SU ' + str(su.sunum) + ' in queue' ])
    

# Downloads a single SU. Ingests it into SUMs (SUMS allows to ingestion of a single SU at a time only.). Updates
# the SU table status for that SU.
# The main thread sets the SU status to 'P'. The Downloader thread sets that status to 'W' to request a ScpWorker
# thread to download the SU. The ScpWorker thread sets the status to 'D' while it is processing the download. When
# the download is complete, the ScpWorker thread sets the status back to 'P'.
class Downloader(threading.Thread):
    sumsConn = None
    sumsDbLock = None # Since all Downloader threads share the same connection, their cursors on these connections
                      # are not isolated. Use a lock to ensure that only one Download is modifying SUMS at one time.

    tList = [] # A list of running thread IDs.
    maxThreads = 16 # Default. Can be overriden with the Downloader.setMaxThreads() method.
    eventMaxThreads = threading.Event() # Event fired when the number of threads decreases.
    lock = threading.Lock() # guard tList

    def __init__(self, **kwargs):
        threading.Thread.__init__(self)
        self.su = kwargs['su']
        self.path = kwargs['path']
        self.suTable = kwargs['sutable']
        self.scpUser = kwargs['scpuser'] # the linux user that has access to the SU
        self.scpHost = kwargs['scphost'] # the machine hosting the SU
        self.scpPort = kwargs['scpport'] # the port on the machine hosting the SU
        self.binPath = kwargs['binpath']
        self.hastapesys = kwargs['hastapesys']
        self.tmpdir = kwargs['tmpdir']
        self.log = kwargs['log']
        self.sunum = self.su.sunum
        self.sdEvent = threading.Event()
        self.scpCompleteLock = threading.RLock()
        self.scpComplete = threading.Condition(self.scpCompleteLock)

    def run(self):
        # Sub-out the download to an ScpWorker instance. To do that, set the SU status to 'W'. The ScpWorker
        # that is used will set the status to 'D' so that no other ScpWorker attempt to download the SU 
        # as well. When the ScpWorker completes the download, it will set the status to 'P' again.        
        suDlPath = None
        sudir = None
        
        setErrorStatus = False
        cleanUpSUDir = False
        
        seriesCached = None
        
        try:        
            # the finally clause will remove this thread from tList; that must happen, else we could 
            # hang on shut-down
            try:
                suStatus = None

                # this SU cannot have been removed from the SU Table at this point; that can only happen
                # after this thread sets the SU status to C or E; so, there is no chance that the SU has been orphaned and
                # there is no need to check for that
                seriesCached = self.su.getSeries()
                
                self.log.writeInfo([ 'Downloader is running for SU ' + str(self.sunum) ])

                if self.su.getStatus() != 'P':
                    raise DownloaderException('SU ' + str(self.sunum) + ' is not pending')
            
                suDlPath = os.path.join(self.tmpdir, 'D' + str(self.sunum))

                scpDlNotified = False
                
                if self.sdEvent.isSet():
                    raise ShutDownException('downloader thread for SU ' + str(self.sunum) + ' is observing the global shutdown and exiting now')

                with self.scpComplete:
                    # Let an ScpWorker thread handle the download. We do that by setting the status to 'W'.
                    # Upon recovery from a daemon shutdown, we may start certain SUs in the W state, in which
                    # case we do not need to set the status to W.
                    self.log.writeInfo([ 'setting SU ' + str(self.sunum) + " status to W" ])

                    # the ScpWorker learns of the source path, the SU size, the scp user, etc., from su.worker
                    self.su.setStatus('W', None)

                    # wake up an ScpWorker
                    ScpWorker.scpNeeded.set()
                    # clear event so that main will block the next time it calls wait
                    ScpWorker.scpNeeded.clear()

                    # wait for the ScpWorker thread to finish downloading the SU; timeout if we have been waiting too long;
                    # the ScpWorker thread itself will check for a download timeout and notify() the Downloader if that happens;
                    # we know a download time happens if the status is D and there was no shut down event (which we just checked above);
                    # no need to check for shutdown event here since the ScpWorker thread will respond to one, killing pending
                    # downloads and notify()ing waiting Downloader threads so that wait() will return
                    if not self.scpComplete.wait(timeout=self.suTable.getTimeout().seconds + 120):
                        self.log.writeWarning([ 'downloader for SU ' + str(self.sunum) + ' timed-out' ])
                        raise DownloaderException('the download of SU ' + str(self.sunum) + ' timed-out')                            
                    else:
                        # download complete (ScpWorker can no longer modify SU obj)
                        pass

                # the download has completed (it is in self.tmpdir), or it has errored-out, or a shut-down is being observed
            
                # if a shut-down is being observed, then the SU status must be W (waiting for scp thread) or F (scp download finished) or 
                # E (error); if there is no shut-down happening, then the status must be F or E.
                suStatus = self.su.getStatus()
                if self.sdEvent.isSet():
                    # normally, we'd raise, but we may have already finished the download; if so, we can ingest into SUMS quickly
                    # before terminating
                    self.log.writeInfo([ 'shutdown happening while downloading SU ' + str(self.sunum) ])
                    # if status == 'F', then go ahead and save the SU in SUMS; below, set status to C; this SU was successfully downloaded
                    # if status == 'E', the download failed, and if status == 'W', then we pretend the download never started (although
                    # it could have started, but got canceled by the shutdown)
                    if suStatus == 'F':
                        self.log.writeInfo([ 'shutdown occurred after ScpWorker successfully downloaded SU ' + str(self.sunum) ])
                    elif suStatus == 'D':
                        # the shutdown event happened while a scp was in progress
                        self.log.writeInfo([ 'shutdown called while download of SU ' + str(self.sunum) + ' was in progress' ])
                        raise ShutDownException('downloader thread for SU ' + str(self.sunum) + ' is observing the global shutdown and exiting now')
                    elif suStatus == 'W':
                        self.log.writeInfo([ 'shutdown called before ScpWorker could download SU ' + str(self.sunum) ])
                        raise ShutDownException('downloader thread for SU ' + str(self.sunum) + ' is observing the global shutdown and exiting now')
                    elif suStatus == 'E':
                        raise DownloaderException('the download of SU ' + str(self.sunum) + ' errored-out')
                    else:
                        # unexpected status
                        raise DownloaderException('unexpected status ' + suStatus + ' for the download of SU ' + str(self.sunum))
                else:
                    # the ScpWorker finished processing the SU download, and that was not due to a shutdown event
                    if suStatus == 'F':
                        self.log.writeInfo([ 'ScpWorker successfully downloaded SU ' + str(self.sunum) ])
                    elif suStatus == 'D':
                        # a download timeout occurred
                        self.log.writeInfo([ 'shutdown called while download of SU ' + str(self.sunum) + ' was in progress' ])
                        raise DownloaderException('the download of SU ' + str(self.sunum) + ' timed-out')
                    elif suStatus == 'E':
                        raise DownloaderException('the download of SU ' + str(self.sunum) + ' errored-out')
                    else:
                        # unexpected status
                        raise DownloaderException('unexpected status ' + suStatus + ' for the download of SU ' + str(self.sunum))

                # At this point, we need to allocate (mkdir) a new SU directory, move the downloaded SU content into this SUDIR, 
                # then commit the newly created SU into SUMS. The previous incarnations of remote-sums-type code all used the SUMS
                # API to achieve the first and last steps. To use the SUMS API, code need to be written in C and it needs to link
                # to the SUMS library. The first remote-sums code did this by running a DRMS module, wherein all three steps were
                # performed. The JMD uses vso_sum_alloc (a DRMS module with access to the SUMS API) to allocate the SU directory, 
                # then it copies the downloaded SU content into the directory, and then it calls vso_sum_put to commit the SU.
                # However, at a high rate of download, the SUMS API seems to have problems, resulting in the vso_sum_alloc and/or
                # vso_sum_put calls to hang for minutes. We have not been able to track down this issue, but it appears to have
                # something to do with either saturation of socket resources and/or RPC resources and/or SUMS queues.
            
                # This script by-passes SUMS altogether to avoid the issues with SUMS and/or DRMS modules hanging under higher load.
                # The first step in by-passing SUMS is to perform the equivalent of the SUM_open() API call. Then we can call the
                # equivalent of the SUM_alloc2() call to allocate a new SU directory, followed by the copying of the download SU
                # content into this new SU directory. Then we can call the equivalent of the SUM_put() API call to commit the 
                # SU, and then we can call the equivalent of the SUM_close() API call to end the SUMS session.
            
                # We need to connect to the SUMS database before we can modify SUMS objects.
                # The DB transaction is NOT in autocommit mode.
                #
                # Do not put a lock around these operations. It takes about 5 to 8 seconds to complete these SUMS DB 
                # operations. If every thread has to acquire and hold this lock for 5 to 8 seconds, throughput will
                # suffer. 
                #
                # And there is no reason to lock these operations. Each Downloader thread
                # operates on a unique set of rows in the SUMS DB tables being modified. The original
                # SUMS maintained a single connection to the SUMS DB. In response to each API function call,
                # SUMS would manipulate the SUMS DB and then it would commit the change. Since each
                # SUMS client makes multiple SUMS API function calls during its run, and SUMS responds to each
                # request as it arrives in its 'inbox', without any regard to sorting by client,
                # the DB manipulations made by clients are interleaved. Therefore, there is no need
                # for one Downloader thread to perform all DB manipulations without interruption from
                # other Downloader threads.
                #
                # The various cursors held by different Downloaders are not isolated (they operate within the same transaction
                # across all Downloader threads), so the following DB manipulations can be interrupted. If an error 
                # happens somewhere in this chain of events, we need to undo the manipulations performed before the
                # error occurred.
                #
                # PG and psycopg2 do not allow multiple concurrent transactions in a single connection. So, I guess
                # we have to serialize each manipulation (by putting a lock around each one).
                with self.sumsConn.cursor() as cursor:
                    allOK = False
                    openDone = False
                    alloc2Done = False
                    putDone = False
                    closeDone = False
                
                    try: 
                        # Put all of this in one transaction. If everything is good, commit the transaction. If an 
                        # exception occurs, roll back.
            
                        ##### SUM_open() port #####
                        try:
                            gotSumsDbLock = self.sumsDbLock.acquire()
                        
                            # This increments the sequence that supplies the sumid and inserts that sumid into the sum_open table.
                            cmd = "SELECT NEXTVAL('public.sum_seq')"
                            cursor.execute(cmd)
                            records = cursor.fetchall()
                            if len(records) != 1:
                                raise SumsAPIException('Unexpected response when fetching sumid from sequence.')
                
                            sumid = records[0][0]

                            currentTimeStr = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            cmd = 'INSERT INTO public.sum_open(sumid, open_date) VALUES (' + str(sumid) + ", '" + currentTimeStr + "')"
                            cursor.execute(cmd)
                            self.sumsConn.commit()
                        finally:
                            if gotSumsDbLock:
                                self.sumsDbLock.release()
                        ##### SUM_open() port - end #####
                        openDone = True
                        self.log.writeInfo([ 'successfully called SUM_open() port for SU ' +  str(self.sunum) ])
                        self.log.writeInfo([ 'sumid is ' + str(sumid) ])
    
                        ##### SUM_alloc2() port #####
                        try:
                            gotSumsDbLock = self.sumsDbLock.acquire()

                            #   First, find a partition that has enough available space for the size of the SU to be downloaded.
                            cmd = 'SELECT PARTN_NAME FROM public.sum_partn_avail WHERE AVAIL_BYTES >= 1024 AND PDS_SET_NUM = 0'
                            cursor.execute(cmd)
                            records = cursor.fetchall()
                            if len(records) < 1:
                                raise SumsAPIException('Cannot allocate a new Storage Unit in SUMS - out of space.')
            
                            partitions = []
                            for rec in records:
                                partitions.append(rec[0])
            
                            #   Second, randomly choose one of the partitions to put the new SU into. We want to spread the write load over available 
                            #   partitions.
                            randIndex = random.randint(0, len(partitions) - 1)
                            partition = partitions[randIndex]
                            sudir = os.path.join(partition, 'D' + str(self.sunum))
                            os.mkdir(sudir)
                            os.chmod(sudir, 0O2755)

                            #   Third, insert a record into the sum_partn_alloc table for this SU. status is DARW, which is 1. effective_date is "0".
                            cmd = "INSERT INTO public.sum_partn_alloc(wd, sumid, status, bytes, effective_date, archive_substatus, group_id, safe_id, ds_index) VALUES ('" + sudir + "', '" + str(sumid) + "', 1, 1024, '0', 0, 0, 0, 0)"
                            cursor.execute(cmd)
                            self.sumsConn.commit()
                        finally:
                            if gotSumsDbLock:
                                self.sumsDbLock.release()
                        ##### SUM_alloc2() port - end #####
                        alloc2Done = True
                        self.log.writeDebug([ 'successfully called SUM_alloc2() for SU ' +  str(self.sunum) ])
            
                        #    Fourth, move the downloaded SU files into the chosen SUMS partition. SUM_alloc2() code calls mkdir, so we cannot
                        #    move the top-level D___ directory into the SUMS partition. Instead we have to move, recursively,  all files and directories in 
                        #    the downloaded D___ directory into the SUMS D___ directory.
                        files = os.listdir(suDlPath)
                        self.log.writeDebug([ 'moving downloaded SU content from ' + suDlPath + ' into allocated SU (' + sudir  + ')' ])

                        try:
                            for afile in files:
                                src = os.path.join(suDlPath, afile)
                                self.log.writeDebug([ 'moving ' + src + ' to ' + sudir ])
                                shutil.move(src, sudir)
                        except shutil.Error as exc: 
                            import traceback
                            self.log.writeError([ traceback.format_exc(5) ])
                            raise RSIOException('Unable to move SU file ' + afile + ' into SUdir ' + sudir + '.')

                        self.log.writeDebug([ 'move of SU ' + str(self.sunum) + ' content succeeded' ])
            
                        ##### SUM_put() port #####
                        try:
                            gotSumsDbLock = self.sumsDbLock.acquire()

                            # The original SUM_put() call called "chmown" to change the ownership of the
                            # files in the SU dir to the SUM_MANAGER. However, this is not necessary since rsumsd.py is run by the 
                            # SUM_MANAGER.
            
                            #   First, chmod all directories to 0755. All regular files get their user/group/other read enabled, and their
                            #   user write enabled, and their group and other write disabled.
                            for root, dirs, files in os.walk(sudir):
                                for adir in dirs:
                                    fullPath = os.path.join(root, adir)
                                    os.chmod(fullPath, 0O0755)
                                for afile in files:
                                    fullPath = os.path.join(root, afile)
                                    st = os.stat(fullPath)
                                    newMod = st.st_mode | stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH | stat.S_IWUSR & ~stat.S_IWGRP & ~stat.S_IWOTH
                                    os.chmod(fullPath, newMod)
                    
                            #   Second, update SUMS sum_main database table - Calculate SU dir number of bytes, set online status to 'Y', set archstatus to 'N', 
                            #   set offsiteack to 'N', set dsname to seriesname, set storagegroup to tapegroup, set storageset to tapegroup / 10000,
                            #   set username to getenv('USER') or nouser if no USER env, set mode to TEMP + TOUCH, set apstatus: if SUMS_TAPE_AVAILABLE ==>
                            #   DAAP (4), else DADP (2), set archsub ==> DAAEDDP (32), set effective_date to tdays in the future (with format "%04d%02d%02d%02d%02d").
                            #   Insert all of this into sum_main.
                            numBytes = os.path.getsize(sudir) + sum([ os.path.getsize(fullPath) for fullPath in [ os.path.join(root, afile) for root, dirs, files in os.walk(sudir) for afile in files ] ]) + sum([ os.path.getsize(fullPath) for fullPath in [ os.path.join(root, adir) for root, dirs, files in os.walk(sudir) for adir in dirs ] ])
                            if self.hastapesys:
                                apStatus = 4 # DAAP
                            else:
                                apStatus = 2 # DADP

                            createDate = datetime.now()
                            createDateStr = createDate.strftime('%Y-%m-%d %H:%M:%S')
                            expDate = self.su.getExpiration()
                            effDate = expDate.strftime('%Y%m%d%H%M')

                            # storage_group is the tape group. It should come from the series definition, but remote sites have been using 0 for years.            
                            cmd = "INSERT INTO public.sum_main(online_loc, online_status, archive_status, offsite_ack, history_comment, owning_series, storage_group, storage_set, bytes, ds_index, create_sumid, creat_date, access_date, username) VALUES ('" + sudir + "', 'Y', 'N', 'N', '', '" + seriesCached + "', 0, 0, " + str(numBytes) + ', ' + str(self.sunum) + ', ' + str(sumid) + ", '" + createDateStr + "', '" + createDateStr + "', '" + os.getenv('USER', 'nouser') + "')"
                            cursor.execute(cmd)

                            self.log.writeDebug([ 'successfully inserted record into sum_main for SU ' + str(self.sunum) ])

                            #    Third, update SUMS sum_partn_alloc table - Insert a new row into sum_partn_alloc for this SU. The SUM_alloc2() port will result in
                            #    a row in sum_partn_alloc with a ds_index of 0, which does not make sense to me. But the SUM_close() port will delete
                            #    that row. By the time this thread terminates, there will be only a single row for this SU in sum_partn_alloc. substatus is DAAEDDP (32).
                            #    But first, delete any existing DADP (delete pending) rows for this sunum if the status of the SU for the new row is DADP.
                            if apStatus == 2:
                                # We do this simply to ensure that we do not have two sum_partn_alloc records with status DADP (delete pending).
                                cmd = 'DELETE FROM public.sum_partn_alloc WHERE ds_index = ' + str(self.sunum) + ' AND STATUS = 2'
                                cursor.execute(cmd)
                                self.log.writeDebug([ 'successfully deleted old DADP record from sum_partn_alloc for SU ' + str(self.sunum) ])
            
                            cmd = "INSERT INTO public.sum_partn_alloc(wd, sumid, status, bytes, effective_date, archive_substatus, group_id, safe_id, ds_index) VALUES ('" + sudir + "', " + str(sumid) + ', ' + str(apStatus) + ', ' + str(numBytes) + ", '" + effDate + "', 32, 0, 0, " + str(self.sunum) + ')'
                            cursor.execute(cmd)
                            self.log.writeDebug([ 'successfully inserted record into sum_partn_alloc for SU ' + str(self.sunum) ])
                            self.sumsConn.commit()
                        finally:
                            if gotSumsDbLock:
                                self.sumsDbLock.release()
                        ##### SUM_put() port - end #####
                        putDone = True
                        self.log.writeDebug([ 'successfully called SUM_put() for SU ' + str(self.sunum) ])
            
                        ##### SUM_close() port #####
                        try:
                            gotSumsDbLock = self.sumsDbLock.acquire()

                            # Delete sum_partn_alloc records for read-only partitions (status == 8) and read-write partitions (status == 1).
                            cmd = 'DELETE FROM public.sum_partn_alloc WHERE sumid = ' + str(sumid) + ' AND (status = 8 OR status = 1)'
                            cursor.execute(cmd)
                            self.log.writeDebug([ 'successfully deleted read-only and read-write records from sum_partn_alloc for SU ' + str(self.sunum) ])
            
                            # Delete the temporary ds_index = 0 records created during the SUM_put() port. I still do not know why this record
                            # was created in the first place.
                            cmd = 'DELETE FROM public.sum_open WHERE sumid = ' + str(sumid)
                            cursor.execute(cmd)
                            self.sumsConn.commit()
                        finally:
                            if gotSumsDbLock:
                                self.sumsDbLock.release()

                        ##### SUM_close() port - end #####
                        closeDone = True
                        self.log.writeDebug([ 'successfully called SUM_close() for SU ' + str(self.sunum) ])
                        self.log.writeDebug([ 'successfully deleted temporary (ds_index == 0) records from sum_open for SU ' + str(self.sunum) ])
                    
                        allOK = True
                    except psycopg2.Error as exc:
                        # Handle database-command errors. These are all due to problems communicating with the SUMS db.
            
                        # Clean-up
                        if os.path.exists(sudir):
                            shutil.rmtree(sudir)
                        if os.path.exists(suDlPath):
                            shutil.rmtree(suDlPath)
                        raise SumsAPIException(exc.diag.message_primary + ': ' + cmd + '.') 
                    except Exception as exc:
                        # Clean-up
                        if os.path.exists(sudir):
                            shutil.rmtree(sudir)
                        if os.path.exists(suDlPath):
                            shutil.rmtree(suDlPath)
                        raise
                    finally:
                        # the cursor still exists
                        if not allOK:
                            # undo manipulations that were successfully performed; these could raise, in which
                            # case we've done the best we can; let the enclosing exception handler set the
                            # download status for this SU to error
                            if openDone:
                                cmd = 'DELETE FROM public.sum_open WHERE sumid = ' + str(sumid)
                                cursor.execute(cmd)
                            if alloc2Done:
                                cmd = "DELETE FROM public.sum_partn_alloc WHERE wd = '" + sudir + "'"
                                cursor.execute(cmd)
                            if putDone:
                                # if putDone, then alloc2Done, so the record was already deleted from sum_partn_alloc; don't
                                # do that here.
                                cmd = 'DELETE FROM public.sum_main WHERE ds_index = ' + str(self.sunum)
                                cursor.execute(cmd)
                            if closeDone:
                                # nothing to clean up if close succeeds
                                pass

                # Remove temporary directory.
                self.log.writeDebug([ 'removing empty temporary download directory ' + suDlPath ])
                try:
                    if os.path.exists(suDlPath):
                        shutil.rmtree(suDlPath)
                except OSError as exc:
                    raise RSIOException(exc.strerror)
           
                self.log.writeDebug([ 'removal of temporary directory ' + suDlPath + ' succeeded' ])
                self.log.writeDebug([ 'downloader for SU ' + str(self.sunum) + ' terminating; unsetting worker' ])
                self.su.removeWorker()
                self.log.writeDebug([ 'setting SU ' + str(self.sunum) + ' status to complete' ])
                self.su.setStatus('C', None)
            except ShutDownException as exc:
                # the status can be P, W, or D here - we should set it to E since the download never completed
                msg = [ exc.args[0] ]
                setErrorStatus = True
                cleanUpSUDir = True
            except DownloaderException as exc:
                # we have not yet set an appropriate status - this should always be E 
                msg = [ exc.args[0] ]
                setErrorStatus = True
                cleanUpSUDir = True
            except RemoteSumsException as exc:
                import traceback

                msg = [ exc.args[0], traceback.format_exc(5) ]
                setErrorStatus = True
                cleanUpSUDir = True
            except Exception as exc:
                # catch all remaining exceptions
                import traceback

                msg = [ 'Unknown exception.', traceback.format_exc(5) ]
                setErrorStatus = True
                cleanUpSUDir = True

            # if this code raises, the outer-most finally clause will execute, removing this thread from the
            # tList
            if setErrorStatus:
                # set SU status to E
                self.log.writeError([ 'setting SU ' + str(self.sunum) + ' status to E' ])
                self.log.writeError(msg)
                self.su.setStatus('E', msg[0]) # do not put traceback strings into DB (weird chars in tracebacks mess things up)

            if cleanUpSUDir:                
                # Must clean-up SU dir and the downloaded files.
                if sudir and os.path.exists(sudir):
                    shutil.rmtree(sudir)
                if suDlPath and os.path.exists(suDlPath):
                    shutil.rmtree(suDlPath)            
        finally:
            # this thread is about to terminate

            # no need to acquire the SU Table lock since the status is accessed by exactly one thread at a time
            DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=self.su, queue=self.suTable.queue, log=self.log)
            self.log.writeDebug([ 'downloader (' + str(self.sunum) + ') successfully added a DownloaderCompleteQueueItem' ])

            # We need to check the class tList variable to update it, so we need to acquire the lock.
            try:
                self.lock.acquire()

                self.log.writeDebug([ 'downloader for SU ' + str(self.sunum) + ' terminating; unsetting worker' ])
                self.su.removeWorker()
                
                self.tList.remove(self) # This thread is no longer one of the running threads.
                self.log.writeInfo([ 'downloader (SUNUM ' + str(self.sunum) + ') halted' ])
                # Use <= because we don't know if we were able to reach Downloader.maxThreads thread running due 
                # to system-resource limitations.
                if len(self.tList) <= self.maxThreads - 1:
                    # Fire event so that main thread can add new SUs to the download queue.
                    self.log.writeDebug([ 'OK to start new download threads' ])
                    self.eventMaxThreads.set()
                    # Clear event so that main will block the next time it calls wait.
                    self.eventMaxThreads.clear()
            finally:
                self.lock.release()

    def getScpComplete(self):
        return self.scpComplete

    # called from main thread only
    def stop(self):
        self.log.writeInfo([ 'stopping Downloader (SUNUM ' + str(self.sunum) + '). It may take 10 seconds for Downloader to stop' ])
        
        # Fire event to stop thread.
        self.sdEvent.set()

    # the Dispatcher calls newThread() and it is holding the table lock (must hold table lock so that there is no contention among 
    # the different dispatchers (which call queue.put()) and the main thread (which calls queue.get());
    # must acquire Downloader lock BEFORE calling newThread() since newThread() will append to tList (the Downloader threads will delete from tList as they complete).
    @classmethod
    def newThread(cls, **kwargs):
        dl = cls(**kwargs)
        su = kwargs['su']

        try:
            su.setWorker(dl)
            cls.tList.append(dl)
            dl.start()
        except (RuntimeError, Exception) as exc:
            # cannot start a new thread, so rollback and re-raise so the calling thread can handle the error
            if dl in cls.tList:
                cls.tList.remove(dl) # error if dl does not exist in list
            su.removeWorker() # noop if SU has no worker

            if isinstance(exc, RuntimeError):
                raise StartThreadException('cannot start a new ' + dl.downloaderType.__name__ + ' thread due to system resource limitations')
            else:
                import traceback
                raise StartThreadException(traceback.format_exc(5))

    @classmethod
    def setMaxThreads(cls, maxThreads):
        cls.maxThreads = maxThreads


class HighPriorityDownloader(Downloader):
    '''
    there are only two priorities - a low-priority downloader (class Downloader), and a high-priority downloader (class HighPriorityDownloader);
    the two types of downloaders really have their own set of downloader threads; 
    '''
    tList = [] # a list of running thread IDs
    maxThreads = 16
    eventMaxThreads = threading.Event() # Event fired when the number of threads decreases.
    lock = threading.Lock() # Guard tList.
    
    def __init__(self, **kwargs):
        super(HighPriorityDownloader, self).__init__(**kwargs)
            
def readTables(requests, sites):
    if requests:
        requests.tryRead()
    
    if sites:
        sites.tryRead()
        
# series (text) - name of the series whose retention 
# request (ReqTable::reqDict[requestidStr] object) - Contains the dbhost, dbport, dbname that identifies the
#    database that contains the series.

def getSeriesInfo(series, dbuser, dbname, dbhost, dbport, log, **kwargs):
    default = kwargs['default']

    # get the expiration from the db; we have the host/port/dbname information from the request
    newSuRetention = -1
    ns, tab = series.split('.')

    try:
        # We need to get information from the DRMS database, which might not be the same database as the remote SUMS database.
        # The class variable ReqTable.rsConn is the connection to the remote SUMS database.
        with psycopg2.connect(user=dbuser, database=dbname, host=dbhost, port=dbport) as conn:
            with conn.cursor() as cursor:
                # We want the new-SU retention too, not the staging retention. So extract the bottom 15 bits.
                cmd = "SELECT retention & x'00007FFF'::int AS retention, archive, tapegroup FROM " + ns + ".drms_series WHERE lower(seriesname) = '" + series.lower() + "'"
                log.writeDebug(['obtaining series info for series ' + series + ': ' + cmd])

                try:
                    cursor.execute(cmd)
                    if cursor.rowcount == 0:
                        # series does not exist - use defaults
                        expiration, archive, tapegroup = default
                        log.writeDebug([ 'series ' + series + ' does not exist; using defaults' ])

                    row = cursor.fetchone()
                    expiration, archive, tapegroup = (datetime.now() + timedelta(days=row[0]), row[1] == 1, row[2])
                    log.writeDebug([ 'info for series ' + series + ' (expiration, archive, tapegroup): ' + expiration.strftime("%Y-%m-%d") + str(archive) + str(tapegroup) ])
                except psycopg2.Error as exc:
                    # Handle database-command errors.
                    log.writeDebug([ 'error executing DB command ', exc.diag.message_primary, ' using defaults' ])
                    expiration, archive, tapegroup = default
                except Exception as exc:
                    log.writeDebug([ 'error executing DB command ', exc.diag.message_primary,  'using defaults' ])
                    expiration, archive, tapegroup = default
        # The connection is read-only, so there is not need to commit a transaction.
    except psycopg2.DatabaseError as exc:
        # Closes the cursor and connection

        # Man, there is no way to get an error message from any exception object that will provide any information why
        # the connection failed.
        msg = 'unable to connect to the database (no, I do not know why)'
        raise GetSeriesInfoException(msg)

    return (expiration, archive, tapegroup)

class DispatcherQueueItem(object):
    def __init__(self, **kwargs):
        # cgi - the cgi-supath URL (e.g., http://jsoc.stanford.edu/cgi-bin) from which SU paths can be obtained.
        # sunums - a list of sorted SUNUMs to download.
        # sutable - the SU table object that represents the SU database table.
        # dbuser - the DB user that rsumsd.py connects as
        # request - ReqTable::dict[requestidStr] object.
        # binPath - the local path to the binaries needed to ingest the downloaded SU into SUMS. This is mostly likely the path to
        #           the DRMS binaries (one binary needed is vso_sum_alloc)
        # hastapesys - does the DRMS have a tape system
        # tmpdir - the directory to which SUs are temporarily downloaded
        # log - the log to write messages to.
        self.cgi = kwargs['cgi']
        self.sunums = kwargs['sunums']
        self.sutable = kwargs['sutable']
        self.dbuser = kwargs['dbuser']
        self.reqtable = kwargs['reqtable']
        request = kwargs['request']
        if request:
            self.requestID = request['requestid']
            self.reqtype = request['type']
            self.dbname = request['dbname']
            self.dbhost = request['dbhost']
            self.dbport = request['dbport']
        self.binpath = kwargs['binpath']
        self.hastapesys = kwargs['hastapesys']
        self.tmpdir = kwargs['tmpdir']
        self.expiration = kwargs['expiration']
        self.archive = kwargs['archive']
        self.tapegroup = kwargs['tapegroup']
        
        if 'lastitem' in kwargs:
            self.lastitem = kwargs['lastitem']
        else:
            self.lastitem = False
        self.log = kwargs['log']
        
        self.queued = False # gets set to True when the item is put on the dispatcher queue

class Dispatcher(threading.Thread):
    '''
    starts a Downloader for each SU in the sunums list; the SUs all originate from one site
    '''
    tList = [] # a list of running thread IDs
    reqTypeMap = {}
    lock = threading.Lock() # guard tList
    
    def __init__(self, **kwargs):
        threading.Thread.__init__(self, target=self.processRequest)
        self.name = kwargs['name']
        self.log = kwargs['log']
        self.downloaderType = kwargs['downloaderType']
        self.queue = Queue(16) # non-blocking, one per Dispatcher instance

    def processRequest(self):
        # process offline SUs
        try:
            queueItem = None
            while True:
                # pop a DispatcherQueueItem from the queue; OK to block waiting because if no item is in the queue, there
                # is nothing to do, and there is no need to check on a shutdown periodically; a shutdown will put a
                # termination item in the queue
                queueItem = self.queue.get()
                    
                if queueItem.lastitem:
                    # shutdown
                    self.queue.task_done()
                    break

                requestID = queueItem.requestID

                # process the SUs for the source site represented by its url
                workingSus = {}
                hasDownloader = []

                try:
                    # the sunums in queueItem all have an SU object (created in dispatchSU()), and they have never had a 
                    # Worker created for them
                    sus, missingSunums = queueItem.sutable.getSUs(releaseTableLock=False, sunums=queueItem.sunums)
                    try:
                        workingSus = dict([ [ str(su.sunum), su ] for su in sus ])
                    finally:
                        # no longer need SU table lock
                        queueItem.sutable.releaseLock()
                    
                    if len(workingSus) > 0:
                        # workingSus are the SUs whose URLs are not known
                        # it may be that rs.sh has been open for all SUs in this request - if so, skip getting their paths again
                        sunumLst = ','.join(list(workingSus.keys()))
                        values = { 'requestid' : 'none', 'sunums' : sunumLst, 'N' : 1 }
                        data = urllib.parse.urlencode(values)
                        url = queueItem.cgi + '?' + data

                        try:
                            self.log.writeDebug([ 'requesting paths for SUNUMs ' + sunumLst + '; URL is ' + url ])
                            with urllib.request.urlopen(url) as response:    
                                dlInfoStr = response.read().decode('UTF-8')
                        except urllib.error.URLError as exc:
                            if type(exc.response) is str:
                                msg = exc.response
                            else:
                                msg = ''
                            self.log.writeWarning([ 'unable to obtain SU info from provider (' + msg + ')' ])
                            raise SUPathCGIException(msg)

                        dlInfo = json.loads(dlInfoStr)
    
                        if dlInfo['status'] == 'complete':
                            # All of the requested SUs are online at the providing site.
                            paths = dlInfo['paths']

                            # Start a download for each SU. If we cannot start the download for any reason, then set the SU status to 'E'.
                            infos = {}
                            for (sunum, path, series, suSize) in paths:
                                skip = False

                                try:
                                    su = workingSus[str(sunum)]
                                except KeyError:
                                    self.log.writeWarning([ 'SUNUM ' + str(sunum) + ' returned by SU-path CGI is not recognized; skipping' ])
                                    # can't set status since there is no su
                                    skip = True

                                if not skip:
                                    if path is None:
                                        # A path of None means that the SUNUM was invalid. We want to set the SU status to 'E'.
                                        msg = 'SU ' + str(sunum) + ' is not valid at the providing site'
                                        su.setStatus('E', msg)
                                        self.log.writeWarning([ msg ])
                                        skip = True
                                    elif path == '':
                                        # An empty-string path means that the SUNUM was valid, but that the SU referred to was offline (it may or
                                        # may be archived). Regardless, RS will not attempt to perform an export request to obtain the path.
                                        # ART - I need to figure out how to place the SUNUM in SUMS so that its archive flag is N (not archived).
                                        msg = 'SU ' + str(sunum) + ' refers to an SU that is valid at the providing site, but it is offline and cannot be downloaded'
                                        su.setStatus('C', msg)
                                        self.log.writeWarning([ msg ])
                                        skip = True

                                if not skip:
                                    if suSize is None:
                                        suSize = 0

                                    if series in infos:
                                        expiration, archive, tapegroup = infos[series]
                                    else:
                                        # request provides the host, port, and dbname to use with jsoc_info to fetch the retention value
                                        try:
                                            if queueItem.hastapesys:
                                                tapegroup = queueItem.tapegroup
                                            else:
                                                tapegroup = 0

                                            default = (queueItem.expiration, queueItem.archive, tapegroup)
                                            infos[series] = getSeriesInfo(series, queueItem.dbuser, queueItem.dbname, queueItem.dbhost, queueItem.dbport, self.log, default=default) 
                                            expiration, archive, tapegroup = infos[series]                                            
                                        except GetSeriesInfoException as exc:
                                            self.log.writeError([ exc.args[0] ])
                                            su.setStatus('E', 'unable to get series info for series ' + series)
                                            # no need to acquire the SU Table lock since the status is accessed by exactly one thread at a time
                                            skip = True

                                if skip:
                                    su.setStatus('E', 'providing site cannot provide an SU path')
                                    continue

                                # save series and expiration
                                su.setSeries(series)
                                su.setExpiration(expiration)
                                su.setArchive(archive)
                                su.setTapegroup(tapegroup)
                                su.setSize(suSize)
                    
                                # either HighPriorityDownloader or Downloader
                                # cls = dict(zip(REQTYPE_TEXT, [ globals()[dcls] for dcls in REQTYPE_DOWNLOADER ]))[request.reqtype]

                                # ok to stop the Dispatcher here - it can't really do anything if there are no Downloaders available; 
                                # and if the main thread adds new requests, they will go into the Dispatcher queue
                                # if we are saturated with downloads, wait here while the Downloader threads complete;
                                # if Remote SUMS is shutting down, then we'll break out of the enclosing loops
                                # ok to hold SU lock too - the only other threads trying to obtain the SU lock are the Scp Workers, and they
                                # do not block on the lock (if they cannot acquire lock immediately, they skip the SU)
                                while True:
                                    self.downloaderType.lock.acquire()
                                    try:                                    
                                        if len(self.downloaderType.tList) < self.downloaderType.maxThreads:
                                            self.log.writeInfo([ 'instantiating a ' + self.downloaderType.__name__ + ' for SU ' + str(su.sunum) ])

                                            # assign new worker to su
                                            self.downloaderType.newThread(su=su, path=path, sutable=queueItem.sutable, scpuser=dlInfo['scpUser'], scphost=dlInfo['scpHost'], scpport=dlInfo['scpPort'], binpath=queueItem.binpath, hastapesys=queueItem.hastapesys, tmpdir=queueItem.tmpdir, log=self.log)
                                            break
                                    except StartThreadException as exc:
                                        self.log.writeError([ exc.args[0] ])
                                        # ran out of system resources - could not start new thread. Just wait for a thread slot to become free

                                        # do not remove su-->request map item since we need that info in the main thread to properly
                                        # update the request's complete attribute                                    
                                    finally:
                                        self.downloaderType.lock.release()

                                    self.log.writeDebug([ 'Dispatcher thread waiting for thread slot for SU ' + str(su.sunum) ])
                                    self.downloaderType.eventMaxThreads.wait()
                                    # we woke up, but we do not know if there are any open threads in the thread pool; loop and check
                                    # tList again
                                
                                # we successfully started a Downloader for this SU
                                hasDownloader.append(su.sunum)
                            # end loop over SUs                        
                        elif dlInfo['status'] == 'pending':
                            # one or more of the requested SUs is offline; this can no longer happen (rs.sh is called
                            # with the N=1 argument now)!! Do not perform an export request!; there are a limited number ofexport-request 
                            # slots (at the JSOC); since a request for an offline SU entails an asynchronous tape read, performing these requests, 
                            # making a request for a large number of SUs could saturate the export system for days;
                            # log an error if we get here.
                            self.log.writeInfo([ 'request includes one or more SUs that are offline at the providing site; an export request was started to put them online' ])
                            for sunumStr, su in workingSus.items():
                                su.setStatus('E', 'an export request was started - this is no longer allowed')
                        else:
                            # error of some kind
                            # update the SU-table status of the SUs to 'E'
                            for sunumStr, su in workingSus.items():
                                su.setStatus('E', 'unable to obtain paths from providing site; ' + dlInfo['statusMsg'])
                except RemoteSumsException as exc:
                    # there was a problem with this queue item; the finally statement will call task_done(), and then we go on to the
                    # next queue item
                    self.log.writeWarning([ exc.msg ])

                    for sunumStr, su in workingSus.items():
                        su.setStatus('E', 'exception ' + exc.__class__.__name__ + ' in dispatcher')
                except ValueError: # it would be better to use JSONDecodeError, but that is not available till Py 3.5
                    self.log.writeWarning([ 'improperly formatted JSON in response to ' + url ])
                    
                    for sunumStr, su in workingSus.items():
                        su.setStatus('E', 'improperly formatted JSON in response')
                # all other exceptions are fatal and should raise, terminating the dispatcher thread
                finally:
                    for sunumStr, su in workingSus.items():
                        if su.sunum not in hasDownloader:
                            DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=su, queue=queueItem.sutable.queue, log=self.log)
                            self.log.writeDebug([ '[ processRequest() ] (failed to start Worker) successfully added a DownloaderCompleteQueueItem for SU ' +  str(su.sunum)])
                
                    self.queue.task_done()
            # end of while loop over queue item; thread is terminating
        finally:
            # this thread is about to terminate; we need to check the class tList variable to update it, so we need to acquire the lock
            Dispatcher.lock.acquire()
            try:
                Dispatcher.tList.remove(self) # this thread is no longer one of the running threads.
                self.log.writeInfo([ 'Dispatcher ' + self.name + ' halted' ])            
            finally:
                Dispatcher.lock.release()

    @classmethod
    def getDispatcher(cls, reqtype):
        dispType = dict(zip(REQTYPE_TEXT, [ globals()[dcls] for dcls in REQTYPE_DOWNLOADER ]))[reqtype]
        return cls.reqTypeMap[dispType.__name__]

    # called from the main thread only
    @classmethod
    def addSUChunk(cls, **kwargs):
        reqtable = kwargs['reqtable']
        sutable = kwargs['sutable']
        request = kwargs['request']
        log = kwargs['log']
        item = DispatcherQueueItem(**kwargs)
        
        # must create SU objects before placing the item in the dispatcher queue, otherwise dispatcher thread will not
        # find them, which is necessary for it to request paths and create a Downloader thread;
        # create a new SU object for each sunum sent to the dispatcher thread; addSUs() locks/releases SU table
        sutable.acquireLock()
        try:
            # since we have the SU Table lock, if we cannot put the item on the dispatcher queue, 
            # we can rollback the changes to the SU Map and the SU Table sudict
            allSUs = []
            existingSUs, newSUs = sutable.addSUs(sunums=item.sunums, locktable=False)
            log.writeDebug([ '[ addSUChunk() ] successfully inserted new SU objects ' + ','.join([ str(sunum) for sunum in item.sunums ]) ])
            allSUs.extend(existingSUs)
            allSUs.extend(newSUs)
        
            # we also have to add to the SU map before sending to the dispatcher thread
            sutable.addRequestToSUMap(sunums=item.sunums, requestid=request['requestid'])
            log.writeDebug([ '[ addSUChunk() ] successfully added ' + str(request['requestid']) + ' to suMap for SUs ' + ','.join([ str(sunum) for sunum in item.sunums ]) ])
        
            dispatcher = cls.getDispatcher(item.reqtype)

            try:
                # add to the queue - the call will NOT block if queue is full; this allows caller to try again later
                dispatcher.queue.put_nowait(item)
                item.queued = True
            except Full:
                log.writeWarning([ 'cannot add Request to Dispatcher queue - it is full; request ' + str(request['requestid']) + ', unable to add SU chunk: ' + ','.join([ str(ansunum) for ansunum in item.sunums ]) ])
                # undo 
                sutable.removeRequestFromSUMap(sus=allSUs, requestid=request['requestid']) # decrements refcount
                sutable.removeSUs(sunums=[ su.sunum for su in allSUs ], locktable=False) # decrements refcount            
                item.queued = False
        finally:
            sutable.releaseLock()
            
        return item

    @classmethod
    def new(cls, **kwargs):
        if kwargs['downloaderType'].__name__ in cls.reqTypeMap:
            raise DuplicateDispatcherType('Dispatcher type ' + kwargs['reqType'].__name__ + ' already exists')
    
        dispatcher = cls(**kwargs)
        cls.reqTypeMap[dispatcher.downloaderType.__name__] = dispatcher
        cls.tList.append(dispatcher)

        try:
            dispatcher.start()
        except RuntimeError:
            # cannot start a new thread, so rollback and re-raise so the calling thread can handle the error
            cls.tList.remove(dispatcher)

            raise StartThreadException('cannot start a new Dispatcher thread due to system resource limitations')
        
        return dispatcher


class LogLevelAction(argparse.Action):
    def __call__(self, parser, namespace, value, option_string=None):
        valueLower = value.lower()
        if valueLower == 'critical':
            level = logging.CRITICAL
        elif valueLower == 'error':
            level = logging.ERROR
        elif valueLower == 'warning':
            level = logging.WARNING
        elif valueLower == 'info':
            level = logging.INFO
        elif valueLower == 'debug':
            level = logging.DEBUG
        else:
            level = logging.ERROR

        setattr(namespace, self.dest, level)

    
class ExpirationAction(argparse.Action):
    def __call__(self, parser, namespace, value, option_string=None):
        # make a date (local timezone) from the value
        expires = dateparser.parse(value)
        setattr(namespace, self.dest, expires)


class ArchiveAction(argparse.Action):
    # the DRMS archive flag is one of: 
    #   -1 : do not archive, and when the SU expires, delete the DRMS records using that SU; when SUM_put() is called, 
    #        DRMS puts a flag file into the SU; then when sum_rm runs, it deletes the DRMS records; so, -1 is not
    #        relevant to Remote SUMS; the flag file is in the downloaded SU, and it is used in sum_rm
    #    0 : do not archive
    #    1 : archive
    # 
    # DRMS maps this flag into a set of SUMS flags: ARCH (archive to SU to tape), TEMP (the SU will expire at some point),
    # PERM (the SU will never expire); the mapping is:
    #    -1, 0 --> DAAEDDP (!PERM && TEMP && !ARCH)
    #        1 --> DAADP (!PERM && TEMP && ARCH)
    # 
    # in all cases, SUs are always temporary and the PERM flag is never used
    # 
    def __call__(self, parser, namespace, value, option_string=None):
        # distutils will make sure that the value isn't something other than a string that can be considered a boolean value
        if bool(distutils.util.strtobool(value)):
            archiveType = DAADP
        else:
            archiveType = DAAEDDP

        setattr(namespace, self.dest, archiveType)


def updateDbAndCommit(log, rsConn, rsDbLock, reqTable, reqIDs):
    # lock the SU table, the SUs, and access to the DB until the SU table SQL has been run so that nothing changes out from under us;
    # no need to lock anything having to do with the requests table - it is accessed by a single thread only
    # we acquire the DB Lock so that our transaction cannot get polluted - we do not want another thread committing the
    # transaction (all cursors share the same transaction)
    rqSql = reqTable.getUpdateDBSql(reqIDs)
    
    rsDbLock.acquire() # do not allow other threads to commit the DB changes in the middle of this
    try:
        # this calls does not commit changes to the DB
        log.writeDebug([ 'updating the DB with request table changes (request ' + ','.join(str(reqID) for reqID in reqIDs) + ')' ])
        reqTable.updateDB(rqSql)
        
        log.writeDebug([ 'committing Req-table changes to DB' ])
        rsConn.commit()
        log.writeDebug([ 'successfully committed Req changes' ])
    except:
        import traceback
        
        log.writeWarning([ 'failed to commit Req changes; changed rolled back' ])
        log.writeWarning([ traceback.format_exc(5) ])
        rsConn.rollback() # it could be that the first call succeeds and the second fails - we need to rollback the first too
        # continue on with the next request (do not terminate)
    finally:
        rsDbLock.release()
        
def getSUSites(sunums, sites, request, log):
    '''
    input:
      sunums - a list of SU integers
      sites - the sites table (DRMS sites that provide SUs)
      request - the request dictionary for a specific request
      log - rsumsd output log
    
    returns a 2-tuple:
      first element - a dictionary where they key is a source site CGI, and the value is a list of SUs that the site serves
      second element - a list of currently online SUs
    '''
    siteSUs = {}
    onlineSUs = []

    offlineSUs = SuTable.offline(sunums, log)

    for sunum in sunums:
        if sunum in offlineSUs:
            log.writeDebug([ 'SU ' + str(sunum) + ' is offline - will start a download' ])
        else:
            log.writeDebug([ 'SU ' + str(sunum) + ' is online already - will NOT start a download' ])
            onlineSUs.append(sunum)

    for sunum in offlineSUs:
        try:
            siteCGI = sites.getSuPathCGI(sunum)
        except UnknownSitecodeException as exc:                        
            # Skip this request - invalid SU.
            msg = 'uknown site code for SU ' + str(sunum) + '; skipping SU for request ' + str(request['requestid'])
            log.writeWarning([ msg ])
            continue

        if siteCGI not in siteSUs:
            siteSUs[siteCGI] = []

        siteSUs[siteCGI].append(sunum)
        
    return (siteSUs, onlineSUs)

# called from the main thread only
# for each SU that is dispatched (a DownloaderCompleteQueueItem will be created), we need to create an SU object
# (or increase a refcount) and call addRequestToSUMap(request, SU); we also need to remove that SU from all
# existing requests' todispatch lists
def dispatchSUs(sites, request, sutable, reqtable, dbuser, binpath, tapesysexists, tmpdir, expiration, archive, tapegroup, log):
    queuedSUs = set()
    notQueuedSUs = set()
    completedSUs = set()
    
    # send SUs to the dispatcher thread only if they have not been sent to the dispatcher thread already; to do so, use
    # the sunums in request['todispatch']; send only offline SUs
    # siteSunums is a dictionary where key is the site CGI, and the value is a list of unknown, offline SUs that
    # the site serves;
    # toComplete is a list of undispatched, but online remote SUs    
    siteSunums, onlineSunums = getSUSites(request['todispatch'], sites, request, log)
    for cgi, sunumList in siteSunums.items():
        if len(sunumList) > 0:
            # Chunk is a list of SUNUMs (up to 64 of them).
            sunumList.sort()
            chunker = Chunker(sunumList, 64)
            for chunk in chunker:
                try:
                    # will NOT block if there are no spots in the Dispatcher queue
                    item = Dispatcher.addSUChunk(cgi=cgi, sunums=chunk, reqtable=reqtable, sutable=sutable, dbuser=dbuser, request=request, binpath=binpath, hastapesys=tapesysexists, tmpdir=tmpdir, expiration=expiration, archive=archive, tapegroup=tapegroup, log=log)
                    
                    # keep track of all SUs dispatched - we will need to use this information to update each request's todispatch list
                    if item.queued:
                        queuedSUs = queuedSUs | set(item.sunums)
                        log.writeDebug([ 'added an item to the dispatcher queue for SU chunk: ' + ','.join([ str(ansunum) for ansunum in item.sunums ]) ])
                    else:
                        # pretend that these sunums were never passed to dispatchSUs()
                        notQueuedSUs = notQueuedSUs | set(item.sunums)
                except QueueFullException as exc:
                    # non-blocking put failed (because queue was full);
                    # none of the SUs in this chunk will appear in the SU Table (and they will not have Downloaders);
                    # the todispatch list mechanism will ensure these SUs get dispatched during the check on pending request
                    log.writeDebug([ 'dispatcher queue full; for request' + str(request['requestid']) + ', unable to add SU chunk: ' + ','.join([ str(ansunum) for ansunum in chunk ]) ])
                except RemoteSumsException as exc:
                    # do not die - just reject the request's current chunk; we do not know exactly which SUs made it into the
                    # SU Table, but at least one either did not or it did, but with status E; the request will eventually 
                    # error-out when the other SUs complete (successfully or not)
                    if type(exc.response) is str:
                        log.writeWarning([ exc.response ])
                    log.writeWarning([ 'failed to process SUs ' + ','.join([ str(sunum) for sunum in chunk ]), 'skipping this chunk' ])
                except Exception:
                    import traceback

                    msg = traceback.format_exc(5)
                    log.writeWarning([ msg ])
                    log.writeWarning([ 'failed to process SUs ' + ','.join([ str(sunum) for sunum in chunk ]), 'skipping this chunk' ])

    # now deal with online SUs (even though we have not sent them to a dispatcher, we should consider them dispatched and completed);
    # for each online SU that does not already have an SU object, we want to create one and we want to create a DownloadComplete queue
    # item
    sutable.acquireLock()
    try:
        # we want to insert a new SU object if the SU object does not already exist; otherwise, we want to
        # increment the refcount on the SU object; set the SU statuses to C;
        # set the initial status to 'C'; we have to lock this since the Dispatcher thread also creates new SUs
        existingSUs, newSUs = sutable.addSUs(sunums=onlineSunums, locktable=False, status='C') # this will bump refcount if the SU object already exist
        for su in existingSUs + newSUs:
            rslog.writeDebug([ '[ dispatchSUs() ] adding ' + str(request['requestid']) + ' to suMap for SU ' + str(su.sunum) ])
            sutable.addRequestToSUMap(sunums=[ su.sunum ], requestid=request['requestid'])
            # add all existingSUs to completedSUs; this request (time T2) might be newer than the previous request (time T1) 
            # that contained the SU that was added to completedSUs previously (at T1); this SU was removed from all requests' 
            # todispatch lists previously (at T1), before this request existed (at T2)
            completedSUs.add(su.sunum)

        for su in newSUs:
            # only create ONE DownloaderCompleteQueueItem() for each SU across ALL new SU requests; if we attempt to 
            # dispatch an ONLINE SU that has already been dispatched, then the SU will not be in newSUs
            DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=su, queue=sutable.queue, log=log)
            log.writeDebug([ '[ dispatchSUs() ] successfully added a DownloaderCompleteQueueItem for SU ' +  str(su.sunum)])
            
        for sunum in request['sunums']:
            if sunum not in notQueuedSUs and not sutable.presentInSUMap(sunums=[ sunum ], requestid=request['requestid']):
                existingSUs, newSUs = sutable.addSUs(sunums=[ sunum ], locktable=False, status='C') # this will bump refcount if the SU object already exist
                rslog.writeDebug([ '[ dispatchSUs() ] adding ' + str(request['requestid']) + ' to suMap for SU ' + str(su.sunum) ])
                sutable.addRequestToSUMap(sunums=[ sunum ], requestid=request['requestid'])
                completedSUs.add(sunum)
    finally:
        sutable.releaseLock()
    
    # update the request's todispatch list (the main thread is the only one to modify request items - no need for locking)
    # SUs sent to dispatcher + online SUs not dispatched previously (not processed by dispatchSUs())
    dispatchedSUs = queuedSUs | completedSUs
    
    reqtable.acquireLock()
    try:
        for request in reqtable.get():
            request['todispatch'] = list(set(request['todispatch']) - dispatchedSUs)
    finally:
        reqtable.releaseLock()


if __name__ == "__main__":
    rv = RET_SUCCESS

    try:
        sumsDrmsParams = SumsDrmsParams()

        parser = CmdlParser(usage='%(prog)s [ -h ] [ sutable=<storage unit table> ] [ reqtable=<request table> ] [ --dbname=<db name> ] [ --dbhost=<db host> ] [ --dbport=<db port> ] [ --binpath=<executable path> ] [ --logfile=<base log-file name> ]')
    
        # Optional parameters - no default argument is provided, so the default is None, which will trigger the use of what exists in the configuration file
        # (which is drmsparams.py).
        parser.add_argument('r', '--reqtable', help='The database table that contains records of the SU-request being processed. If provided, overrides default specified in configuration file.', metavar='<request unit table>', dest='reqtable', default=sumsDrmsParams.get('RS_REQUEST_TABLE'))
        parser.add_argument('n', '--nworkers', help='The number of scp worker threads.', metavar='<number of worker threads>', dest='nWorkers', type=int, default=sumsDrmsParams.get('RS_N_WORKERS'))
        parser.add_argument('t', '--tmpdir', help='The temporary directory to use for scp downloads.', metavar='<temporary directory>', dest='tmpdir', default=sumsDrmsParams.get('RS_TMPDIR'))
        parser.add_argument('-N', '--dbname', help='The name of the database that contains the series table from which records are to be deleted.', metavar='<db name>', dest='dbname', default=sumsDrmsParams.get('RS_DBNAME'))
        parser.add_argument('-U', '--dbuser', help='The name of the database user account.', metavar='<db user>', dest='dbuser', default=sumsDrmsParams.get('RS_DBUSER'))
        parser.add_argument('-H', '--dbhost', help='The host machine of the database that contains the series table from which records are to be deleted.', metavar='<db host machine>', dest='dbhost', default=sumsDrmsParams.get('RS_DBHOST'))
        parser.add_argument('-P', '--dbport', help='The port on the host machine that is accepting connections for the database that contains the series table from which records are to be deleted.', metavar='<db host port>', dest='dbport', default=int(sumsDrmsParams.get('RS_DBPORT')))
        parser.add_argument('-b', '--binpath', help='The path to executables run by this daemon (e.g., vso_sum_alloc, vso_sum_put).', metavar='<executable path>', dest='binpath', default=sumsDrmsParams.get('RS_BINPATH'))
        parser.add_argument('-l', '--loglevel', help='Specifies the amount of logging to perform. In order of increasing verbosity: critical, error, warning, info, debug', dest='loglevel', action=LogLevelAction, default=logging.ERROR)
        parser.add_argument('-E', '--expiration', help='The default date (ISO 8601) at which ingested SUs expire and become eligible for deletion.', dest='expiration', action=ExpirationAction, default=argparse.SUPPRESS)
        parser.add_argument('-L', '--lifespan', help='The lifespan of ingested SUs (number of days).', dest='lifespan', type=int, default=argparse.SUPPRESS)
        parser.add_argument('-a', '--archive', help='If set, then data are archived to tape.', dest='archive', action=ArchiveAction, default=argparse.SUPPRESS)
        parser.add_argument('-g', '--tapegroup', help='', dest='tapegroup', type=int, default=argparse.SUPPRESS)
                
        arguments = Arguments(parser)
        
        if arguments.nWorkers < 3:
            raise RSArgsException('must specify a minimum of 3 worker threads')

        if not hasattr(arguments, 'expiration') and not hasattr(arguments, 'lifespan'):
            # try RS_SU_EXPIRATION first
            try:
                expiration = dateparser.parse(sumsDrmsParams.get('RS_SU_EXPIRATION'))
                arguments.setArg('expiration', expiration)
            except DrmsParamsException:
                try:
                    # try RS_SU_LIFESPAN next
                    lifespan = int(sumsDrmsParams.get('RS_SU_LIFESPAN'))
                    
                    # convert to expiration
                    arguments.setArg('expiration', datetime.now() + timedelta(days=lifespan))
                except DrmsParamsException:
                    # neither expiration nor lifepan
                    raise RSArgsException('must provide either the expiration or lifespan argument')
                    
        if not hasattr(arguments, 'archive'):
            try:
                archive = bool(distroutil.strtobool(sumsDrmsParams.get('RS_SU_ARCHIVE')))
            except DrmsParamsException:
                archive = False

            arguments.setArg('archive', archive)

        if not hasattr(arguments, 'tapegroup'):
            try:
                tapegroup = int(sumsDrmsParams.get('RS_SU_TAPEGROUP'))
            except DrmsParamsException:
                tapegroup = 0

            arguments.setArg('tapegroup', tapegroup)

        arguments.setArg('lockfile', sumsDrmsParams.get('RS_LOCKFILE'))
        arguments.setArg('dltimeout', timedelta(seconds=int(sumsDrmsParams.get('RS_DLTIMEOUT'))))
        arguments.setArg('reqtimeout', timedelta(seconds=int(sumsDrmsParams.get('RS_REQTIMEOUT'))))
        arguments.setArg('maxthreads', int(sumsDrmsParams.get('RS_MAXTHREADS')))
        arguments.setArg('scpMaxNumSUs', int(sumsDrmsParams.get('RS_SCP_MAXSUS')))
        arguments.setArg('scpMaxPayload', 1024 * 1024 * int(sumsDrmsParams.get('RS_SCP_MAXPAYLOAD')))
        arguments.setArg('scpTimeOut', timedelta(seconds=int(sumsDrmsParams.get('RS_SCP_TIMEOUT'))))
        arguments.setArg('rsSiteInfoURL', sumsDrmsParams.get('RS_SITE_INFO_URL'))
        arguments.setArg('logdir', sumsDrmsParams.get('RS_LOGDIR'))
        
        arguments.setArg('sumsdbname', sumsDrmsParams.get('DBNAME') + '_sums')
        arguments.setArg('sumsdbuser', sumsDrmsParams.get('SUMS_MANAGER'))
        arguments.setArg('sumsdbhost', sumsDrmsParams.get('SUMS_DB_HOST'))
        arguments.setArg('sumsdbport', int(sumsDrmsParams.get('SUMPGPORT')))
        
        arguments.setArg('tapesysexists', int(sumsDrmsParams.get('SUMS_TAPE_AVAILABLE')) == 1)
        
        pid = os.getpid()

        # Create/Initialize the log file.
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
        rslog = Log(os.path.join(sumsDrmsParams.get('RS_LOGDIR'), LOG_FILE_BASE_NAME + '_' + datetime.now().strftime('%Y%m%d') + '.txt'), arguments.loglevel, formatter)
        thContainer = [ arguments, str(pid), rslog ]
        
        # TerminationHandler opens a DB connection to the RS database (which is the same as the DRMS database, most likely).
        with TerminationHandler(thContainer) as th:        
            rslog.writeInfo([ 'setting download timeout to ' + str(arguments.dltimeout) + ' (the daemon must complete the download within this interval)' ])
            rslog.writeInfo([ 'setting request timeout to ' + str(arguments.reqtimeout) + ' (the daemon must locate the request within this interval)' ])
            rslog.writeInfo([ 'setting scp timeout to ' + str(arguments.scpTimeOut) + ' (each ScpWorker waits this long at most before initiating the next scp)' ])
        
            rsConn = th.rsConn()
            sumsConn = th.sumsConn()

            rsDbLock = threading.RLock() # global
            sumsDbLock = threading.Lock() # global
            
            rslog.writeInfo([ 'obtained script file lock' ])

            reqTable = arguments.reqtable

            suTableObj = None
            reqTableObj = None
            sites = None

            # Read the storage-unit and request tables. Do this only once per daemon run. However, we save this table
            # information every iteration of the daemon loop, just in case a crash happens. After a crash, when
            # the daemon starts up, it will retrieve the latest saved information so the disruption will be minimal.
            # We will have to clean up any pending downloads since the threads managing those downloads will have
            # been lost, and we cannot trust that the downloads completed successfully (although they might have).
            # A fancier implementation would be some kind of download manager that can recover partially downloaded
            # storage units, but who has the time :)

            ReqTable.rsConn = rsConn # Class variable
            ReqTable.rsDbLock = rsDbLock # Class variable
            reqTableObj = ReqTable(reqTable, arguments.reqtimeout, rslog)

            SuTable.rsConn = rsConn # Class variable
            SuTable.sumsConn = sumsConn # Class variable
            SuTable.rsDbLock = rsDbLock # Class variable
            SuTable.sumsDbLock = sumsDbLock # Class variable
            suTableObj = SuTable(arguments.dltimeout, reqTableObj, rslog)

            
            Downloader.sumsConn = sumsConn
            Downloader.sumsDbLock = sumsDbLock # Class variable

            sites = SiteTable(arguments.rsSiteInfoURL, rslog)

            # This function will try to read each table 10 times before giving up (and raising an exception).
            readTables(reqTableObj, sites)

            # Set max number of threads we can process at once.
            Downloader.setMaxThreads(arguments.maxthreads)
            
            ###########################
            # START SCPWORKER THREADS #
            ###########################
            
            # make N threads that handle scp commands; each of the worker threads will use one of these threads to perform
            # the actual scp command; MUST do this here, before 'P' Downloader threads have been
            # started. The ScpWorker threads need the parent Downloader threads to exist before it can process 'W' SUs, but if there
            # are more than maxThreads 'P' SUs, then the Dispatcher code will block until threads free up, and that cannot happen
            # if the ScpWorker threads are not running
            ScpWorker.lock.acquire()
            try:
                for nthread in range(1, arguments.nWorkers + 1):
                    if len(ScpWorker.tList) < ScpWorker.maxThreads - 2:
                        rslog.writeInfo([ 'instantiating ScpWorker ' + str(nthread) + ' with priority ' + str(100) ])
                        ScpWorker.newThread(id=nthread, sutable=suTableObj, tmpdir=arguments.tmpdir, maxsus=arguments.scpMaxNumSUs, maxpayload=arguments.scpMaxPayload, scptimeout=arguments.scpTimeOut, priority=100, log=rslog)
                    else:
                        break # The finally clause will ensure the ScpWorker lock is released.
        
                # high priority ScpWorkers
                for nthread in range(arguments.nWorkers + 1, arguments.nWorkers + 3):
                    rslog.writeInfo([ 'instantiating ScpWorker ' + str(nthread) + ' with priority ' + str(0) ])
                    ScpWorker.newThread(id=nthread, sutable=suTableObj, tmpdir=arguments.tmpdir, maxsus=arguments.scpMaxNumSUs, maxpayload=arguments.scpMaxPayload, scptimeout=arguments.scpTimeOut, priority=0, log=rslog)
            finally:
                ScpWorker.lock.release()
                    
            Dispatcher.lock.acquire()
            try:                                    
                rslog.writeInfo([ 'instantiating the downloader Dispatcher' ])
                dispatcher = Dispatcher.new(name='downloader-dispatcher', downloaderType=Downloader, log=rslog)
                rslog.writeInfo([ 'downloader Dispatcher is running' ])
            
                rslog.writeInfo([ 'instantiating the high-priority download Dispatcher' ])
                highPriorityDispatcher = Dispatcher.new(name='high-priority-downloader-dispatcher', downloaderType=HighPriorityDownloader, log=rslog)
                rslog.writeInfo([ 'high-priority download Dispatcher is running' ])
            except StartThreadException as exc:
                raise StartThreadException('cannot start Dispatcher')
            finally:
                Dispatcher.lock.release()

            ################################
            # RESTART INTERRUPTED REQUESTS #
            ################################

            # we must have already started ScpWorker threads, otherwise the Dispatcher will block if we try to process too
            # many SUs in the following block of code - we'll use up all Downloader threads, and since there are no 
            # ScpWorker threads perform downloads, the Downloader pool will not get restored, and the whole
            # system will block on the Downloader.eventMaxThreads.wait() call
            th.disableInterrupts()
            try:
                # when disabling interrupts, add an exception handler with a finally clause so that we re-enable
                # interrupts when an exception happens (so we can terminate remote sums)
            
                reqsPending = reqTableObj.getPending()
                rslog.writeInfo([ 'there are ' + str(len(reqsPending)) + ' pending requests on start-up'])
            
                # request is a dictionary
                for request in reqsPending:
                    # use a set() to remove duplicates IN THE SAME REQUEST
                    sunums = list(set(request['sunums'])) # the SUs may or may not have been dispatched in previous iterations
                    rslog.writeInfo([ 'found an interrupted download request, id ' + str(request['requestid']) + ', for SUNUMs ' + ','.join([str(sunum) for sunum in sunums]) ])

                    # FOR ALL OFFLINE SUs, dispatchSUs() will asynchronously add/++refcount a SU to the sutable, and add an entry in the SU map; 
                    # it will also remove the offline SUs from ALL requests' 'todispatch' lists; for all ONLINE SUs, dispatchSUs() will synchronously
                    # add a new status=C SU to the sutable, and add an entry to the SU map; it will also remove the offline SUs from ALL requests' 
                    # 'todispatch' lists
                    dispatchSUs(sites, request, suTableObj, reqTableObj, arguments.dbuser, arguments.binpath, arguments.tapesysexists, arguments.tmpdir, arguments.expiration, arguments.archive, arguments.tapegroup, rslog)

                    # At this point, both the requests table and SU table have been modified, but have not been flushed to disk.
                    # Flush them, but do this inside a transaction so that the first does not happen without the second.
                    updateDbAndCommit(rslog, rsConn, rsDbLock, reqTableObj, [ request['requestid'] ])
            except:
                raise
            finally:    
                th.enableInterrupts()
            # END RESTART REQUESTS #

            ###############
            ## MAIN LOOP ##
            ###############
            ilogger = IntervalLogger(rslog, timedelta(seconds=5))
            # sleep for at least one second between iterations
            while True:
                # For each 'P' request in the request table, check to see if the requested downloads have completed yet.
                
                ############################
                # PROCESS PENDING REQUESTS #
                ############################
                th.disableInterrupts()
                try:
                    # when disabling interrupts, add an exception handler with a finally clause so that we re-enable
                    # interrupts when an exception happens (so we can terminate remote sums)
                    
                    # use a queue so we do not have to worry about SU contention - the only threads that can modify the
                    # SU statuses are the Downloaders and ScpWorkers
                    for inum in range(1, 32):
                        # process at most 32 pending SUs - but don't process until queue is empty since the number of SUs
                        # in the queue could be large

                        # pop a DownloaderCompleteItem from the queue (time-out after 0.5 seconds - if a timeout occurs, then the queue was empty);
                        # the existence of the item implies that the Downloader thread has exited, removing the possibility of thread
                        # contention for this SU;
                        # must acquire Downloader lock since there are several actions that must occur atomically on the put() side of the code
                        completeItem = None
                        try:
                            suTableObj.acquireLock()
                            try:
                                completeItem = suTableObj.queue.get_nowait()
                                rslog.writeDebug([ 'processing download-complete item for SU ' + str(completeItem.su.sunum) ])
                            except Empty:
                                # no DownloaderCompleteItem item available; move on to processing new requests
                                break
                            except:
                                raise
                            finally:
                                suTableObj.releaseLock()

                            # check SU download status 
                            # an SU object is created in the Dispatcher thread; read/writes happen in either the Downloader and ScpWorker 
                            # thread (but there is no contention between these two threads); there is no thread contention possible
                            # for the SU contents
                            if completeItem.su.status == 'E':
                                rslog.writeInfo([ 'download of SU ' + str(completeItem.su.sunum)  + ' has errored-out; ' + completeItem.su.errmsg ])
                            elif completeItem.su.status == 'C':
                                rslog.writeInfo([ 'download of SU ' + str(completeItem.su.sunum)  + ' has completed' ])
                            elif completeItem.su.status == 'P' or completeItem.su.status == 'W' or completeItem.su.status == 'D':
                                # the Downloader no longer exists, so this is an error
                                completeItem.su.setStatus('E', 'download for SU ' + str(completeItem.su.sunum) + ' did not properly complete')
                            else:
                                # unknown status; set status to 'E'
                                completeItem.su.setStatus('E', 'SU ' + str(completeItem.su.sunum) + ' has an unknown status of ' + completeItem.su.status + '.')

                            # find all requests that refer to this SU with the SU's map to all its requests
                            reqTableObj.acquireLock() # because we need to access reqTableObj.reqDict
                            try:
                                suTableObj.acquireLock() # because we need to access suTableObj.suMap
                                try:
                                    for requestID in suTableObj.suMap[str(completeItem.su.sunum)]:
                                        # add this SU to the request['complete'] list
                                
                                        # we cannot cache the actual request dict because we refresh the set of requests near
                                        # the end of the main loop; so we cache the requestID, and then we have to hash into 
                                        # the request dict to get the current request dict for that requestID
                                        request = reqTableObj.get([ requestID ])[0]
                                        if completeItem.su.sunum not in request['complete']:
                                            request['complete'].append(completeItem.su.sunum)
                                            rslog.writeDebug([ 'added ' + str(completeItem.su.sunum) + ' to complete list for request ' + str(request['requestid']) ])
                                finally:
                                    suTableObj.releaseLock()
                            finally:
                                reqTableObj.releaseLock()                            
                        finally:
                            if completeItem:
                                suTableObj.queue.task_done()

                    # the Downloaders check for orphaned SUs (SUs without workers - no progress can be made) - no 
                    # need to do that here; but we need to check for missing Downloaders
                    reqsPending = reqTableObj.getPending()
                    for request in reqsPending:
                        sunums = set(request['sunums'])
                        completedSunums = set(request['complete'])
                        
                        sunumList = ','.join([ str(sunum) for sunum in list(sunums) ])
                    
                        rslog.writeDebug([ 'request ' + str(request['requestid']) + ' sunums: ' + sunumList ])
                        rslog.writeDebug([ 'request ' + str(request['requestid']) + ' complete SUs: ' + ','.join([ str(sunum) for sunum in list(completedSunums) ]) ])
                        
                        if len(sunums.symmetric_difference(completedSunums)) == 0:
                            # request has completed
                            reqError = False
                            errMsg = None

                            sus, missingSunums = suTableObj.getSUs(releaseTableLock=False, sunums=list(sunums))
                            try:
                                for su in sus:
                                    if su.status == 'E':
                                        reqError = True
                                        errMsg = su.errmsg
                                        break

                                # remove sunum-->request map items
                                suTableObj.removeRequestFromSUMap(sus=sus, requestid=request['requestid']) # decrements refcount
                                rslog.writeDebug([ 'removed SUs: ' + sunumList + ' from SU map' ])
                                suTableObj.removeSUs(sunums=[ su.sunum for su in sus ], locktable=False) # decrements refcount
                                rslog.writeDebug([ 'removed SUs: ' + sunumList ])
                                
                                # this request is done; set this request's status to 'C' or 'E', and decrement the refcount on each SU
                                if reqError:
                                    rslog.writeInfo([ 'request number ' + str(request['requestid']) + ' for SUNUM(s) ' + sunumList + ' errored-out' ])
                                    reqTableObj.setStatus([ request['requestid'] ], 'E', errMsg)
                                else:
                                    rslog.writeInfo([ 'request number ' + str(request['requestid']) + ' for SUNUM(s) ' + sunumList + ' completed successfully' ])
                                    reqTableObj.setStatus([ request['requestid'] ], 'C')
                            finally:
                                suTableObj.releaseLock()

                            # commit status changes to the requests table
                            updateDbAndCommit(rslog, rsConn, rsDbLock, reqTableObj, [ request['requestid'] ])
                        else:
                            # check to see if any request has undispatched SUs
                            if len(request['todispatch']) > 0:
                                # a Dispatcher asynchronously inserts rows into the SU Table, and it may block waiting for a Downloader;
                                # it may be that for this request, some of the SUs do not appear in the SU Table yet, or if they do, 
                                # they might be lacking a Downloader;
                    
                                # not in SU Table; one of two things is possible:
                                # 1. they are in the Dispatcher queue (not yet being processed by the Dispatcher thread)
                                # 2. the attempt to insert them into the Dispatcher queue failed because the queue was full
                                # if #1 is the case, we do nothing; if #2 is the case, then we need to re-try inserting them 
                                # into the Dispatcher queue - use request to determine which queue to use; since all the SUs in 
                                # missingSunums belong to one request, we can use the todispatch list method to determine
                                # which SUs to put into the dispatch queue
                                sunums = list(set(request['todispatch']) ) # the SUs that have not been dispatched yet        
                                rslog.writeDebug([ 'request ' + str(request['requestid']) + ' (obj ' + str(id(request)) + ')' + ' has un-dispatched SUs: ' + ','.join([ str(sunum) for sunum in sunums ]) ])
                                dispatchSUs(sites, request, suTableObj, reqTableObj, arguments.dbuser, arguments.binpath, arguments.tapesysexists, arguments.tmpdir, arguments.expiration, arguments.archive, arguments.tapegroup, rslog)

                                # At this point, both the requests table and SU table have been modified, but have not been flushed to disk.
                                # Flush them, but do this inside a transaction so that the first does not happen without the second.
                                updateDbAndCommit(rslog, rsConn, rsDbLock, reqTableObj, [ request['requestid'] ])
                            else:
                                # not all SU have been processed, but at the same time all have been dispatched; if the worker attribute
                                # (Downloader) of the SU is not None, then we started a Downloader for this SU; if that Downloader died,
                                # then we need to set the SU status to E

                                # there is the error case where an SU has been dispatched, but no Downloader was ever created (a queue
                                # item was added, but for some reason, the dispatcher never created a Downloader);
                                # sunums are the pending SUs (all SUs have been dispatched)
                                sunums = list(set(request['todispatch']))
                                sus, missingSunums = suTableObj.getSUs(releaseTableLock=False, sunums=sunums)
                                try:
                                    # the sus are in the SU Table, so they should have a Downloader (it is possible that an SU has been dispatched
                                    # but has not yet been assigned a Downloader because the Dispatcher thread has yet to read its queue item)                                    
                                    dispatcher = Dispatcher.getDispatcher(request['type'])

                                    for su in sus:
                                        # we lock the Downloader lock whenever we set/unset the worker in the su object
                                        dispatcher.downloaderType.lock.acquire()
                                        try:
                                            if hasattr(su, 'worker') and su.worker is not None:
                                                # a downloader thread has definitely been started; it should be alive
                                                if not isinstance(su.worker, (Downloader)) or not su.worker.isAlive():
                                                    # set SU status to E
                                                    su.setStatus('E', 'download for SU ' + str(su.sunum) + ' lost its Downloader unexpectedly')
                                        
                                                    # put a complete item in the queue so that the main thread will handle this in the 
                                                    # pending requests section (do no further SU-completion processing here)
                                                    DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=su, queue=suTableObj.queue, log=rslog)
                                                    rslog.writeDebug([ 'successfully added a DownloaderCompleteQueueItem for SU ' +  str(su.sunum)])
                                            
                                        finally:
                                            downloaderType.lock.release()
                                            
                                finally:
                                    suTableObj.releaseLock()
                except:
                    # pass this to the enclosing handler
                    raise
                finally:
                    th.enableInterrupts()
                # For each 'N' request in the request table, start a new set of downloads (if there is no download currently running -
                # i.e., no SU record) or increment the refcounts on the downloads (if there are downloads currently running - i.e.,
                # an SU record exists). But Before starting a new download, make sure that requested SU is not already online.
                # Due to race conditions, a request could have caused a download to occur needed by another request whose state is 'N'.
                
                # END PENDING REQUESTS #

                ########################
                # PROCESS NEW REQUESTS #
                ########################
                th.disableInterrupts()
                try:
                    # when disabling interrupts, add an exception handler with a finally clause so that we re-enable
                    # interrupts when an exception happens (so we can terminate remote sums)
                    
                    # locks reqDict, but only for a brief period of time (during swap of new reqDict for old reqDict)
                    reqTableObj.refresh() # clients may have added requests to the queue

                    reqsNew = reqTableObj.getNew()

                    # reqsNew contains requests sorted by (priority, start-time)
                    # request is a dictionary
                    for request in reqsNew:
                        timeNow = datetime.now(request['starttime'].tzinfo)
                        if timeNow > request['starttime'] + reqTableObj.getTimeout():
                            ilogger.writeInfo([ 'request number ' + str(request['requestid']) + ' timed-out' ])
                            reqTableObj.setStatus([ request['requestid'] ], 'E', 'request timed-out')
                        
                            try:
                                reqTableObj.updateDbAndCommit([ request['requestid'] ])
                            except:
                                import traceback
                            
                                ilogger.writeWarning([ traceback.format_exc(5) ])
                                # swallow the exception and continue with the next request
                                pass
                            continue
                    
                        # use a set() to remove duplicates IN THE SAME REQUEST
                        
                        sunums = list(set(request['sunums'])) # the SUs that have not been dispatched yet
                        rslog.writeInfo([ 'found a new download request, id ' + str(request['requestid']) + ', for SUNUMs ' + ','.join([ str(sunum) for sunum in sunums ]) ])

                        # sunumsToSetToComplete - SUs that were NOT dispatched because they were online already; if they were
                        # not online, but already part of another request, they DO get dispatched; then the dispatcher does NOT
                        # create a Downloader for the SU;
                        # it is possible that the dispatcher was full, so some SUs might not have been dispatched; there will
                        # be additional attempts in the pending-request processing part of the main loop
                        dispatchSUs(sites, request, suTableObj, reqTableObj, arguments.dbuser, arguments.binpath, arguments.tapesysexists, arguments.tmpdir, arguments.expiration, arguments.archive, arguments.tapegroup, rslog)

                        # the new request has been fully processed; change its status from 'N' to 'P';
                        # this call modifies the requests object and it acquires each SU's lock
                        reqTableObj.setStatus([ request['requestid'] ], 'P')

                        # At this point, both the requests table and SU table have been modified, but have not been flushed to disk.
                        # Flush them, but do this inside a transaction so that the first does not happen without the second.
                        updateDbAndCommit(rslog, rsConn, rsDbLock, reqTableObj, [ request['requestid'] ])
                except:
                    raise
                finally:                    
                    th.enableInterrupts()
                # END PROCESS NEW REQUESTS #

                # Delete all request-table records whose state is 'D'. It doesn't matter if this operation gets interrupted. If
                # that happens, then these delete-pending records will be deleted the next time this code runs uninterrupted.
                # CLIENTS DO NOT APPEAR TO SET REQ STATUS TO D - THIS IS A NO-OP
                reqsToDelete = reqTableObj.getDelete()
                reqTableObj.deleteDB(reqsToDelete)
                
                time.sleep(1)
                ######################
                ## END OF MAIN LOOP ##
                ######################
            
            # Save the db state when exiting.
            rslog.writeInfo([ 'remote-sums daemon is exiting; saving database tables' ])
            updateDbAndCommit(rslog, rsConn, rsDbLock, reqTableObj, None)

        # DB connection was terminated.            
        # Lock was released     
    except TerminationException as exc:
        msg = exc.args[0]
        if rslog:
            rslog.writeInfo([ msg ])
    except LockException as exc:
        msg = exc.args[0]
        print(msg)
        rslog = None
    except RemoteSumsException as exc:
        msg = exc.args[0]
        if rslog:
            rslog.writeError([ msg ])
            
        rv = exc.retcode
    except:
        import traceback
        
        msg = traceback.format_exc(5)
        if rslog:
            rslog.writeError([ msg ])
        else:
            print(msg, file=sys.stderr)
        rv = RET_UNKNOWN_ERROR

if rslog:
    rslog.writeInfo([ 'exiting with return status ' + str(rv) ])
# Will not exit process if threads are still running. Set global shutdown flag that threads are monitoring. When they see the flag, they
# will terminate too.

logging.shutdown()
sys.exit(rv)
