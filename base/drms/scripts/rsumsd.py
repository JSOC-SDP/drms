#!/usr/bin/env python

from __future__ import print_function
import sys
import re
import os
import stat
import filecmp
import thread
import psycopg2
import threading
import fcntl
from datetime import datetime, timedelta
import urllib
import urllib2
import json
import signal
import time
from copy import deepcopy
import psycopg2
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../../../include'))
from drmsparams import DRMSParams
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../../../base/libs/py'))
from drmsCmdl import CmdlParser
from drmsLock import DrmsLock
from subprocess import check_output, check_call, CalledProcessError, Popen

# This script runs as a daemon at the site that has requested an SU that does not belong to the site. It is responsible for contacting
# the owning site and requesting the path to the desired SUs. The owning site must be running the rs.sh CGI to respond to the requesting
# site's request.

# There are three database tables: 1., a DRMS site table, 2., a request table, and 3., an SU table (sunum, starttime, status, errmsg)
# The site table (sitename, sitecode, baseurl) provides
# the information needed to query the providing site for the information needed to scp the requested SUs to the requesting site. The URL to the cgi
# program that provides scp information is formed by appending "rs.py" to baseurl. There are two parameters for this cgi: 1., "requestid", and 2., "sunums".
# During the initial request to the providing site, the requesting site will provide a requestid of "none", and a comma-separated list of SUNUMs
# in the sunums argument. Should the providing site have all the requested SUs online, then it will return the scp information needed to access those
# SUs, and a status of "complete". If, however, the SUs are not all online, the initial request will start an asynchronous tape-read of the offline SUs,
# returning a request ID that identifies the initial request, and a status of "pending". The requesting site must then poll for completion by
# periodically calling the cgi with a status request. To make a status request, the requestid argument contains the requestid returned by the
# inital CGI call, and the sunums argument contains "none". While the data are not ready, the status request returns a status of "pending". When
# the data are online, the status request returns a status of "complete".
#
# The request table (requestid, sunums, status) is populated by drms_storageunit.c. For all SUs that are offline and are not owned by the running
# DRMS/SUMS, the code inserts a record into the request table. The requestid is a UUID (within the running DRMS/SUMS) generated by a sequence table.
# The list of SUNUMs is put in sunums, and the initial status is set to 'N' (New request). drms_storageunit.c chunks such SUNUMs into
# manageable-sized requests. After inserting one or more such records into the request table, drms_storageunit.c then polls these records,
# waiting for the status to become 'C' (Complete request). After that happens, drms_storageunit.c then calls SUM_get() again on these SUs
# to obtain their paths. This daemon, rsumsd.py, periodically and reads all records in the request table. For each SU in each 'N' record
# (a single request, which could be requesting multiple SUs) the daemon first checks if the SU is already being processed. If so, then
# the SU table is not modified. The status of the record in the request table is set to 'P'. If the SU is not in the SU table, then
# this can mean one of two things. The daemon has never processed this SU, or the daemon has already processed this SU. When the daemon has completed
# processing an SU, it deletes the record for the SU from the SU table. If the latter is true, the daemon should not re-process the same SU. To distinguish
# between these two possibilities, the daemon first checks to see if the SU is already present in SUMS (it calls show_info -o sunum=SUNUM).
# If the SU is online, then the daemon does nothing. But if it is offline, then the daemon inserts a record for the SU into the SU table, and starts
# processing that SU. The status of that SU-table record is set to 'P', as is the status of the request record containing that SUNUM.
#
# For each SU in each 'P' request record, the daemon searches for records in the SU table. If one or more such records exist in the SU table, then
# the request record is left in the pending state. The next time the daemon scans the request records, it will again check the SU table looking
# for completion of all SUs. When that occurs, the status of the request record is set to 'C', indicating that the request is complete. The
# drms_storageunit.c code will then call SUMS to get the newly created paths to the requested SUs.

RET_SUCCESS = 0
RET_INVALIDARGS = 1
RET_LOCK = 2
RET_SUTABLE_READ = 3
RET_SUTABLE_WRITE = 4
RET_REQTABLE_READ = 5
RET_REQTABLE_WRITE = 6
RET_DBCOMMAND = 7
RET_LOGFILE = 8
RET_OFFLINE = 9
RET_UKNOWNREQUEST = 10
RET_UKNOWNSU = 11
RET_UKNOWNSITECODE = 12
RET_DUPLICATESUNUM = 13

LOG_FILE_BASE_NAME = 'rslog'

class Log:
    def __init__(self, logPath, baseFileName):
        now = datetime.now().strftime('%Y%m%d')
        fileName = baseFileName + '_' + now + '.txt'
        self.fileName = os.path.join(logPath, fileName)
        try:
            # If path doesn't exist, create it. Since we are running as the production rs user, ownership will be fine.
            if not os.path.isdir(logPath):
                os.mkdir(logPath)
            
            fobj = open(self.fileName, 'a')
        except IOError as exc:
            type, value, traceback = sys.exc_info()
            raise Exception('badLogfile', 'Unable to open ' + "'" + value.filename + "'.")

        self.fobj = fobj

    def __del__(self):
        self.fobj.close()

    def write(self, text):
        try:
            lines = ['[' + datetime.now().strftime('%Y-%m-%d %T') + '] ' + line + '\n' for line in text]
            self.fobj.writelines(lines)
            self.fobj.flush()
        except IOError as exc:
            type, value, traceback = sys.exc_info()
            raise Exception('badLogwrite', 'Unable to write to ' + value.filename + '.')

class SuTable:
    cursor = None
                
    def __init__(self, tableName, timeOut, log):
        self.tableName = tableName
        self.timeOut = timeOut # A timedelta object - the length of time to wait for a download to complete.
        self.lock = thread.allocate_lock()
        self.locked = False
        self.log = log
        self.suDict = {}
    
    def __del__(self):
        if self.locked:
            self.lock.release()
    
    @classmethod
    def setCursor(cls, cursorIn):
        cls.cursor = cursorIn

    def read(self):
        # sus(sunum, starttime, refcount, status, errmsg)
        cmd = 'SELECT sunum, starttime, refcount, status, errmsg FROM ' + self.tableName
    
        try:
            cursor.execute(cmd)
    
        except psycopg2.Error as exc:
            raise Exception('sutableRead', exc.diag.message_primary)
    
        for record in cursor:
            sunumStr = str(record[0])
            
            self.suDict[sunumStr] = {}
            self.suDict[sunumStr]['sunum'] = record[0]
            # Whoa! pyscopg returns timestamps as datetime.datetime objects already!
            self.suDict[sunumStr]['starttime'] = record[1]
            self.suDict[sunumStr]['refcount'] = record[2]
            self.suDict[sunumStr]['status'] = record[3]
            self.suDict[sunumStr]['errmsg'] = record[4]
            self.suDict[sunumStr]['dirty'] = False
            self.suDict[sunumStr]['new'] = False

    # This will never be used. Rows are written one at a time.
    def write(self):
        # sus(sunum, starttime, refcount, status, errmsg)
        try:
            cursor.execute('PREPARE preparedStatement AS INSERT INTO ' + suTable + ' VALUES($1, $2, $3, $4, $5)')
            for sunumStr in sorted(self.suDict.iterkeys()):
                if self.suDict[sunumStr]['dirty']:
                    cursor.execute('EXECUTE preparedstatement (%s, %s, %s, %s, %s)', (sunumStr, self.suDict[sunumStr]['starttime'], str(self.suDict[sunumStr]['refcount']), self.suDict[sunumStr]['status']), self.suDict[sunumStr]['errmsg'])
    
        except psycopg2.Error as exc:
            raise Exception('badSql', exc.diag.message_primary)

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes.
    def updateDB(self, sunum=None):
        if sunum:
            # Update a single record.
            sunumStr = str(sunum)
            
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', 'No SU-table record exists for SU ' + sunumStr + '.')
            
            if self.suDict[sunumStr]['dirty']:
                if self.suDict[sunumStr]['new'] == True:
                    cmd = 'INSERT INTO ' + self.tableName + '(sunum, starttime, refcount, status, errmsg) VALUES(' + sunumStr + ",'" + self.suDict[sunumStr]['starttime'].strftime('%Y-%m-%d %T') + "', " + str(self.suDict[sunumStr]['refcount']) + ", '" + self.suDict[sunumStr]['status'] + "', '" + self.suDict[sunumStr]['errmsg'] + "')"
                else:
                    cmd = 'UPDATE ' + self.tableName + " SET starttime='" + self.suDict[sunumStr]['starttime'].strftime('%Y-%m-%d %T') + "', refcount=" + str(self.suDict[sunumStr]['refcount']) + ", status='" + self.suDict[sunumStr]['status'] + "', errmsg='" + self.suDict[sunumStr]['errmsg'] + "' WHERE sunum=" + sunumStr
                
                self.log.write(['Updating SU db table: ' + cmd])
                
                try:
                    cursor.execute(cmd)
            
                except psycopg2.Error as exc:
                    raise Exception('sutableWrite', exc.diag.message_primary)
                
                self.suDict[sunumStr]['dirty'] = False
                self.suDict[sunumStr]['new'] = False
        else:
            # Update all dirty records.
            for sunumStr in self.suDict:
                if self.suDict[sunumStr]['dirty']:
                    if self.suDict[sunumStr]['new'] == True:
                        cmd = 'INSERT INTO ' + self.tableName + '(sunum, starttime, refcount, status, errmsg) VALUES(' + sunumStr + ",'" + self.suDict[sunumStr]['starttime'].strftime('%Y-%m-%d %T') + "', " + str(self.suDict[sunumStr]['refcount']) + ", '" + self.suDict[sunumStr]['status'] + "', '" + self.suDict[sunumStr]['errmsg'] + "')"
                    else:
                        cmd = 'UPDATE ' + self.tableName + " SET starttime='" + self.suDict[sunumStr]['starttime'].strftime('%Y-%m-%d %T') + "', refcount=" + str(self.suDict[sunumStr]['refcount']) + ", status='" + self.suDict[sunumStr]['status'] + "', errmsg='" + self.suDict[sunumStr]['errmsg'] + "' WHERE sunum=" + sunumStr
                    
                    self.log.write(['Updating SU db table: ' + cmd])
                    
                    try:
                        cursor.execute(cmd)
                    
                    except psycopg2.Error as exc:
                        raise Exception('sutableWrite', exc.diag.message_primary)
                    
                    self.suDict[sunumStr]['dirty'] = False
                    self.suDict[sunumStr]['new'] = False

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes.
    def deleteDB(self, sunums):
        if len(sunums) > 0:
            # Delete the in-memory cache of these sunums
            for asunum in sunums:
                sunumStr = str(asunum)
                
                if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                    raise Exception('unknownSunum', 'No SU-table record exists for SU ' + sunumStr + '.')

                del self.suDict[sunumStr]
            
            sunumLstStr = ','.join([str(asunum) for asunum in sunums])
        
            cmd = 'DELETE FROM ' + self.tableName + ' WHERE sunum=' + sunumLstStr
        
            try:
                cursor.execute(cmd)
                
            except psycopg2.Error as exc:
                raise Exception('sutableWrite', exc.diag.message_primary)

    def acquireLock(self):
        self.lock.acquire()
        self.locked = True
    
    def releaseLock(self):
        if self.locked:
            self.lock.release()
            self.locked = False
    
    def insert(self, sunums):
        for asunum in sunums:
            sunumStr = str(asunum)
        
            if sunumStr in self.suDict:
                raise Exception('knownSunum', 'SU-table record already exists for SU ' + sunumStr + '.')
        
            self.suDict[sunumStr] = {}
            self.suDict[sunumStr]['sunum'] = asunum
            self.suDict[sunumStr]['starttime'] = datetime.now()
            self.suDict[sunumStr]['refcount'] = 1
            self.suDict[sunumStr]['status'] = 'P'
            self.suDict[sunumStr]['errmsg'] = ''

            # Set dirty flag
            self.suDict[sunumStr]['dirty'] = True

            # Set the new flag (so that the record will be INSERTed into the SU database table instead of UPDATEd).
            self.suDict[sunumStr]['new'] = True

    def setStatus(self, sunums, code, msg=None):
        for asunum in sunums:
            sunumStr = str(asunum)
        
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', 'No SU-table record exists for SU ' + sunumStr + '.')
        
            self.suDict[sunumStr]['status'] = code
            if msg is not None:
                self.suDict[sunumStr]['errmsg'] = msg
            else:
                self.suDict[sunumStr]['errmsg'] = ''

            # Set dirty flag
            self.suDict[sunumStr]['dirty'] = True

    def setStarttime(self, sunum, starttime):
        for asunum in sunums:
            sunumStr = str(asunum)
    
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', 'No SU-table record exists for SU ' + sunumStr + '.')
            
            self.suDict[sunumStr]['starttime'] = starttime
            
            # Set dirty flag
            self.suDict[sunumStr]['dirty'] = True
    def incrementRefcount(self, sunums):
        for asunum in sunums:
            sunumStr = str(sunum)
            
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', 'No SU-table record exists for SU ' + sunumStr + '.')
            
            self.suDict[sunumStr]['refcount'] += 1

    def decrementRefcount(self, sunums):
        toDel = []
        for asunum in sunums:
            sunumStr = str(asunum)

            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', 'No SU-table record exists for SU ' + sunumStr + '.')
            
            if self.suDict[sunumStr]['refcount'] == 0:
                raise Exception('noReference', 'Cannot decrement refcount on unreferenced SU record ' + sunumStr + '.')
                    
            self.suDict[sunumStr]['refcount'] -= 1
            if self.suDict[sunumStr]['refcount'] == 0:
                toDel.append(asunum)

        self.deleteDB(toDel)

    def get(self, sunums=None):
        toRet = []
        
        if not sunums:
            return self.suDict
        
        for asunum in sunums:
            sunumStr = str(asunum)
        
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', 'No SU-table record exists for SU ' + sunumStr + '.')

            toRet.append(self.suDict[sunumStr])

        return toRet

    # Returns a dictionary of SU records.
    def getPending(self):
        pending = []
        
        for sunumStr in self.suDict.iterkeys():
            if self.suDict[sunumStr]['status'] == 'P':
                pending.append(self.suDict[sunumStr])

        # Sorts in place - and returns None.
        pending.sort(key=lambda(dict) : dict['sunum'])

        return pending

    def getTimeout(self):
        return self.timeOut

    @classmethod
    def offline(cls, sunums, binPath, log):
        # There is not an efficient way to check for the SU being on/offline. But we can use jsoc_fetch (vs. show_info - jsoc_fetch returns
        # JSON, which is handy). And it also can be called in a mode where it does not trigger a SUM_get() - it uses SUM_infoAns():
        #   op=exp_su requestid=NOASYNCREQUEST sunum=123456789 format=json formatvar=dataobj method=url_quick protocol=as-is
        cmd = [binPath + '/jsoc_fetch', 'op=exp_su', 'requestid=NOASYNCREQUEST', 'format=json', 'formatvar=dataobj', 'method=url_quick', 'protocol=as-is', 'sunum=' + ','.join([str(asunum) for asunum in sunums])]
        log.write(['Checking online disposition: ' + ' '.join(cmd)])
        
        try:
            resp = check_output(cmd)
            output = resp.decode('utf-8')
            lines = output.split('\n')
        
        except ValueError:
            raise Exception('findOffline', "Unable to run command: '" + ' '.join(cmd) + "'.")
        except CalledProcessError as exc:
            raise Exception('findOffline', "Command '" + ' '.join(cmd) + "' returned non-zero status code " + str(exc.returncode))
        
        jsonRsp = []
        offline = []
        
        # output is not strictly JSON. There is an HTTP header we need to remove.
        regExp = re.compile(r'Content-type')
        for line in lines:
            if len(line) == 0:
                continue
            match = regExp.match(line)
            if match:
                continue
            jsonRsp.append(line)
        
        jsonObj = json.loads(''.join(jsonRsp))
        for sunum in jsonObj['data']:
            if jsonObj['data'][sunum]['sustatus'] == 'N':
                offline.append(sunum)
        
        return offline

class ReqTable:
    cursor = None
    
    def __init__(self, tableName, timeOut):
        self.tableName = tableName
        self.timeOut = timeOut
        self.reqDict = {}
    
    @classmethod
    def setCursor(cls, cursorIn):
        cls.cursor = cursorIn
    
    def read(self):
        # requests(requestid, starttime, sunums, status, errmsg)
        cmd = 'SELECT requestid, starttime, sunums, status, errmsg FROM ' + self.tableName
        
        try:
            cursor.execute(cmd)
        
        except psycopg2.Error as exc:
            raise Exception('reqtableRead', exc.diag.message_primary, cmd)
        
        for record in cursor:
            requestidStr = str(record[0])

            self.reqDict[requestidStr] = {}
            self.reqDict[requestidStr]['requestid'] = record[0]
            # Whoa! pyscopg returns timestamps as datetime.datetime objects already!
            self.reqDict[requestidStr]['starttime'] = record[1]
            self.reqDict[requestidStr]['sunums'] = [int(asunum) for asunum in record[2].split(',')]
            self.reqDict[requestidStr]['status'] = record[3]
            self.reqDict[requestidStr]['errmsg'] = record[4]
            self.reqDict[requestidStr]['dirty'] = False

    # This method finds 'N' records inserted since the last time it was run (or since the table was first read). It ignores
    # all other changes to the database table (made from outside this program) that have happened. To read those changes,
    # shut down this program, then make the changes, then start this program again.
    def refresh(self):
        if not cursor:
            raise Exception('noCursor', 'Cannot refresh the requests table because no database cursor exists.')
        
        updatedTable = ReqTable(self.tableName, self.timeOut)
        newRequests = updatedTable.getNew()

        for arequest in newRequests:
            try:
                self.get((arequest['requestid']))
            except Exception as exc:
                if len(exc.args) != 2:
                    raise # Re-raise

                etype = exc.args[0]

                if etype == 'unknownRequestid':
                    # arequest is a request that has been added tot the request db table since the last time refresh was run.
                    requestidStr = arequest['requestid']
                    self.reqDict[requestidStr] = {}
                    self.reqDict[requestidStr]['requestid'] = requestidStr # Strings are immutable, so copying the reference is ok.
                    self.reqDict[requestidStr]['starttime'] = deepcopy(arequest['starttime'])
                    self.reqDict[requestidStr]['sunums'] = deepcopy(arequest['sunums'])
                    self.reqDict[requestidStr]['status'] = arequest['status']
                    self.reqDict[requestidStr]['errmsg'] = arequest['errmsg']
                    self.reqDict[requestidStr]['dirty'] = False
                    
                else:
                    raise # Re-raise

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes.
    def updateDB(self, requestids=None):
        if requestids:
            # Update the specified records.
            for arequestid in requestids:
                requestidStr = str(requestid)
            
                if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                    raise Exception('unknownRequestid', 'No request-table record exists for ID ' + requestidStr + '.')
                
                if self.reqDict[requestidStr]['dirty']:
                    cmd = 'UPDATE ' + self.tableName + " SET starttime='" + self.reqDict[requestidStr]['starttime'].strftime('%Y-%m-%d %T') + "', sunums=" + ','.join(self.reqDict[requestidStr]['sunums']) + ", status='" + self.reqDict[requestidStr]['status'] + "', errmsg='" + self.reqDict[requestidStr]['errmsg'] + "' WHERE requestid=" + requestidStr
                    
                    try:
                        cursor.execute(cmd)
                    
                    except psycopg2.Error as exc:
                        raise Exception('reqtableWrite', exc.diag.message_primary)
                    
                    self.reqDict[requestidStr]['dirty'] = False
        else:
            # Update all dirty records.
            for requestidStr in self.reqDict:
                if self.reqDict[requestidStr]['dirty']:
                    cmd = 'UPDATE ' + self.tableName + " SET starttime='" + self.reqDict[requestidStr]['starttime'].strftime('%Y-%m-%d %T') + "', sunums='" + ','.join([str(asunum) for asunum in self.reqDict[requestidStr]['sunums']]) + "', status='" + self.reqDict[requestidStr]['status'] + "', errmsg='" + self.reqDict[requestidStr]['errmsg'] + "' WHERE requestid='" + requestidStr + "'"
                    
                    try:
                        cursor.execute(cmd)
                    
                    except psycopg2.Error as exc:
                        raise Exception('reqtableWrite', exc.diag.message_primary)
                    
                    self.reqDict[requestidStr]['dirty'] = False

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes.
    def deleteDB(self, requestids):
        if len(requestids) > 0:
            for arequestid in requestids:
                requestidStr = str(requestid)
                
                if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                    raise Exception('unknownRequestid', 'No request-table record exists for ID ' + requestidStr + '.')

                del self.reqDict[requestidStr]
            
            reqidLstStr = ','.join(requestids)
            
            cmd = 'DELETE FROM ' + self.tableName + ' WHERE requestid=' + reqidLstStr
            
            try:
                cursor.execute(cmd)
            
            except psycopg2.Error as exc:
                raise Exception('reqtableWrite', exc.diag.message_primary + ': ' + cmd)
        
    def setStatus(self, requestids, code, msg=None):
        for arequestid in requestids:
            requestidStr = str(arequestid)
        
            if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                raise Exception('unknownRequestid', 'No request-table record exists for ID ' + requestidStr + '.')
            
            self.reqDict[requestidStr]['status'] = code
            if msg:
                self.reqDict[requestidStr]['errmsg'] = msg
            else:
                self.reqDict[requestidStr]['errmsg'] = ''
            
            # Set dirty flag
            self.reqDict[requestidStr]['dirty'] = True

    def get(self, requestids=None):
        toRet = []
    
        if not requestids:
            return self.reqDict
        
        for arequestid in requestids:
            requestidStr = str(requestid)
            
            if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                raise Exception('unknownRequestid', 'No request-table record exists for ID ' + requestidStr + '.')
    
            toRet.append(self.reqDict[requestidStr])
    
        return toRet
    
    def getPending(self):
        pendLst = []
    
        for requestidStr in self.reqDict.iterkeys():
            if self.reqDict[requestidStr]['status'] == 'P':
                pendLst.append(self.reqDict[requestidStr])
    
        # Sort by start time. Sorts in place - and returns None.
        pendLst.sort(key=lambda(dict): dict['starttime'].strftime('%Y-%m-%d %T'))
            
        return pendLst
    
    def getNew(self):
        newLst = []
        
        for requestidStr in self.reqDict.iterkeys():
            if self.reqDict[requestidStr]['status'] == 'N':
                newLst.append(self.reqDict[requestidStr])
        
        # Sort by start time. Sorts in place - and returns None.
        newLst.sort(key=lambda(dict): dict['starttime'].strftime('%Y-%m-%d %T'))

        return newLst

    def getDelete(self):
        deleteLst = []

        for requestidStr in self.reqDict.iterkeys():
            if self.reqDict[requestidStr]['status'] == 'D':
                deleteLst.append(self.reqDict[requestidStr])

        deleteLst.sort(key=lambda(dict): dict['requestid'])

        return deleteLst

    def getTimeout(self):
        return self.timeOut

# The site information is stored in a public database table at Stanford. It is accessible by all remote sites
# with the sites.py cgi. To obtain information about all sites, the sites.py cgi is called with no parameters.
# Otherwise, information about a single site can be obtained by by providing the site name to the 'site' argument.
# The information is stored in drms.rs_sites on hmidb.
class SiteTable:
    def __init__(self, log):
        self.log = log
        self.siteDict = {} # Keyed by name.
        self.siteMap = {} # Map from str(code) to name.

    def read(self):
        url = 'http://jsoc.stanford.edu/cgi-bin/rssites.sh'
        req = urllib2.Request(url)
        response = urllib2.urlopen(req)
        siteInfoStr = response.read()

        # siteInfoStr is a string, that happens to be json.
        siteInfo = json.loads(siteInfoStr)
        
        if siteInfo['status'] != 'success':
            raise Exception('badCgi', "Failure calling cgi '" + url + "'.")

        # siteInfo is a dictionary, keyed by site name. Each dictionary entry is a dictionay, with two keys: code and baseurl.
        for asite in siteInfo.iterkeys():
            if asite == 'status':
                # Skip status.
                continue
            self.siteDict[asite] = {}
            self.siteDict[asite]['name'] = asite
            self.siteDict[asite]['code'] = siteInfo[asite]['code']
            self.siteDict[asite]['baseurl'] = siteInfo[asite]['baseurl']
            self.siteMap[str(self.siteDict[asite]['code'])] = asite

            self.log.write(['Reading site info for ' + asite + ': code => ' + str(self.siteDict[asite]['code']) + ', baseurl => ' + self.siteDict[asite]['baseurl']])

    @staticmethod
    def getCode(sunum):
        code = sunum >> 48
        if code & 0xC000 != 0:
            raise Exception('badSunum', 'The site-code value of SUNUM ' + sunum + ' is out of range (valid range is 0 to 16383).')

        return code

    def getURL(self, sunum):
        code = SiteTable.getCode(sunum)
        
        if not str(code) in self.siteMap or not self.siteMap[str(code)]:
            raise Exception('unknownSitecode', 'There is no site in the site table for code ' + str(code) + '.')
        
        name = self.siteMap[str(code)]
        url = self.siteDict[name]['baseurl']
        return url

class Chunker(object):
    def __init__(self, list, chSize):
        self.chunks = []
        iChunk = -1
        nElem = 1
        
        for elem in list:
            if iChunk == -1 or nElem % chSize == 0:
                iChunk += 1
                self.chunks.append([])
    
            self.chunks[iChunk].append(elem)
            nElem += 1
    
    def __iter__(self):
        return self.iterate()
    
    # Iterate through chunks.
    def iterate(self):
        i = 0
        while i < len(self.chunks):
            yield self.chunks[i]
            i += 1

# Downloads a single SU. Ingests it into SUMs (SUMS allows to ingestion of a single SU at a time only.). Updates
# the SU table status for that SU.
class Downloader(threading.Thread):
    tList = [] # A list of running thread IDs.
    maxThreads = 16 # Default. Can be overriden with the Downloader.setMaxThreads() method.
    eventMaxThreads = threading.Event() # Event fired when the number of threads decreases.
    lock = threading.Lock() # Guard tList.

    def __init__(self, sunum, path, sus, scpUser, scpHost, scpPort, binPath, log):
        threading.Thread.__init__(self)
        self.sunum = sunum
        self.path = path
        self.suTable = sus
        self.scpUser = scpUser
        self.scpHost = scpHost
        self.scpPort = scpPort
        self.binPath = binPath
        self.log = log

    def run(self):
        dlDir = '/tmp/.su' + str(self.sunum)
        
        self.log.write(['Downloading SU [scp -r -P ' + self.scpPort + ' ' + self.scpUser + '@' + self.scpHost + ':' + self.path + '/* ' + dlDir])
        
        # Download the SU.
        try:
            # Don't forget to make the temporary directory first.
            self.log.write(['Creating temporary download directory ' + dlDir + '.'])
            os.mkdir(dlDir)
            
            cmdList = ['scp', '-r', '-P', self.scpPort, self.scpUser + '@' + self.scpHost + ':' + self.path + '/*', dlDir]
            try:
                check_call(cmdList)
            except CalledProcessError as exc:
                raise Exception('scp', "Command '" + ' '.join(cmdList) + "' returned non-zero status code " + str(exc.returncode))

            # ART - TEST; do not attempt to ingest into SUMS.
            if False:
                # Ingest the SUs into SUMS. size matters not...look at me...judge me by my size, do you?
                cmdList = [binPath + '/vso_sum_alloc', 'sunum=' + str(self.sunum), 'size=1024']
                try:
                    resp = check_output(cmdList)
                    output = resp.decode('utf-8')
                except CalledProcessError as exc:
                    raise Exception('vso_sum_alloc', "Command '" + ' '.join(cmdList) + "' returned non-zero status code " + str(exc.returncode) + '.')
                
                regExp = re.compile(r'.+sudir:(\S+)')
                matchObj = regExp.match(output)
                if matchObj is not None:
                    sudir = matchObj.group(1)
                else:
                    raise Exception('vso_sum_alloc', "Command '" + ' '.join(cmdList) + "' printed unexcepted output " + output + '.')
                
                cmdList = ['mv', '/tmp/.su' + str(self.sunum) + '/*', sudir]
                try:
                    check_call(cmdList)
                except CalledProcessError as exc:
                    raise Exception('mv', "Command '" + ' '.join(cmdList) + "' returned non-zero status code " + str(exc.returncode))
            
            # Remove temporary directory.
            # ART - TEST; need to uncomment this.
            # os.rmdir(dlDir)
            
            # Update SU table. Set SU-table record status to 'C'. Must first lock the SU table since we are modifying it. Also,
            # the state may not be 'P' due to some problem cropping up in the meantime. Only set to 'C' if the state is 'P'.
            self.suTable.acquireLock()
            try:
                su = self.suTable.get([self.sunum])
                if su[0]['status'] == 'P':
                    self.log.write(['Setting SU ' + str(self.sunum) + ' status to complete.'])
                    self.suTable.setStatus([self.sunum], 'C', None)
                    # Flush the change to disk.
                    self.suTable.updateDB()
            finally:
                # Always release lock.
                self.suTable.releaseLock()
            
            # This thread is about to terminate.
            
            # We need to check the class tList variable to update it, so we need to acquire the lock.
            Downloader.lock.acquire()
            try:
                Downloader.tList.remove(self) # This thread is no longer one of the running threads.
                if len(Downloader.tList) == Downloader.maxThreads - 1:
                    # Fire event so that main thread can add new SUs to the download queue.
                    Downloader.eventMaxThreads.set()
                    # Clear event so that main will block the next time it calls wait.
                    Downloader.eventMaxThreads.clear()
            finally:
                Downloader.lock.release()
        except Exception as exc:
            if len(exc.args) == 2:
                type = exc[0]
                msg = exc[1]
            else:
                raise

            if type == 'scp' or type == 'vso_sum_alloc' or type == 'mv':
                sus.setStatus(self.sunum, 'E', 'Error downloading storage unit ' + str(self.sunum) + ': ' + msg + '.')
    
    @staticmethod
    def newThread(sunum, path, sus, scpUser, scpHost, scpPort, binPath, log):
        Downloader.lock.acquire()
        try:
            dl = Downloader(sunum, path, sus, scpUser, scpHost, scpPort, binPath, log)
            dl.tList.append(dl)
        finally:
            Downloader.lock.release()
        dl.start()

    @classmethod
    def setMaxThreads(cls, maxThreads):
        cls.maxThreads = maxThreads

def getOption(val, default):
    if val:
        return val
    else:
        return default

def getArgs():
    istat = False
    optD = {}
    
    parser = CmdlParser(usage='%(prog)s [ -h ] [ sutable=<storage unit table> ] [ reqtable=<request table> ] [ --dbname=<db name> ] [ --dbhost=<db host> ] [ --dbport=<db port> ] [ --binpath=<executable path> ] [ --logfile=<base log-file name> ]')
    
    # Optional parameters - no default argument is provided, so the default is None, which will trigger the use of what exists in the configuration file
    # (which is drmsparams.py).
    parser.add_argument('r', 'reqtable', '--reqtable', help='The database table that contains records of the SU-request being processed. If provided, overrides default specified in configuration file.', metavar='<request unit table>', dest='reqtable')
    parser.add_argument('s', 'sutable', '--sutable', help='The database table that contains records of the storage units being processed. If provided, overrides default specified in configuration file.', metavar='<storage unit table>', dest='sutable')
    parser.add_argument('-N', '--dbname', help='The name of the database that contains the series table from which records are to be deleted.', metavar='<db name>', dest='dbname')
    parser.add_argument('-U', '--dbuser', help='The name of the database user account.', metavar='<db user>', dest='dbuser')
    parser.add_argument('-H', '--dbhost', help='The host machine of the database that contains the series table from which records are to be deleted.', metavar='<db host machine>', dest='dbhost')
    parser.add_argument('-P', '--dbport', help='The port on the host machine that is accepting connections for the database that contains the series table from which records are to be deleted.', metavar='<db host port>', dest='dbport')
    parser.add_argument('-b', '--binpath', help='The path to executables run by this daemon (e.g., vso_sum_alloc, vso_sum_put).', metavar='<executable path>', dest='binpath')
    parser.add_argument('-l', '--logfile', help='The base file name to use for logs.', metavar='<base file name>', dest='logfile')
    
    try:
        args = parser.parse_args()
          
    except Exception as exc:
        if len(exc.args) == 2:
            type = exc[0]
            msg = exc[1]
                  
            if type != 'CmdlParser-ArgUnrecognized' and type != 'CmdlParser-ArgBadformat':
                raise # Re-raise
                  
            print(msg, file=sys.stderr)
            istat = True
            optD = None
              
        else:
            raise # Re-raise
  
    if not istat:
        try:
            drmsParams = DRMSParams()
            if drmsParams is None:
                raise Exception('drmsParams', 'Unable to locate DRMS parameters file (drmsparams.py).')
            
            # Get configuration information.
            optD['cfg'] = drmsParams
            
            # Override defaults.
            optD['reqtable'] = getOption(args.reqtable, drmsParams.get('RS_REQUEST_TABLE'))
            optD['sutable'] = getOption(args.sutable, drmsParams.get('RS_SU_TABLE'))
            optD['dbname'] = getOption(args.dbname, drmsParams.get('RS_DBNAME'))
            optD['dbuser'] = getOption(args.dbname, drmsParams.get('RS_DBUSER'))
            optD['dbhost'] = getOption(args.dbhost, drmsParams.get('RS_DBHOST'))
            optD['dbport'] = int(getOption(args.dbport, drmsParams.get('RS_DBPORT')))
            optD['binpath'] = getOption(args.binpath, drmsParams.get('RS_BINPATH'))
            optD['lockfile'] = getOption(None, drmsParams.get('RS_LOCKFILE'))
            optD['dltimeout'] = int(getOption(None, drmsParams.get('RS_DLTIMEOUT')))
            optD['reqtimeout'] = int(getOption(None, drmsParams.get('RS_REQTIMEOUT')))
            optD['maxthreads'] = int(getOption(None, drmsParams.get('RS_MAXTHREADS')))
            optD['logdir'] = getOption(None, drmsParams.get('RS_LOGDIR'))
            optD['logfile'] = getOption(args.logfile, LOG_FILE_BASE_NAME)
    
        except Exception as exc:
            if len(exc.args) != 2:
                raise # Re-raise
        
            etype = exc.args[0]
            msg = exc.args[1]
        
            if etype == 'drmsParams':
                print('Error reading DRMS parameters: ' + msg, file=sys.stderr)
                istat = True
                optD = None
    
        except KeyError as exc:
            type, value, traceback = sys.exc_info()
            print(exc.strerror, file=sys.stderr)
            istat = True
            optD = None
    
    return optD

def filterSunums(sunumList, sus, jfPath):
    rv = []
    
    # Pass SUNUM only if it is offline and not being current processed.
    notBeingProcessed = [ sunum for sunum in sunumList if not sunum in sus ]
    if len(notBeingProcessed) > 0:
        # There is not an efficient way to check for the SU being on/offline. But we can use jsoc_fetch (vs. show_info - jsoc_fetch returns
        # JSON, which is handy). And it also can be called in a mode where it does not trigger a SUM_get() - it uses SUM_infoEx():
        #   op=exp_su requestid=NOASYNCREQUEST sunum=123456789 format=json formatvar=dataobj method=url_quick protocol=as-is
        cmd = jfPath + ' op=exp_su requestid=NOASYNCREQUEST format=json formatvar=dataobj method=url_quick protocol=as-is sunum=' + ','.join(notBeingProcessed)
    
        try:
            resp = check_output(cmd)
            output = resp.decode('utf-8')
    
        except ValueError:
            raise Exception('jfetch', "Unable to run command: '" + ' '.join(cmd) + "'.")
        except CalledProcessError as exc:
            raise Exception('jfetch', "Command '" + ' '.join(cmd) + "' returned non-zero status code " + str(exc.returncode))

        offline = []
        jsonObj = json.loads(output)
        for sunum in jsonObj['data']:
            if jsonObj['data'][sunum]['sustatus'] == 'N':
                offline.append(sunum)
                    
        rv = offline
    else:
        rv = notBeingProcessed

    return rv

def readTables(sus, requests, sites):
    nAtts = 0
    while True:
        try:
            sus.read()
            break
        except Exception as exc:
            if len(exc.args) != 2:
                raise # Re-raise
            
            etype = exc.args[0]

            if etype == 'sutableRead':
                if nAtts > 10:
                    raise # Re-raise
                nAtts += 1
                time.sleep(2)
                continue

    nAtts = 0
    while True:
        try:
            requests.read()
            break
        except Exception as exc:
            if len(exc.args) != 2:
                raise # Re-raise
            
            etype = exc.args[0]
            
            if etype == 'reqtableRead':
                if nAtts > 10:
                    raise # Re-raise
                nAtts += 1
                time.sleep(2)
                continue


    nAtts = 0
    while True:
        try:
            sites.read()
            break
        except Exception as exc:
            if len(exc.args) != 2:
                raise # Re-raise
            
            etype = exc.args[0]
            
            if etype == 'badCgi':
                if nAtts > 10:
                    raise # Re-raise
                nAtts += 1
                time.sleep(2)

# Process the SUs for the source site represented by url.
# url - the base URL to the rs.sh cgi (e.g., http://jsoc.stanford.edu/cgi-bin) from which SU paths can be obtained.
# sunums - a list of sorted SUNUMs to download.
# sus - the SU table object that represents the SU database table.
# binPath - the local path to the binaries needed to ingest the downloaded SU into SUMS. This is mostly likely the path to
#           the DRMS binaries (one binary needed is vso_sum_alloc)
def processSUs(url, sunums, sus, binPath, log, insertRec=True):
    rv = False
    
    # Get path to SUs by calling the rs.sh cgi at the owning remote site (url identifies the remote site).
    # Create the sunum= argument.
    sunumLst = ','.join(str(asunum) for asunum in sunums)
    values = {'requestid' : 'none', 'sunums' : sunumLst}
    data = urllib.urlencode(values)
    log.write(['Requesting paths for SUNUMs ' + sunumLst + '. URL is ' + url + '/rs.sh' + '?' + data])
    req = urllib2.Request(url + '/rs.sh', data)
    response = urllib2.urlopen(req)
    dlInfoStr = response.read()
    
    # ART - Check status.
    
    
    
    dlInfo = json.loads(dlInfoStr)

    paths = dlInfo['paths']

    # Start a download for each SU. If we cannot start the download for any reason, then set the SU status to 'E'.
    for (asunum, path) in paths:
        Downloader.lock.acquire()
        doWait = False
        try:
            if len(Downloader.tList) >= Downloader.maxThreads:
                doWait = True
        finally:
            Downloader.lock.release()
        
        if doWait:
            Downloader.eventMaxThreads.wait()

        Downloader.newThread(asunum, path, sus, dlInfo['scpUser'], dlInfo['scpHost'], dlInfo['scpPort'], binPath, log)

        # Create a new SU-table record for each SU in the sus table (or update the starttime of an existing one).
        if insertRec:
            sus.insert([asunum])
        else:
            sus.setStarttime(asunum, datetime.now())

    return rv


rv = RET_SUCCESS

if __name__ == "__main__":
    try:
        optD = getArgs()
        pid = os.getpid()
            
        with DrmsLock(optD['lockfile'], str(pid)) as lock:
            rslog = Log(optD['logdir'], optD['logfile'])

            # Connect to the database
            try:
                # The connection is NOT in autocommit mode. If changes need to be saved, then conn.commit() must be called.
                with psycopg2.connect(database=optD['dbname'], user=optD['dbuser'], host=optD['dbhost'], port=optD['dbport']) as conn:
                    with conn.cursor() as cursor:
                        suTable = optD['sutable']
                        reqTable = optD['reqtable']

                        sus = None
                        requests = None
                        sites = None

                        # Read the storage-unit and request tables. Do this only once per daemon run. However, we save this table
                        # information every iteration of the daemon loop, just in case a crash happens. After a crash, when
                        # the daemon starts up, it will retrieve the latest saved information so the disruption will be minimal.
                        # We will have to clean up any pending downloads since the threads managing those downloads will have
                        # been lost, and we cannot trust that the downloads completed successfully (although they might have).
                        # A fancier implementation would be some kind of download manager that can recover partially downloaded
                        # storage units, but who has the time :)
                        sus = SuTable(suTable, timedelta(minutes=optD['dltimeout']), rslog)
                        requests = ReqTable(reqTable, timedelta(minutes=optD['reqtimeout']))
                        sites = SiteTable(rslog)
                        
                        SuTable.setCursor(cursor)
                        ReqTable.setCursor(cursor)

                        # This function will try to read each table 10 times before giving up (and raising an exception).
                        readTables(sus, requests, sites)

                        # Set max number of threads we can process at once.
                        Downloader.setMaxThreads(optD['maxthreads'])

                        # Recover pending downloads that got disrupted from a daemon crash. All SU downloads that are in the pending
                        # state at the time the tables are read were disrupted. There are no other threads running at this point.
                        susPending = sus.getPending()
                        
                        siteSunums = {}
                        for asu in susPending:
                            siteURL = sites.getURL(asu['sunum'])
                            
                            if siteURL not in siteSunums:
                                siteSunums[siteURL] = []

                            siteSunums[siteURL].append(asu['sunum'])

                        # There is no need to acquire the SU-table lock. processSUs() will start new threads that can modify the
                        # SU-record statuses, but by the time that happens, the main thread will be done reading those statuses.
                        for url in siteSunums.iterkeys():
                            if len(siteSunums[url]) > 0:
                                # Chunk is a list of SUNUMs (up to 64 of them).
                                siteSunums[url].sort()
                                chunker = Chunker(siteSunums[url], 64)
                                for chunk in chunker:
                                    # processSUs(..., insertRec=True) would attempt to insert a new record in the sus table for each SUNUM. By
                                    # setting the last insertRec argument to False, we merely update the existing
                                    # record's starttime value.
                                    processSUs(url, chunk, sus, optD['binpath'], rslog, False)
                    
                        # I think this is how you make it possible to pass arguments to your signal handler - define the function
                        # in the scope where the variables you want to use are visible. terminator is a closure where
                        # requests, sus, and cursor are defined.
                        shutDown = False
                        def terminator(*args):
                            global shutDown
                            global rslog
                            
                            rslog.write(['Termination signal handler called. Saving the db-table caches.'])
                            shutDown = True

                        signal.signal(signal.SIGINT, terminator)
                        signal.signal(signal.SIGTERM, terminator)
                        
                        # Start of main loop.
                        while True and not shutDown:
                            # Always lock the SU table first and do all processing that requires this lock first.
                            sus.acquireLock()
                            try:
                                # For each P SU in the SU table, see if it is time to time-out. susPending are ordered by SUNUM.
                                # I guess we could process more than one SuTable, but for now, let's assume there is only one such
                                # table.
                                susPending = sus.getPending()
                                for asu in susPending:
                                    timeNow = datetime.now(asu['starttime'].tzinfo)
                                    if timeNow > asu['starttime'] + sus.getTimeout():
                                        rslog.write('Download of SUNUM ' + str(asu['sunum']) + ' timed-out.')
                                        sus.setStatus([asu['sunum']], 'E', 'Download timed-out.')
                            
                                cursor.execute('BEGIN')
                                sus.updateDB()
                                cursor.execute('END')
                            
                                # Ignore SUs in the other states (C or E). These will be checked in other parts of the code.
                                
                                # For each 'P' request in the request table, check to see if the requested downloads have completed yet.
                                reqsPending = requests.getPending()
                                for arequest in reqsPending:
                                    done = True
                                    reqError = False
                                    sunums = arequest['sunums']
                                    for asunum in sunums:
                                        if done == False and reqError == True:
                                            break
                                        asu = sus.get([asunum])
                                        if asu[0]['status'] == 'P':
                                            done = False
                                        elif asu[0]['status'] == 'E':
                                            reqError = True
                                    
                                    if done:
                                        # There are no pending downloads for this request. Set this request's status to 'C' or 'E', and decrement
                                        # refcount on each SU.
                                        if reqError:
                                            rslog.write(['Request number ' + str(arequest['requestid']) + ' errored-out.'])
                                            requests.setStatus([arequest['requestid']], 'E', 'Error downloading at least one SU.')
                                        else:
                                            rslog.write(['Request number ' + str(arequest['requestid']) + ' completed successfully.'])
                                            requests.setStatus([arequest['requestid']], 'C')

                                        # These next two calls can modify the db state! Put them in a transaction so that they form an atomic
                                        # operation. We do not want an interruption to cause the first to happen, but not the second.
                                        cursor.execute('BEGIN')
                                        requests.updateDB()
                                        sus.decrementRefcount(sunums)
                                        cursor.execute('END')
                
                                # For each 'N' request in the request table, start a new set of downloads (if there is no download currently running -
                                # i.e., no SU record) or increment the refcounts on the downloads (if there are downloads currently running - i.e.,
                                # an SU record exists). But Before starting a new download, make sure that requested SU is not already online.
                                # Due to race conditions, a request could have caused a download to occur needed by another request whose state is 'N'.
                                requests.refresh() # Clients may have added requests to the queue.
                                
                                reqsNew = requests.getNew()
                                for arequest in reqsNew:
                                    timeNow = datetime.now(arequest['starttime'].tzinfo)
                                    if timeNow > arequest['starttime'] + requests.getTimeout():
                                        rslog.write(['Request number ' + str(arequest['requestid']) + ' timed-out.'])
                                        requests.setStatus([arequest['requestid']], 'E', 'Request timed-out.')
                                        cursor.execute('BEGIN')
                                        requests.updateDB()
                                        cursor.execute('END')
                                        continue
                                    
                                    sunums = arequest['sunums']
                                    rslog.write(['Found a new download request, id ' + str(arequest['requestid']) + ' for SUNUMs ' + ','.join([str(asunum) for asunum in sunums]) + '.'])
                                    
                                    # Get all SU records for which a download is already in progress.
                                    unknown = []
                                    known = []
                                    for asunum in sunums:
                                        try:
                                            asu = sus.get([asunum])
                                        except Exception as exc:
                                            if len(exc.args) != 2:
                                                raise # Re-raise
                                                
                                            etype = exc.args[0]
                                            msg = exc.args[1]
                    
                                            if etype == 'unknownSunum':
                                                unknown.append(asunum)
                                                continue
                                                
                                        raise # Re-raise
                                        
                                        known.append(asunum)
                                
                                    # Increment the refcount on all SU records for the SUs being requested by the new request. This modifies the
                                    # sus object.
                                    sus.incrementRefcount(known)
                                    
                                    offlineSunums = SuTable.offline(unknown, optD['binpath'], rslog)
                                    
                                    # ART - TEST; force all unknown to offline so we can start downloads.
                                    offlineSunums = [asunum for asunum in unknown]
                                    
                                    dlsToStart = []
                                    toComplete = []
                                    for asunum in unknown:
                                        if asunum in offlineSunums:
                                            dlsToStart.append(asunum)
                                        else:
                                            toComplete.append(asunum)
                                    
                                    # Insert a new SU record for all unknown SUs that are already online. These calls modify the sus object.
                                    sus.insert(toComplete)
                                    sus.setStatus(toComplete, 'C')
                                        
                                    # Start downloads for all unknown, offline SUs
                                    siteSunums = {}
                                    for asunum in dlsToStart:
                                        siteURL = sites.getURL(asunum)
                                        
                                        if siteURL not in siteSunums:
                                            siteSunums[siteURL] = []
                                        
                                        siteSunums[siteURL].append(asunum)
                                        
                                    for url in siteSunums.iterkeys():
                                        if len(siteSunums[url]) > 0:
                                            # Chunk is a list of SUNUMs (up to 64 of them).
                                            siteSunums[url].sort()
                                            chunker = Chunker(siteSunums[url], 64)
                                            for chunk in chunker:
                                                # We want to always insert a record for each SU into the SU table. Do not provide the insertRec
                                                # argument to do so. This call creates new SU-table records, so it modifies the sus object.
                                                processSUs(url, chunk, sus, optD['binpath'], rslog)
                                    
                                    # The new request has been fully processed. Change its status from 'N' to 'P'.
                                    # This call modifies the requests object.
                                    requests.setStatus([arequest['requestid']], 'P')

                                    # At this point, both the requests and sus object have been modified, but have not been flushed to disk.
                                    # Flush them, but do this inside a transaction so that the first does not happen without the second.
                                    cursor.execute('BEGIN')
                                    sus.updateDB()
                                    requests.updateDB()
                                    cursor.execute('END')

                                # Delete all request-table records whose state is 'D'. It doesn't matter if this operation gets interrupted. If
                                # that happens, then these delete-pending records will be deleted the next time this code runs uninterrupted.
                                reqsToDelete = requests.getDelete()
                                requests.deleteDB(reqsToDelete)
                            finally:
                                # Always release the lock, even if an unhandled exception crops up.
                                sus.releaseLock()
                            
                            # Must poll for new requests to appear in requests table.
                            time.sleep(1)
                            # End of main loop.
                        
                        # Save the db state when exiting.
                        rslog.write(['Remote-sums daemon is exiting. Saving database tables.'])
                        cursor.execute('BEGIN')
                        sus.updateDB()
                        requests.updateDB()
                        cursor.execute('END')
        
            except psycopg2.DatabaseError as exc:
                # Closes the cursor and connection
                
                # Man, there is no way to get an error message from any exception object that will provide any information why
                # the connection failed.
                print('Unable to connect to the database (no, I do not know why).', file=sys.stderr)
    
                # No need to close cursor - leaving the with block does that.
                rv = RET_DBCONNECT

            except psycopg2.Error as exc:
                # Handle database-command errors.
                print(exc.diag.message_primary, file=sys.stderr)
                rv = RET_DBCOMMAND

        # Lock was released

    except Exception as exc:
        if len(exc.args) != 2:
            raise # Re-raise
        
        etype = exc.args[0]
        msg = exc.args[1]
        
        if etype == 'drmsLock':
            rslog.write(['Error locking file: ' + lockFile + '\n' + msg])
            rv = RET_LOCK
        elif etype == 'sutableRead':
            rslog.write(['Unable to read from storage-unit table: ' + msg])
            rv = RET_SUTABLE_READ
        elif etype == 'sutableWrite':
            rslog.write(['Unable to write to storage-unit table: ' + msg])
            rv = RET_SUTABLE_WRITE
        elif etype == 'reqtableRead':
            rslog.write(['Unable to read from storage-unit-request table: ' + msg])
            rv = RET_REQTABLE_READ
        elif etype == 'reqtableWrite':
            rslog.write(['Unable to write to storage-unit-request table: ' + msg])
            rv = RET_REQTABLE_WRITE
        elif etype == 'badLogfile':
            rslog.write(['Cannot access log file: ' + msg])
            rv = RET_LOGFILE
        elif etype == 'badLogwrite':
            rslog.write(['Cannot access log file: ' + msg])
            rv = RET_LOGFILE
        elif etype == 'findOffline':
            rslog.write(['Cannot determine online disposition: ' + msg])
            rv = RET_OFFLINE
        elif etype == 'unknownRequestid':
            rslog.write(['Oops! ' + msg])
            rv = RET_UKNOWNREQUEST
        elif etype == 'unknownSunum':
            rslog.write(['Oops! ' + msg])
            rv = RET_UKNOWNSU
        elif etype == 'noReference':
            rslog.write([msg])
            rv = RET_UKNOWNSU
        elif etype == 'unknownSitecode':
            rslog.write([msg])
            rv = RET_UKNOWNSITECODE
        elif etype == 'knownSunum':
            rslog.write([msg])
            rv = RET_DUPLICATESUNUM
        else:
            rslog.write(['Unhandled exception. Remote-sums daemon is exiting. Rolling back uncommitted database changes. '])
            raise # Re-raise

sys.exit(rv)
