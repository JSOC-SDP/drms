#!/usr/bin/env python

from __future__ import print_function
import sys
import re
import os
import stat
import filecmp
import thread
import psycopg2
import threading
import fcntl
from datetime import datetime, timedelta
import urllib
import urllib2
import json
import signal
import time
from copy import deepcopy
import shutil
import psycopg2
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../../../include'))
from drmsparams import DRMSParams
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../../../base/libs/py'))
from drmsCmdl import CmdlParser
from drmsLock import DrmsLock
from subprocess import check_output, check_call, CalledProcessError, Popen

# This script runs as a daemon at the site that has requested an SU that does not belong to the site. It is responsible for contacting
# the owning site and requesting the path to the desired SUs. The owning site must be running the rs.sh CGI to respond to the requesting
# site's request.

# There are three database tables: 1., a DRMS site table, 2., a request table, and 3., an SU table (sunum, starttime, status, errmsg)
# The site table (sitename, sitecode, baseurl) provides
# the information needed to query the providing site for the information needed to scp the requested SUs to the requesting site. The URL to the cgi
# program that provides scp information is formed by appending "rs.py" to baseurl. There are two parameters for this cgi: 1., "requestid", and 2., "sunums".
# During the initial request to the providing site, the requesting site will provide a requestid of "none", and a comma-separated list of SUNUMs
# in the sunums argument. Should the providing site have all the requested SUs online, then it will return the scp information needed to access those
# SUs, and a status of "complete". If, however, the SUs are not all online, the initial request will start an asynchronous tape-read of the offline SUs,
# returning a request ID that identifies the initial request, and a status of "pending". The requesting site must then poll for completion by
# periodically calling the cgi with a status request. To make a status request, the requestid argument contains the requestid returned by the
# inital CGI call, and the sunums argument contains "none". While the data are not ready, the status request returns a status of "pending". When
# the data are online, the status request returns a status of "complete".
#
# The request table (requestid, sunums, status) is populated by drms_storageunit.c. For all SUs that are offline and are not owned by the running
# DRMS/SUMS, the code inserts a record into the request table. The requestid is a UUID (within the running DRMS/SUMS) generated by a sequence table.
# The list of SUNUMs is put in sunums, and the initial status is set to 'N' (New request). drms_storageunit.c chunks such SUNUMs into
# manageable-sized requests. After inserting one or more such records into the request table, drms_storageunit.c then polls these records,
# waiting for the status to become 'C' (Complete request). After that happens, drms_storageunit.c then calls SUM_get() again on these SUs
# to obtain their paths. This daemon, rsumsd.py, periodically and reads all records in the request table. For each SU in each 'N' record
# (a single request, which could be requesting multiple SUs) the daemon first checks if the SU is already being processed. If so, then
# the SU table is not modified. The status of the record in the request table is set to 'P'. If the SU is not in the SU table, then
# this can mean one of two things. The daemon has never processed this SU, or the daemon has already processed this SU. When the daemon has completed
# processing an SU, it deletes the record for the SU from the SU table. If the latter is true, the daemon should not re-process the same SU. To distinguish
# between these two possibilities, the daemon first checks to see if the SU is already present in SUMS (it calls show_info -o sunum=SUNUM).
# If the SU is online, then the daemon does nothing. But if it is offline, then the daemon inserts a record for the SU into the SU table, and starts
# processing that SU. The status of that SU-table record is set to 'P', as is the status of the request record containing that SUNUM.
#
# For each SU in each 'P' request record, the daemon searches for records in the SU table. If one or more such records exist in the SU table, then
# the request record is left in the pending state. The next time the daemon scans the request records, it will again check the SU table looking
# for completion of all SUs. When that occurs, the status of the request record is set to 'C', indicating that the request is complete. The
# drms_storageunit.c code will then call SUMS to get the newly created paths to the requested SUs.

RET_SUCCESS = 0
RET_INVALIDARGS = 1
RET_LOCK = 2
RET_SUTABLE_READ = 3
RET_SUTABLE_WRITE = 4
RET_REQTABLE_READ = 5
RET_REQTABLE_WRITE = 6
RET_SITETABLE_LOAD = 7
RET_DBCOMMAND = 8
RET_LOGFILE = 9
RET_OFFLINE = 10
RET_GETRETENTION = 11
RET_UKNOWNREQUEST = 12
RET_UKNOWNSU = 13
RET_UKNOWNSITECODE = 14
RET_DUPLICATESUNUM = 15
RET_DBUPDATE = 16

LOG_FILE_BASE_NAME = 'rslog'

class SumsDrmsParams(DRMSParams):
    def __init__(self):
        super(SumsDrmsParams, self).__init__()

    def get(self, name):
        val = super(SumsDrmsParams, self).get(name)

        if val is None:
            raise Exception('drmsParams', 'Unknown DRMS parameter: ' + name + '.')
        return val


class Arguments(object):

    def __init__(self, parser):
        # This could raise in a few places. Let the caller handle these exceptions.
        self.parser = parser
        
        # Parse the arguments.
        self.parse()
        
        # Set all args.
        self.setAllArgs()
        
    def parse(self):
        try:
            self.parsedArgs = self.parser.parse_args()      
        except Exception as exc:
            if len(exc.args) == 2:
                type, msg = exc
                  
                if type != 'CmdlParser-ArgUnrecognized' and type != 'CmdlParser-ArgBadformat':
                    raise # Re-raise

                raise Exception('args', msg)
            else:
                raise # Re-raise

    def setArg(self, name, value):
        if not hasattr(self, name):
            # Since Arguments is a new-style class, it has a __dict__, so we can
            # set attributes directly in the Arguments instance.
            setattr(self, name, value)
        else:
            raise Exception('args', 'Attempt to set an argument that already exists: ' + name + '.')

    def setAllArgs(self):
        for key,val in list(vars(self.parsedArgs).items()):
            self.setArg(key, val)
        
    def getArg(self, name):
        try:
            return getattr(self, name)
        except AttributeError as exc:
            raise Exception('args', 'Unknown argument: ' + name + '.')

class Log(object):
    """Manage a logfile."""

    def __init__(self, file):
        self.fileName = file
        self.fobj = None
        
        try:
            head, tail = os.path.split(file)

            if not os.path.isdir(head):
                os.mkdir(head)
            fobj = open(self.fileName, 'a')
        except OSError as exc:
            type, value, traceback = sys.exc_info()
            raise Exception('badLogfile', 'Unable to access ' + "'" + value.filename + "'.")
        except IOError as exc:
            type, value, traceback = sys.exc_info()
            raise Exception('badLogfile', 'Unable to open ' + "'" + value.filename + "'.")
        
        self.fobj = fobj

    def __del__(self):
        if self.fobj:
            self.fobj.close()

    def write(self, text):
        try:
            lines = ['[' + datetime.now().strftime('%Y-%m-%d %T') + '] ' + line + '\n' for line in text]
            self.fobj.writelines(lines)
            self.fobj.flush()
        except IOError as exc:
            type, value, traceback = sys.exc_info()
            raise Exception('badLogwrite', 'Unable to write to ' + value.filename + '.')

class SuTable:
    cursor = None
                
    def __init__(self, tableName, timeOut, log):
        self.tableName = tableName
        self.timeOut = timeOut # A timedelta object - the length of time to wait for a download to complete.
        self.lock = thread.allocate_lock()
        self.locked = False
        self.log = log
        self.suDict = {}
    
    def __del__(self):
        if self.locked:
            self.lock.release()
    
    @classmethod
    def setCursor(cls, cursorIn):
        cls.cursor = cursorIn

    def read(self):
        # sus(sunum, starttime, refcount, status, errmsg)
        cmd = 'SELECT sunum, series, retention, starttime, refcount, status, errmsg FROM ' + self.tableName
    
        try:
          cursor.execute(cmd)
    
        except psycopg2.Error as exc:
            raise Exception('sutableRead', exc.diag.message_primary)
    
        for record in cursor:
            sunumStr = str(record[0])
            
            self.suDict[sunumStr] = {}
            self.suDict[sunumStr]['sunum'] = record[0]         # integer
            self.suDict[sunumStr]['series'] = record[1]        # text
            self.suDict[sunumStr]['retention'] = record[2]     # integer
            # Whoa! pyscopg returns timestamps as datetime.datetime objects already!
            self.suDict[sunumStr]['starttime'] = record[3]     # datetime.datetime
            self.suDict[sunumStr]['refcount'] = record[4]      # integer
            self.suDict[sunumStr]['status'] = record[5]        # text
            self.suDict[sunumStr]['errmsg'] = record[6]        # text
            self.suDict[sunumStr]['dirty'] = False
            self.suDict[sunumStr]['new'] = False
            self.suDict[sunumStr]['polling'] = False

    def tryRead(self):
        nAtts = 0
        while True:
            try:
                self.read()
                break
            except Exception as exc:
                if len(exc.args) != 2:
                    raise # Re-raise

                etype = exc.args[0]

                if etype == 'sutableRead':
                    if nAtts > 10:
                        raise # Re-raise
                else:
                    raise

            nAtts += 1
            time.sleep(1)

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes.
    def updateDB(self, sunums=None):
        if sunums:
            # Update a subset of all records.
            for asunum in sunums:
                sunumStr = str(asunum)
           
                if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                    raise Exception('unknownSunum', '(updateDB) No SU-table record exists for SU ' + sunumStr + '.')
            
                if self.suDict[sunumStr]['dirty']:
                    if self.suDict[sunumStr]['new'] == True:
                        cmd = 'INSERT INTO ' + self.tableName + '(sunum, series, retention, starttime, refcount, status, errmsg) VALUES(' + sunumStr + ",'" + self.suDict[sunumStr]['series'] + "', " + str(self.suDict[sunumStr]['retention']) + ", '" + self.suDict[sunumStr]['starttime'].strftime('%Y-%m-%d %T') + "', " + str(self.suDict[sunumStr]['refcount']) + ", '" + self.suDict[sunumStr]['status'] + "', '" + self.suDict[sunumStr]['errmsg'] + "')"
                    else:
                        # The fields excluded from the update statement are not modified once set.
                        cmd = 'UPDATE ' + self.tableName + " SET series='" + self.suDict[sunumStr]['series'] + "', retention=" + str(self.suDict[sunumStr]['retention']) + ", starttime='" + self.suDict[sunumStr]['starttime'].strftime('%Y-%m-%d %T') + "', refcount=" + str(self.suDict[sunumStr]['refcount']) + ", status='" + self.suDict[sunumStr]['status'] + "', errmsg='" + self.suDict[sunumStr]['errmsg'] + "' WHERE sunum=" + sunumStr
                
                    self.log.write(['Updating SU db table: ' + cmd])
                
                    try:
                        cursor.execute(cmd)
            
                    except psycopg2.Error as exc:
                        raise Exception('sutableWrite', exc.diag.message_primary)
                
                    self.suDict[sunumStr]['dirty'] = False
                    self.suDict[sunumStr]['new'] = False
        else:
            # Update all dirty records.
            for sunumStr in self.suDict:
                if self.suDict[sunumStr]['dirty']:
                    if self.suDict[sunumStr]['new'] == True:
                        cmd = 'INSERT INTO ' + self.tableName + '(sunum, series, retention, starttime, refcount, status, errmsg) VALUES(' + sunumStr + ",'" + self.suDict[sunumStr]['series'] + "', " + str(self.suDict[sunumStr]['retention']) + ", '" + self.suDict[sunumStr]['starttime'].strftime('%Y-%m-%d %T') + "', " + str(self.suDict[sunumStr]['refcount']) + ", '" + self.suDict[sunumStr]['status'] + "', '" + self.suDict[sunumStr]['errmsg'] + "')"
                    else:
                        cmd = 'UPDATE ' + self.tableName + " SET series='" + self.suDict[sunumStr]['series'] + "', retention=" + str(self.suDict[sunumStr]['retention']) + ", starttime='" + self.suDict[sunumStr]['starttime'].strftime('%Y-%m-%d %T') + "', refcount=" + str(self.suDict[sunumStr]['refcount']) + ", status='" + self.suDict[sunumStr]['status'] + "', errmsg='" + self.suDict[sunumStr]['errmsg'] + "' WHERE sunum=" + sunumStr
                    
                    self.log.write(['Updating SU db table: ' + cmd])
                    
                    try:
                        cursor.execute(cmd)
                    
                    except psycopg2.Error as exc:
                        raise Exception('sutableWrite', exc.diag.message_primary)
                    
                    self.suDict[sunumStr]['dirty'] = False
                    self.suDict[sunumStr]['new'] = False

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes.
    def deleteDB(self, sunums):
        if len(sunums) > 0:
            # Delete the in-memory cache of these sunums
            for asunum in sunums:
                sunumStr = str(asunum)
                
                if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                    raise Exception('unknownSunum', '(deleteDB) No SU-table record exists for SU ' + sunumStr + '.')

                del self.suDict[sunumStr]
            
            sunumLstStr = ','.join([str(asunum) for asunum in sunums])
        
            cmd = 'DELETE FROM ' + self.tableName + ' WHERE sunum IN (' + sunumLstStr + ')'
        
            try:
                cursor.execute(cmd)
                
            except psycopg2.Error as exc:
                raise Exception('sutableWrite', exc.diag.message_primary)

    def acquireLock(self):
        self.lock.acquire()
        # self.log.write(['Acquired SU-Table lock.'])
        self.locked = True
    
    def releaseLock(self):
        if self.locked:
            self.lock.release()
            # self.log.write(['Released SU-Table lock.'])
            self.locked = False
    
    def insert(self, sunums):
        for asunum in sunums:
            sunumStr = str(asunum)
        
            if sunumStr in self.suDict:
                raise Exception('knownSunum', 'SU-table record already exists for SU ' + sunumStr + '.')
        
            self.suDict[sunumStr] = {}
            self.suDict[sunumStr]['sunum'] = asunum
            self.suDict[sunumStr]['series'] = ''
            self.suDict[sunumStr]['retention'] = -1
            self.suDict[sunumStr]['starttime'] = datetime.now()
            self.suDict[sunumStr]['refcount'] = 1
            self.suDict[sunumStr]['status'] = 'P'
            self.suDict[sunumStr]['errmsg'] = ''

            # Set dirty flag
            self.suDict[sunumStr]['dirty'] = True

            # Set the new flag (so that the record will be INSERTed into the SU database table instead of UPDATEd).
            self.suDict[sunumStr]['new'] = True

            # The polling flag is set only while we are waiting for a providing site to give us paths for SUs.
            self.suDict[sunumStr]['polling'] = False

    def setStatus(self, sunums, code, msg=None):
        for asunum in sunums:
            sunumStr = str(asunum)
        
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', '(setStatus) No SU-table record exists for SU ' + sunumStr + '.')
        
            self.suDict[sunumStr]['status'] = code
            if msg is not None:
                self.suDict[sunumStr]['errmsg'] = msg
            else:
                self.suDict[sunumStr]['errmsg'] = ''

            # Set dirty flag
            self.suDict[sunumStr]['dirty'] = True

    def setSeries(self, sunums, series):
        for asunum in sunums:
            sunumStr = str(asunum)
            
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', '(setSeries) No SU-table record exists for SU ' + sunumStr + '.')
            
            self.suDict[sunumStr]['series'] = series
            
            # Set dirty flag
            self.suDict[sunumStr]['dirty'] = True

    def setRetention(self, sunums, retention):
        for asunum in sunums:
            sunumStr = str(asunum)
            
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', '(setRetention) No SU-table record exists for SU ' + sunumStr + '.')
            
            self.suDict[sunumStr]['retention'] = retention
            
            # Set dirty flag
            self.suDict[sunumStr]['dirty'] = True

    def setStarttime(self, sunums, starttime):
        for asunum in sunums:
            sunumStr = str(asunum)
    
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', '(setStarttime) No SU-table record exists for SU ' + sunumStr + '.')
            
            self.suDict[sunumStr]['starttime'] = starttime
            
            # Set dirty flag
            self.suDict[sunumStr]['dirty'] = True
    def incrementRefcount(self, sunums):
        for asunum in sunums:
            sunumStr = str(asunum)
            
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', '(incrementRefcount) No SU-table record exists for SU ' + sunumStr + '.')
            
            self.suDict[sunumStr]['refcount'] += 1

    def decrementRefcount(self, sunums):
        toDel = []
        for asunum in sunums:
            sunumStr = str(asunum)

            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', '(decrementRefcount) No SU-table record exists for SU ' + sunumStr + '.')
            
            if self.suDict[sunumStr]['refcount'] == 0:
                raise Exception('noReference', 'Cannot decrement refcount on unreferenced SU record ' + sunumStr + '.')
                    
            self.suDict[sunumStr]['refcount'] -= 1
            if self.suDict[sunumStr]['refcount'] == 0:
                toDel.append(asunum)

        self.deleteDB(toDel)

    def get(self, sunums=None):
        toRet = []
        
        if not sunums:
            return self.suDict
        
        for asunum in sunums:
            sunumStr = str(asunum)
        
            if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                raise Exception('unknownSunum', '(get) No SU-table record exists for SU ' + sunumStr + '.')

            toRet.append(self.suDict[sunumStr])

        return toRet

    # Returns a dictionary of SU records.
    def getPending(self):
        pending = []
        
        for sunumStr in self.suDict.iterkeys():
            if self.suDict[sunumStr]['status'] == 'P':
                pending.append(self.suDict[sunumStr])

        # Sorts in place - and returns None.
        pending.sort(key=lambda(dict) : dict['sunum'])

        return pending

    def getTimeout(self):
        return self.timeOut

    @classmethod
    def offline(cls, sunums, binPath, log):
        # There is not an efficient way to check for the SU being on/offline. But we can use jsoc_fetch (vs. show_info - jsoc_fetch returns
        # JSON, which is handy). And it also can be called in a mode where it does not trigger a SUM_get() - it uses SUM_infoAns():
        #   op=exp_su requestid=NOASYNCREQUEST sunum=123456789 format=json formatvar=dataobj method=url_quick protocol=as-is
        rv = []        

        if len(sunums) > 0:
            cmd = [binPath + '/jsoc_fetch', 'op=exp_su', 'requestid=NOASYNCREQUEST', 'format=json', 'formatvar=dataobj', 'method=url_quick', 'protocol=as-is', 'sunum=' + ','.join([str(asunum) for asunum in sunums])]
            log.write(['Checking online disposition: ' + ' '.join(cmd)])
        
            try:
                resp = check_output(cmd)
                output = resp.decode('utf-8')
                lines = output.split('\n')
        
            except ValueError:
                raise Exception('findOffline', "Unable to run command: '" + ' '.join(cmd) + "'.")
            except CalledProcessError as exc:
                raise Exception('findOffline', "Command '" + ' '.join(cmd) + "' returned non-zero status code " + str(exc.returncode))
        
            jsonRsp = []
        
            # output is not strictly JSON. There is an HTTP header we need to remove.
            regExp = re.compile(r'Content-type')
            for line in lines:
                if len(line) == 0:
                    continue
                match = regExp.match(line)
                if match:
                    continue
                jsonRsp.append(line)
        
            jsonObj = json.loads(''.join(jsonRsp))
            for sunum in jsonObj['data']:
                # sustatus could be 'I' (the local SUMS knows nothing about this SU) or 'Y' (it is in the SUMS db, and it is online). It cannot be 'N' or 'X'
                # because if it were retrievable from tape, it would have been retrieved instead of finding its way into the requests table.
                if jsonObj['data'][sunum]['sustatus'] == 'I':
                    rv.append(sunum)
        return rv

class ReqTable:
    cursor = None
    
    def __init__(self, tableName, timeOut, log):
        self.tableName = tableName
        self.timeOut = timeOut
        self.log = log
        self.reqDict = {}
    
    @classmethod
    def setCursor(cls, cursorIn):
        cls.cursor = cursorIn
    
    def read(self):
        # requests(requestid, starttime, sunums, status, errmsg)
        cmd = 'SELECT requestid, dbhost, dbport, dbname, starttime, sunums, status, errmsg FROM ' + self.tableName
        
        try:
            cursor.execute(cmd)
        
        except psycopg2.Error as exc:
            raise Exception('reqtableRead', exc.diag.message_primary, cmd)
        
        for record in cursor:
            requestidStr = str(record[0])

            self.reqDict[requestidStr] = {}
            self.reqDict[requestidStr]['requestid'] = record[0] # integer
            self.reqDict[requestidStr]['dbhost'] = record[1]    # text
            self.reqDict[requestidStr]['dbport'] = record[2]    # integer
            self.reqDict[requestidStr]['dbname'] = record[3]    # text
            # Whoa! pyscopg returns timestamps as datetime.datetime objects already!
            self.reqDict[requestidStr]['starttime'] = record[4] # datetime.datetime
            self.reqDict[requestidStr]['sunums'] = [int(asunum) for asunum in record[5].split(',')] # text (originally)
            self.reqDict[requestidStr]['status'] = record[6]    # text
            self.reqDict[requestidStr]['errmsg'] = record[7]    # text
            self.reqDict[requestidStr]['dirty'] = False

    def tryRead(self):
        nAtts = 0
        while True:
            try:
                self.read()
                break
            except Exception as exc:
                if len(exc.args) != 2:
                    raise # Re-raise

                etype = exc.args[0]

                if etype == 'reqtableRead':
                    if nAtts > 10:
                        raise # Re-raise
                else:
                    raise

            nAtts += 1
            time.sleep(1)

    # This method finds 'N' records inserted since the last time it was run (or since the table was first read). It ignores
    # all other changes to the database table (made from outside this program) that have happened. To read those changes,
    # shut down this program, then make the changes, then start this program again.
    def refresh(self):
        if not cursor:
            raise Exception('noCursor', 'Cannot refresh the requests table because no database cursor exists.')
        
        # Delete existing items from self.
        self.reqDict = {}
        
        # Read the table from the database anew.
        self.tryRead()

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes.
    def updateDB(self, requestids=None):
        if requestids:
            # Update the specified records.
            for arequestid in requestids:
                requestidStr = str(arequestid)
            
                if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                    raise Exception('unknownRequestid', 'No request-table record exists for ID ' + requestidStr + '.')
                
                if self.reqDict[requestidStr]['dirty']:
                    # The only columns that this daemon will modify are status and errmsg.
                    cmd = 'UPDATE ' + self.tableName + " SET status='" + self.reqDict[requestidStr]['status'] + "', errmsg='" + self.reqDict[requestidStr]['errmsg'] + "' WHERE requestid=" + requestidStr
                    
                    try:
                        cursor.execute(cmd)
                    
                    except psycopg2.Error as exc:
                        raise Exception('reqtableWrite', exc.diag.message_primary)
                    
                    self.reqDict[requestidStr]['dirty'] = False
        else:
            # Update all dirty records.
            for requestidStr in self.reqDict:
                if self.reqDict[requestidStr]['dirty']:
                    # The only columns that this daemon will modify are status and errmsg.
                    cmd = 'UPDATE ' + self.tableName + " SET status='" + self.reqDict[requestidStr]['status'] + "', errmsg='" + self.reqDict[requestidStr]['errmsg'] + "' WHERE requestid='" + requestidStr + "'"
                    
                    try:
                        cursor.execute(cmd)
                    
                    except psycopg2.Error as exc:
                        raise Exception('reqtableWrite', exc.diag.message_primary)
                    
                    self.reqDict[requestidStr]['dirty'] = False

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes.
    def deleteDB(self, requestids):
        if len(requestids) > 0:
            for arequestid in requestids:
                requestidStr = str(requestid)
                
                if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                    raise Exception('unknownRequestid', 'No request-table record exists for ID ' + requestidStr + '.')

                del self.reqDict[requestidStr]
            
            reqidLstStr = ','.join(requestids)
            
            cmd = 'DELETE FROM ' + self.tableName + ' WHERE requestid=' + reqidLstStr
            
            try:
                cursor.execute(cmd)
            
            except psycopg2.Error as exc:
                raise Exception('reqtableWrite', exc.diag.message_primary + ': ' + cmd)
        
    def setStatus(self, requestids, code, msg=None):
        for arequestid in requestids:
            requestidStr = str(arequestid)
        
            if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                raise Exception('unknownRequestid', 'No request-table record exists for ID ' + requestidStr + '.')
            
            self.reqDict[requestidStr]['status'] = code
            if msg:
                self.reqDict[requestidStr]['errmsg'] = msg
            else:
                self.reqDict[requestidStr]['errmsg'] = ''
            
            # Set dirty flag
            self.reqDict[requestidStr]['dirty'] = True

    def get(self, requestids=None):
        toRet = []
    
        if not requestids:
            return [ self.reqDict[key] for (key, val) in self.reqDict.items() ]
        
        for arequestid in requestids:
            requestidStr = str(arequestid)
            
            if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                raise Exception('unknownRequestid', 'No request-table record exists for ID ' + requestidStr + '.')
    
            toRet.append(self.reqDict[requestidStr])
    
        return toRet
    
    def getPending(self):
        pendLst = []
    
        for requestidStr in self.reqDict.iterkeys():
            if self.reqDict[requestidStr]['status'] == 'P':
                pendLst.append(self.reqDict[requestidStr])
    
        # Sort by start time. Sorts in place - and returns None.
        pendLst.sort(key=lambda(dict): dict['starttime'].strftime('%Y-%m-%d %T'))
            
        return pendLst
    
    def getNew(self):
        newLst = []
        
        for requestidStr in self.reqDict.iterkeys():
            if self.reqDict[requestidStr]['status'] == 'N':
                newLst.append(self.reqDict[requestidStr])
        
        # Sort by start time. Sorts in place - and returns None.
        newLst.sort(key=lambda(dict): dict['starttime'].strftime('%Y-%m-%d %T'))

        return newLst

    def getDelete(self):
        deleteLst = []

        for requestidStr in self.reqDict.iterkeys():
            if self.reqDict[requestidStr]['status'] == 'D':
                deleteLst.append(self.reqDict[requestidStr])

        deleteLst.sort(key=lambda(dict): dict['requestid'])

        return deleteLst

    def getTimeout(self):
        return self.timeOut

    # series (text) - Name of series whose retention is wanted.
    # request (ReqTable::reqDict[requestidStr] object) - Contains the dbhost, dbport, dbname that identifies the
    #    database that contains the series.
    @staticmethod
    def getRetention(series, request, dbuser, binPath, log):
        # Who you gonna call...jsoc_info! A la:
        # jsoc_info op=series_struct ds=hmi.v_avg120
        # Ack - there is Stanford-specific stuff in jsoc_info. Instead, just get the retention from the db. We have the
        # host/port/dbname information from request.
        newSuRetention = -1
        ns, tab = series.split('.')

        try:
            with psycopg2.connect(database=request['dbname'], user=dbuser, host=request['dbhost'], port=request['dbport']) as conn:
                with conn.cursor() as cursor:
                    # We want the new-SU retention too, not the staging retention. So extract the bottom 15 bits.
                    cmd = "SELECT retention & x'00007FFF'::int AS retention FROM " + ns + ".drms_series WHERE seriesname ILIKE '" + series + "'"
                    log.write(['Obtaining new-SU retention for series ' + series + ': ' + cmd])

                    try:
                        cursor.execute(cmd)
                        newSuRetention = cursor.fetchone()[0]
                        log.write(['Retention is ' + str(newSuRetention) + '.'])
                    except psycopg2.Error as exc:
                        # Handle database-command errors.
                        raise Exception('getRetention', exc.diag.message_primary)

        except psycopg2.DatabaseError as exc:
            # Closes the cursor and connection

            # Man, there is no way to get an error message from any exception object that will provide any information why
            # the connection failed.
            msg = 'Unable to connect to the database (no, I do not know why).'
            raise Exception('getRetention', msg)

        return newSuRetention

# The site information is stored in a public database table at Stanford. It is accessible by all remote sites
# with the sites.py cgi. To obtain information about all sites, the sites.py cgi is called with no parameters.
# Otherwise, information about a single site can be obtained by by providing the site name to the 'site' argument.
# The information is stored in drms.rs_sites on hmidb.
class SiteTable:
    def __init__(self, log):
        self.log = log
        self.siteDict = {} # Keyed by name.
        self.siteMap = {} # Map from str(code) to name.

    def read(self):
        url = 'http://jsoc.stanford.edu/cgi-bin/rssites.sh'
        req = urllib2.Request(url)
        response = urllib2.urlopen(req)
        siteInfoStr = response.read()

        # siteInfoStr is a string, that happens to be json.
        siteInfo = json.loads(siteInfoStr)
        
        if siteInfo['status'] != 'success':
            raise Exception('sitetableRead', "Failure calling cgi '" + url + "'.")

        # siteInfo is a dictionary, keyed by site name. Each dictionary entry is a dictionay, with two keys: code and baseurl.
        for asite in siteInfo.iterkeys():
            if asite == 'status':
                # Skip status.
                continue
            self.siteDict[asite] = {}
            self.siteDict[asite]['name'] = asite
            self.siteDict[asite]['code'] = siteInfo[asite]['code']
            self.siteDict[asite]['baseurl'] = siteInfo[asite]['baseurl']
            self.siteMap[str(self.siteDict[asite]['code'])] = asite

            self.log.write(['Reading site info for ' + asite + ': code => ' + str(self.siteDict[asite]['code']) + ', baseurl => ' + self.siteDict[asite]['baseurl']])

    def tryRead(self):
        nAtts = 0
        while True:
            try:
                self.read()
                break
            except Exception as exc:
                if len(exc.args) != 2:
                    raise # Re-raise

                etype = exc.args[0]

                if etype == 'sitetableRead':
                    if nAtts > 10:
                        raise # Re-raise
                else:
                    raise

            nAtts += 1
            time.sleep(1)

    @staticmethod
    def getCode(sunum):
        code = sunum >> 48
        if code & 0xC000 != 0:
            raise Exception('badSunum', 'The site-code value of SUNUM ' + sunum + ' is out of range (valid range is 0 to 16383).')

        return code

    def getURL(self, sunum):
        code = SiteTable.getCode(sunum)
        
        if not str(code) in self.siteMap or not self.siteMap[str(code)]:
            raise Exception('unknownSitecode', 'There is no site in the site table for code ' + str(code) + '.')
        
        name = self.siteMap[str(code)]
        url = self.siteDict[name]['baseurl']
        return url

class Chunker(object):
    def __init__(self, list, chSize):
        self.chunks = []
        iChunk = -1
        nElem = 1
        
        for elem in list:
            if iChunk == -1 or nElem % chSize == 0:
                iChunk += 1
                self.chunks.append([])
    
            self.chunks[iChunk].append(elem)
            nElem += 1
    
    def __iter__(self):
        return self.iterate()
    
    # Iterate through chunks.
    def iterate(self):
        i = 0
        while i < len(self.chunks):
            yield self.chunks[i]
            i += 1

# Downloads a single SU. Ingests it into SUMs (SUMS allows to ingestion of a single SU at a time only.). Updates
# the SU table status for that SU.
class Downloader(threading.Thread):
    tList = [] # A list of running thread IDs.
    maxThreads = 16 # Default. Can be overriden with the Downloader.setMaxThreads() method.
    eventMaxThreads = threading.Event() # Event fired when the number of threads decreases.
    lock = threading.Lock() # Guard tList.

    def __init__(self, sunum, path, series, retention, sus, scpUser, scpHost, scpPort, binPath, log):
        threading.Thread.__init__(self)
        self.sunum = sunum
        self.path = path
        self.series = series
        self.retention = retention
        self.suTable = sus
        self.scpUser = scpUser
        self.scpHost = scpHost
        self.scpPort = scpPort
        self.binPath = binPath
        self.log = log

    def run(self):
        dlDir = '/tmp/.su' + str(self.sunum)
        
        self.log.write(['Downloading SU [scp -r -P ' + self.scpPort + ' ' + self.scpUser + '@' + self.scpHost + ':' + self.path + '/* ' + dlDir])
        
        # Download the SU.
        try:
            try:
                self.log.write(['Class Downloader acquiring SU-table lock for SU ' + str(self.sunum) + '.'])
                self.suTable.acquireLock()

                su = self.suTable.get([self.sunum])

                # Check for download error or completion
                if su[0]['status'] != 'P':
                    raise Exception('downloader', 'SU ' + str(su[0]['sunum']) + ' not pending.')
            finally:
                # Always release lock.
                self.log.write(['Class Downloader releasing SU-table lock for SU ' + str(self.sunum) + '.'])
                self.suTable.releaseLock()

            # Don't forget to make the temporary directory first.
            if os.path.exists(dlDir):
                self.log.write(['Removing stale temporary directory ' + dlDir + '.'])
                shutil.rmtree(dlDir)
            self.log.write(['Creating temporary download directory ' + dlDir + '.'])
            os.mkdir(dlDir)
            
            cmdList = ['scp', '-r', '-P', self.scpPort, self.scpUser + '@' + self.scpHost + ':' + self.path + '/*', dlDir]
            try:
                # check_call(cmdList)
                # The scp process will inherit stdin, stdout, and stderr from this script.
                proc = Popen(cmdList)
            except OSError as exc:
                raise Exception('scpSU', "Cannot run command '" + ' '.join(cmdList) + "' ")
            except ValueError as exc:
                raise Exception('scpSU', "scp command '" + ' '.join(cmdList) + "' called with invalid arguments.")

            # Poll for completion
            while True:
                if gShutDown:
                    proc.kill()
                    self.log.write(['Download thread is observing the global shutdown and exiting now.'])
                    return
                try:
                    self.log.write(['Class Downloader acquiring SU-table lock for SU ' + str(self.sunum) + '.'])
                    self.suTable.acquireLock()
                    su = self.suTable.get([self.sunum])

                    # Check for download error or completion
                    if su[0]['status'] != 'P':
                        raise Exception('downloader', 'SU ' + str(su[0]['sunum']) + ' not pending.')

                    # Check for download time-out.
                    timeNow = datetime.now(su[0]['starttime'].tzinfo)
                    if timeNow > su[0]['starttime'] + self.suTable.getTimeout():
                        self.log.write(['Download of SUNUM ' + str(su[0]['sunum']) + ' timed-out.'])
                        sus.setStatus([su[0]['sunum']], 'E', 'Download timed-out.')        
                        # Flush the change to disk.
                        self.suTable.updateDB()                
                        raise Exception('downloader', 'Timed-out.')

                finally:
                    # Always release lock.
                    self.log.write(['Class Downloader releasing SU-table lock for SU ' + str(self.sunum) + '.'])
                    self.suTable.releaseLock()

                # The Python documentation is confusing at best. I think we have to look at the proc.returncode attribute
                # to determine if the child process has completed. None means it hasn't. If the value is not None, then 
                # the child process has terminated, and the value is the child process's return code.
                proc.poll()
                if proc.returncode is not None:
                    if proc.returncode != 0:
                        raise Exception('scpSU', 'Command "' + ' '.join(cmdList) + '" returned non-zero status code ' + str(proc.returncode)) 
                    break

                time.sleep(1)

            self.log.write(['scp command succeeded.'])

            # Ingest the SUs into SUMS. size matters not...look at me...judge me by my size, do you?
            cmdList = [self.binPath + '/vso_sum_alloc', 'sunum=' + str(self.sunum), 'size=1024']
            self.log.write(['Allocating a new SU: ' + ' '.join(cmdList)])

            try:
                resp = check_output(cmdList)
                output = resp.decode('utf-8')
            except CalledProcessError as exc:
                raise Exception('sumsAlloc', 'Command returned non-zero status code ' + str(exc.returncode) + ': ' + ' '.join(cmdList) + '.')
                
            regExp = re.compile(r'.+sudir:(\S+)')
            matchObj = regExp.match(output)
            if matchObj is not None:
                sudir = matchObj.group(1)
            else:
                raise Exception('sumsAlloc', 'Command printed unexpected output ' + output + ': '+ ' '.join(cmdList) + '.')

            self.log.write(['SU allocation succeeded.'])

            files = os.listdir('/tmp/.su' + str(self.sunum))
            self.log.write(['Moving downloaded SU content in /tmp/.su' + str(self.sunum) + ' into allocated SU (' + sudir  + ').'])

            try:
                for afile in files:
                    src = os.path.join('/tmp/.su' + str(self.sunum), afile)
                    shutil.move(src, sudir)
            except shutil.Error as exc: 
                raise Exception('mvSU', 'Unable to move SU file ' + afile + ' into SUdir ' + sudir + '.')

            self.log.write(['Move of SU content succeeded.'])

            cmdList = [self.binPath + '/vso_sum_put', 'sunum=' + str(self.sunum), 'seriesname=' + self.series, 'sudir=' + sudir, 'retention=' + str(self.retention)]
            self.log.write(['Committing SU to SUMS database.'])

            try:
                resp = check_call(cmdList)
            except CalledProcessError as exc:
                raise Exception('sumsPut', 'Command returned non-zero status code ' + str(exc.returncode) + ': '+ ' '.join(cmdList) + '.')
 
            self.log.write(['Commit of SU succeeded.'])

            # Remove temporary directory.
            self.log.write(['Removing temporary download directory ' + dlDir + '.'])
            try:
                os.rmdir(dlDir)
            except OSError as exc:
                raise Exception('rmTmpSU', exc.strerror)
           
            self.log.write(['Removal of temporary directory succeeded.'])
 
            # Update SU table. Set SU-table record status to 'C'. Must first lock the SU table since we are modifying it. Also,
            # the state may not be 'P' due to some problem cropping up in the meantime. Only set to 'C' if the state is 'P'.
            try:
                self.log.write(['Class Downloader acquiring SU-table lock for SU ' + str(self.sunum) + '.'])            
                self.suTable.acquireLock()
                
                su = self.suTable.get([self.sunum])
                if su[0]['status'] == 'P':
                    self.log.write(['Setting SU ' + str(self.sunum) + ' status to complete.'])
                    self.suTable.setStatus([self.sunum], 'C', None)
                    # Flush the change to disk.
                    self.suTable.updateDB()
            finally:
                # Always release lock.
                self.log.write(['Class Downloader releasing SU-table lock for SU ' + str(self.sunum) + '.'])
                self.suTable.releaseLock()
        except Exception as exc:
            if len(exc.args) == 2:
                type = exc[0]
                msg = exc[1]
            else:
                raise

            if type == 'scpSU' or type == 'sumsAlloc' or type == 'mvSU' or type == 'sumsPut' or type == 'rmTmpSU':
                try:
                    sus.setStatus([self.sunum], 'E', 'Error downloading storage unit ' + str(self.sunum) + ': ' + msg + '.')
                    # Flush the change to disk.
                    self.suTable.updateDB()
                except Exception:
                    # Catch everything and just let the thread pass away peacefully.
                    pass
            elif type == 'unknownSunum':
                self.log.write(['Cannot download SU. No SU record.' + msg])
            elif type == 'downloader':
                self.log.write([msg])
            else:
                raise
  
        # This thread is about to terminate. 
        # We need to check the class tList variable to update it, so we need to acquire the lock.
        try:
            Downloader.lock.acquire()
            self.log.write(['Class Downloader acquired Downloader lock for SU ' + str(self.sunum) + '.'])
            Downloader.tList.remove(self) # This thread is no longer one of the running threads.
            if len(Downloader.tList) == Downloader.maxThreads - 1:
                # Fire event so that main thread can add new SUs to the download queue.
                self.log.write(['OK to start new download threads.'])
                Downloader.eventMaxThreads.set()
                # Clear event so that main will block the next time it calls wait.
                Downloader.eventMaxThreads.clear()
        finally:
            Downloader.lock.release()
            self.log.write(['Class Downloader released Downloader lock for SU ' + str(self.sunum) + '.'])


    # Must acquire Downloader lock BEFORE calling newThread() since newThread() will append to tList (the Downloader threads will delete from tList as they complete).
    @staticmethod
    def newThread(sunum, path, series, retention, sus, scpUser, scpHost, scpPort, binPath, log):
        dl = Downloader(sunum, path, series, retention, sus, scpUser, scpHost, scpPort, binPath, log)
        dl.tList.append(dl)
        dl.start()

    @classmethod
    def setMaxThreads(cls, maxThreads):
        cls.maxThreads = maxThreads

class ProviderPoller(threading.Thread):
    def __init__(self, url, requestID, sunums, sus, reqTable, request, dbUser, binPath, log):
        threading.Thread.__init__(self)
        self.url = url
        self.requestID = requestID # The provider request ID.
        self.sunums = sunums # The sunums requested from provider (under request ID self.requestID).
        self.suTable = sus
        self.reqTable = reqTable
        self.request = request # The ReqTable::reqdict[requestidStr] object (the row in the request table)
        self.dbUser = dbUser
        self.binPath = binPath
        self.log = log
        self.startTime = datetime.now() # Cool bug. This used ot be self.start. But the parent object has a method named 'start' The effect was to override the method with an attribute.
        self.timeOut = sus.getTimeout()

    def run(self):
        values = {'requestid' : self.requestID, 'sunums' : 'none'}
        data = urllib.urlencode(values)
        errMsg = None
        timeToLog = True
        loopN = 0

        try:
            # Set the in-memory ProviderPoller flag for all sunums in this request.
            self.suTable.acquireLock()
            for asunum in self.sunums:
                try:
                    asu = self.suTable.get([asunum])
                    asu[0]['polling'] = True
                    self.suTable.updateDB([asunum])
                except Exception as exc:
                    if len(exc.args) != 2:
                        raise # Re-raise

                    etype = exc.args[0]

                    if etype != 'unknownSunum':
                        raise
        finally:
            self.suTable.releaseLock()

        dlInfo = {}
        dlInfo['status'] = 'pending'
        while True:
            if datetime.now(self.startTime.tzinfo) > self.startTime + self.timeOut:
                # The providing site has not completed the export, and the time-out has elapsed. Give up.
                errMsg = 'Timed-out waiting for providing site to return paths to requested SUs (' + ','.join([ str(asunum) for asunum in self.sunums ]) + ') - provider request ' + self.requestID + '.'
                break

            if timeToLog:
                self.log.write(['Checking on request to provider (provider request ' + self.requestID + ').'])
                self.log.write(['URL is ' + self.url + '/rs.sh' + '?' + data])

            req = urllib2.Request(self.url + '/rs.sh', data)
            response = urllib2.urlopen(req)
            dlInfoStr = response.read()
            dlInfo = json.loads(dlInfoStr)

            if timeToLog:
                self.log.write(['Provider returns status ' + dlInfo['status'] + '.'])

            if dlInfo['status'] != 'pending':
                break;

            time.sleep(1)
            loopN += 1
            
            # Log every 5 seconds.
            timeToLog = (loopN % 5 == 0)

        # We might not have printed to log.
        if not errMsg and not timeToLog:
            self.log.write(['Checking on request to provider (provider request ' + self.requestID + ').'])
            self.log.write(['URL is ' + self.url + '/rs.sh' + '?' + data])
            self.log.write(['Provider returns status ' + dlInfo['status'] + '.'])

        # We must acquire the SU-table lock since we will be updating the status fields for individual SUs. 
        try:
            self.suTable.acquireLock()

            # We are done polling, remove the polling flag.
            for asunum in self.sunums:
                try:
                    asu = self.suTable.get([asunum])
                    asu[0]['polling'] = False
                    self.suTable.updateDB([asunum])
                except Exception as exc:
                    if len(exc.args) != 2:
                        raise # Re-raise

                    etype = exc.args[0]

                    if etype != 'unknownSunum':
                        raise
 
            if dlInfo['status'] != 'complete':
                # Set all SU records to 'E' (rsumds.py timed-out waiting for the SUs to be ready at the providing site).
                if not errMsg:
                    errMsg = 'The providing site failed to return paths to requests SUs.'
                self.suTable.setStatus(self.sunums, 'E', errMsg)

                # Flush the change to disk.
                self.suTable.updateDB(self.sunums)
            else:
                # Start a download for each SU. If we cannot start the download for any reason, then set the SU status to 'E'.
                self.log.write(['The SU paths are ready.'])
                paths = dlInfo['paths']

                retentions = {}
                for (asunum, path, series) in paths:
                    if not path:
                        # A path of None means that the SUNUM was invalid. We want to set the SU status to 'E'.
                        self.suTable.setStatus([asunum], 'E', 'SU ' + str(asunum) + ' is not valid at the providing site.')
                        continue
                    elif path == '':
                        # An empty-string path means that the SUNUM was valid, but that the SU referred to was offline, and could not
                        # be placed back online - it is not archived.
                        # ART - I need to figure out how to place the SUNUM in SUMS so that its archive flag is N (not archived).
                        self.suTable.setStatus([asunum], 'C', 'SU ' + str(asunum) + ' refers to an offline SU valid at the providing site that was not archived. It cannot be downloaded.')
                        continue
                    
                    if series in retentions:
                        retention = retentions[series]
                    else:
                        # request provides the host, port, and dbname to use with jsoc_info to fetch the retention value.
                        retention = ReqTable.getRetention(series, self.request, self.dbUser, self.binPath, self.log)
                        retentions[series] = retention
                        
                        # Save series and retention.
                        sus.setSeries([asunum], series)
                        sus.setRetention([asunum], retention)

                    while True:
                        Downloader.lock.acquire()
                        try:
                            if len(Downloader.tList) < Downloader.maxThreads:
                                self.log.write(['Instantiating a Downloader for SU ' + asunum + '.'])
                                Downloader.newThread(asunum, path, series, retention, self.suTable, dlInfo['scpUser'], dlInfo['scpHost'], dlInfo['scpPort'], self.binPath, self.log)
                                break # The finally clause will ensure the Downloader lock is released.
                        finally:
                            Downloader.lock.release()

                        Downloader.eventMaxThreads.wait()
                        # We woke up, but we do not know if there are any open threads in the thread pool. Loop and check
                        # tList again.
                
                # Flush the change to disk.
                self.suTable.updateDB(self.sunums)
        except Exception as exc:
            if len(exc.args) != 2:
                raise

            type = exc[0]

            # Eventually I will figure out which exceptions to handle.
            raise
        finally:
            # Always release lock.
            self.suTable.releaseLock()

    @staticmethod
    def newThread(url, requestID, sunums, sus, reqTable, request, dbUser, binPath, log):
        poller = ProviderPoller(url, requestID, sunums, sus, reqTable, request, dbUser, binPath, log)
        poller.start()

def readTables(sus, requests, sites):
    if sus:
        sus.tryRead()

    if requests:
        requests.tryRead()
    
    if sites:
        sites.tryRead()

# Process the SUs for the source site represented by url.
# url - the base URL to the rs.sh cgi (e.g., http://jsoc.stanford.edu/cgi-bin) from which SU paths can be obtained.
# sunums - a list of sorted SUNUMs to download.
# sus - the SU table object that represents the SU database table.
# request - ReqTable::dict[requestidStr] object.
# binPath - the local path to the binaries needed to ingest the downloaded SU into SUMS. This is mostly likely the path to
#           the DRMS binaries (one binary needed is vso_sum_alloc)
# log - the log to write messages to.
# reprocess - the SUs identified are all being reprocessed. They all have a status of 'P' in the SU table. There was
#             some interruption that caused the download to be lost.
# reset - reset the processing start time for each SU. Ignored, unless reprocess is true
def processSUs(url, sunums, sus, reqTable, request, dbUser, binPath, log, reprocess=False, reset=False):
    # Get path to SUs by calling the rs.sh cgi at the owning remote site (url identifies the remote site).
    # Create the sunum= argument.

    # Skip any SUs that have already been processed. Pending SUs are OK to restart, however. It may be the case
    # that rsumds.py was interrupted during a download, in which case, we want to re-download the SU.
    workingSunums = []
    for asunum in sunums:
        try:
            su = sus.get([asunum])
            if su[0]['status'] == 'P':
                if not reprocess:
                    # Accidental attempt to reprocess an SU whose processing has already started.
                    raise Exception('accidentalRepro', 'An accidental attempt to reprocess pending SU ' + str(asunum) + ' occurred.')
                workingSunums.append(asunum)
                # Reset start time.
                if reset:
                    sus.setStarttime([asunum], datetime.now())
        except Exception as exc:
            if len(exc.args) != 2:
                raise # Re-raise

            etype = exc.args[0]

            if etype != 'unknownSunum':
                raise

            workingSunums.append(asunum)
            # Create a new SU table record for this SU.
            log.write(['Inserting a new SU table record for ' + str(asunum)])
            sus.insert([asunum])

    sunumLst = ','.join(str(asunum) for asunum in workingSunums)
    values = {'requestid' : 'none', 'sunums' : sunumLst}
    data = urllib.urlencode(values)
    log.write(['Requesting paths for SUNUMs ' + sunumLst + '. URL is ' + url + '/rs.sh' + '?' + data])
    req = urllib2.Request(url + '/rs.sh', data)
    response = urllib2.urlopen(req)
    dlInfoStr = response.read()
    dlInfo = json.loads(dlInfoStr)

    if dlInfo['status'] == 'complete':
        # All of the requested SUs are online at the providing site.
        paths = dlInfo['paths']

        # Start a download for each SU. If we cannot start the download for any reason, then set the SU status to 'E'.
        retentions = {}
        for (asunum, path, series) in paths:
            if not path:
                # A path of None means that the SUNUM was invalid. We want to set the SU status to 'E'.
                sus.setStatus([asunum], 'E', 'SU ' + str(asunum) + ' is not valid at the providing site.')
                continue
            elif path == '':
                # An empty-string path means that the SUNUM was valid, but that the SU referred to was offline, and could not
                # be placed back online - it is not archived. 
                # ART - I need to figure out how to place the SUNUM in SUMS so that its archive flag is N (not archived).
                sus.setStatus([asunum], 'C', 'SU ' + str(asunum) + ' refers to an offline SU valid at the providing site that was not archived. It cannot be downloaded.')
                continue

            # Get retention, if it hasn't been gotten yet. If we are re-processing SUs, then the retention has already been determined and saved.
            if reprocess:
                # We know this won't raise, because we already obtained the su object at the beginning of this method.
                su = sus.get([asunum])
                retention = su[0]['retention']
            else:
                if series in retentions:
                    retention = retentions[series]
                else:
                    # request provides the host, port, and dbname to use with jsoc_info to fetch the retention value.
                    retention = ReqTable.getRetention(series, request, dbUser, binPath, log)
                    retentions[series] = retention
                    
                # Save series and retention.
                sus.setSeries([asunum], series)
                sus.setRetention([asunum], retention)

            while True:
                Downloader.lock.acquire()
                try:
                    if len(Downloader.tList) < Downloader.maxThreads:
                        log.write(['Instantiating a Downloader for SU ' + asunum + '.'])
                        Downloader.newThread(asunum, path, series, retention, sus, dlInfo['scpUser'], dlInfo['scpHost'], dlInfo['scpPort'], binPath, log)
                        break # The finally clause will ensure the Downloader lock is released.
                finally:
                    Downloader.lock.release()

                # We are holding the suTable lock. The new downloader threads have to acquire this lock because they change the
                # status of the suTable rows. If we do not releaes the lock, then we could deadlock here.
                sus.releaseLock()

                Downloader.eventMaxThreads.wait()

                sus.acquireLock()
                # We woke up, but we do not know if there are any open threads in the thread pool. Loop and check
                # tList again.

        # For each SU that was requested, but for which no path was given in the response, update its SU-table record with an error status.
        pathInResp = dict([ (str(asunum), True) for (asunum, path, series) in paths ])
        for asunum in workingSunums:
            if str(asunum) not in pathInResp:
                sus.setStatus([asunum], 'E', 'Providing site cannot provide a path for SU ' + str(asunum) + '.')
    elif dlInfo['status'] == 'pending':
        # One or more of the requested SUs is offline. Poll until they are ready. Ideally we wouldn't block the main
        # thread here, waiting for the SUs to be available. We could spawn a thread to poll, freeing up the main
        # thread to continue with other requests. But in the interest of time, just poll for now. Must acquire
        # su-table lock when it is finally time to start downloads.
        log.write(['Request includes one or more SUs that are offline at the providing site. Waiting for providing site to put them online.'])

        ProviderPoller.newThread(url, dlInfo['requestid'], workingSunums, sus, reqTable, request, dbUser, binPath, log)
    else:
        # Error of some kind.
        # Update the SU-table status of the SUs to 'E'.
        sus.setStatus(workingSunums, 'E', 'Unable to obtain paths from providing site.\n' + dlInfo['statusMsg'] + '.')

# Global - set True when main thread calls sys.exit(). Threads must check this variable if they can loop indefinitely.
# There is no need to use a lock when accessing this variable - only the main thread will write to it.
gShutDown = False

rv = RET_SUCCESS

if __name__ == "__main__":
    try:
        sumsDrmsParams = SumsDrmsParams()
        if sumsDrmsParams is None:
            raise Exception('drmsParams', 'Unable to locate DRMS parameters file (drmsparams.py).')
            
        parser = CmdlParser(usage='%(prog)s [ -h ] [ sutable=<storage unit table> ] [ reqtable=<request table> ] [ --dbname=<db name> ] [ --dbhost=<db host> ] [ --dbport=<db port> ] [ --binpath=<executable path> ] [ --logfile=<base log-file name> ]')
    
        # Optional parameters - no default argument is provided, so the default is None, which will trigger the use of what exists in the configuration file
        # (which is drmsparams.py).
        parser.add_argument('r', '--reqtable', help='The database table that contains records of the SU-request being processed. If provided, overrides default specified in configuration file.', metavar='<request unit table>', dest='reqtable', default=sumsDrmsParams.get('RS_REQUEST_TABLE'))
        parser.add_argument('s', '--sutable', help='The database table that contains records of the storage units being processed. If provided, overrides default specified in configuration file.', metavar='<storage unit table>', dest='sutable', default=sumsDrmsParams.get('RS_SU_TABLE'))
        parser.add_argument('-N', '--dbname', help='The name of the database that contains the series table from which records are to be deleted.', metavar='<db name>', dest='dbname', default=sumsDrmsParams.get('RS_DBNAME'))
        parser.add_argument('-U', '--dbuser', help='The name of the database user account.', metavar='<db user>', dest='dbuser', default=sumsDrmsParams.get('RS_DBUSER'))
        parser.add_argument('-H', '--dbhost', help='The host machine of the database that contains the series table from which records are to be deleted.', metavar='<db host machine>', dest='dbhost', default=sumsDrmsParams.get('RS_DBHOST'))
        parser.add_argument('-P', '--dbport', help='The port on the host machine that is accepting connections for the database that contains the series table from which records are to be deleted.', metavar='<db host port>', dest='dbport', default=int(sumsDrmsParams.get('RS_DBPORT')))
        parser.add_argument('-b', '--binpath', help='The path to executables run by this daemon (e.g., vso_sum_alloc, vso_sum_put).', metavar='<executable path>', dest='binpath', default=sumsDrmsParams.get('RS_BINPATH'))
        parser.add_argument('-l', '--logfile', help='The file to which logging is written.', metavar='<file name>', dest='logfile', default=os.path.join(sumsDrmsParams.get('RS_LOGDIR'), LOG_FILE_BASE_NAME + '_' + datetime.now().strftime('%Y%m%d') + '.txt'))
                
        arguments = Arguments(parser)
        
        arguments.setArg('lockfile', sumsDrmsParams.get('RS_LOCKFILE'))
        arguments.setArg('dltimeout', int(sumsDrmsParams.get('RS_DLTIMEOUT')))
        arguments.setArg('reqtimeout', int(sumsDrmsParams.get('RS_REQTIMEOUT')))
        arguments.setArg('maxthreads', int(sumsDrmsParams.get('RS_MAXTHREADS')))
        arguments.setArg('logdir', sumsDrmsParams.get('RS_LOGDIR'))
        
        pid = os.getpid()
            
        with DrmsLock(arguments.lockfile, str(pid)) as lock:
            rslog = Log(arguments.logfile)

            rslog.write(['Starting up daemon.']) 
            rslog.write(['Obtained script file lock.'])
            # Connect to the database
            try:
                # The connection is NOT in autocommit mode. If changes need to be saved, then conn.commit() must be called.
                with psycopg2.connect(database=arguments.dbname, user=arguments.dbuser, host=arguments.dbhost, port=arguments.dbport) as conn:
                    rslog.write(['Connected to database ' + arguments.dbname + ' on ' + arguments.dbhost + ':' + str(arguments.dbport) + ' as user ' + arguments.dbuser])
                    with conn.cursor() as cursor:
                        suTable = arguments.sutable
                        reqTable = arguments.reqtable

                        sus = None
                        requests = None
                        sites = None

                        # Read the storage-unit and request tables. Do this only once per daemon run. However, we save this table
                        # information every iteration of the daemon loop, just in case a crash happens. After a crash, when
                        # the daemon starts up, it will retrieve the latest saved information so the disruption will be minimal.
                        # We will have to clean up any pending downloads since the threads managing those downloads will have
                        # been lost, and we cannot trust that the downloads completed successfully (although they might have).
                        # A fancier implementation would be some kind of download manager that can recover partially downloaded
                        # storage units, but who has the time :)
                        rslog.write(['Setting download-timeout to ' + str(arguments.dltimeout) + ' minutes.'])
                        sus = SuTable(suTable, timedelta(minutes=arguments.dltimeout), rslog)
                        rslog.write(['Setting request-timeout to ' + str(arguments.reqtimeout) + ' minutes.'])
                        requests = ReqTable(reqTable, timedelta(minutes=arguments.reqtimeout), rslog)
                        sites = SiteTable(rslog)
                        
                        SuTable.setCursor(cursor)
                        ReqTable.setCursor(cursor)

                        # This function will try to read each table 10 times before giving up (and raising an exception).
                        readTables(sus, requests, sites)

                        # Set max number of threads we can process at once.
                        Downloader.setMaxThreads(arguments.maxthreads)

                        # Recover pending downloads that got disrupted from a daemon crash. All SU downloads that are in the pending
                        # state at the time the tables are read were disrupted. There are no other threads running at this point.
                        susPending = sus.getPending()
                        
                        siteSunums = {}
                        for asu in susPending:
                            timeNow = datetime.now(asu['starttime'].tzinfo)
                            if timeNow > asu['starttime'] + sus.getTimeout():
                                # Set SU status to 'E'.
                                rslog.write(['Download of SUNUM ' + str(asu['sunum']) + ' timed-out.'])
                                sus.setStatus([asu['sunum']], 'E', 'Download timed-out.')
                                continue

                            rslog.write(['Recovering interrupted download for SUNUM ' + str(asu['sunum']) + '.'])
                            siteURL = sites.getURL(asu['sunum'])
                            
                            if siteURL not in siteSunums:
                                siteSunums[siteURL] = []

                            siteSunums[siteURL].append(asu['sunum'])

                        sus.updateDB()

                        # There is no need to acquire the SU-table lock. processSUs() will start new threads that can modify the
                        # SU-record statuses, but by the time that happens, the main thread will be done reading those statuses.
                        for url in siteSunums.iterkeys():
                            if len(siteSunums[url]) > 0:
                                # Chunk is a list of SUNUMs (up to 64 of them).
                                siteSunums[url].sort()
                                chunker = Chunker(siteSunums[url], 64)
                                for chunk in chunker:
                                    # processSUs(..., reprocess=False) would attempt to insert a new record in the sus table for each SUNUM. By
                                    # setting the last reprocess argument to True, we do not insert a new record, but instead continue to use
                                    # the existing record. 
                                    try:
                                        processSUs(url, chunk, sus, requests, None, arguments.dbuser, arguments.binpath, rslog, True)

                                    except Exception as exc:
                                        if len(exc.args) != 2:
                                            raise # Re-raise

                                        etype = exc.args[0]
                                        msg = exc.args[1]

                                        # Do not die - just reject reprocess attempt of the request. Eventually, the downloads will time-out, and the 
                                        # status of the request will be marked 'E'.
                                        rslog.write(['Failed to reprocess SUs ' + ','.join([ str(asunum) for asunum in chunk ]) + '.'])
                    
                        # I think this is how you make it possible to pass arguments to your signal handler - define the function
                        # in the scope where the variables you want to use are visible. terminator is a closure where
                        # requests, sus, and cursor are defined.
                        shutDown = False
                        def terminator(*args):
                            global shutDown
                            global rslog
                            
                            rslog.write(['Termination signal handler called. Saving the db-table caches.'])
                            shutDown = True

                        signal.signal(signal.SIGINT, terminator)
                        signal.signal(signal.SIGTERM, terminator)
                        
                        # Start of main loop.
                        loopN = 0
                        while True and not shutDown:
                            # Always lock the SU table first and do all processing that requires this lock first.
                            sus.acquireLock()
                            try:
                                # For each P SU in the SU table, see if it is time to time-out. susPending are ordered by SUNUM.
                                # I guess we could process more than one SuTable, but for now, let's assume there is only one such
                                # table. The Downloader thread normally handles time-outs, but if the thread croaks and leaves 
                                # the SU pending, then the following code handles the time-out.
                                susPending = sus.getPending()
                                for asu in susPending:
                                    timeNow = datetime.now(asu['starttime'].tzinfo)
                                    if timeNow > asu['starttime'] + sus.getTimeout():
                                        rslog.write(['Download of SUNUM ' + str(asu['sunum']) + ' timed-out.'])
                                        # Kill the Downloader thread (if it exists).
                                        sus.setStatus([asu['sunum']], 'E', 'Download timed-out.')
                           
                                try: 
                                    cursor.execute('BEGIN')
                                    sus.updateDB()
                                    cursor.execute('END')
                                except psycopg2.Error as exc:
                                    # Handle database-command errors.
                                    raise Exception('dbUpdate', exc.diag.message_primary)

                                # Ignore SUs in the other states (C or E). These will be checked in other parts of the code.
                                
                                # For each 'P' request in the request table, check to see if the requested downloads have completed yet.

                                # Log every 5 seconds.
                                timeToLog = (loopN % 5 == 0)

                                reqsPending = requests.getPending()
                                for arequest in reqsPending:
                                    done = True
                                    reqError = False
                                    sunums = arequest['sunums']
                                    errMsg = ''
                                    processing = {}

                                    for asunum in sunums:
                                        if str(asunum) in processing:
                                            # Skip duplicates.
                                            rslog.write(['Skipping pending request for SU ' + str(asunum) + ' - this is a duplicate SU.'])
                                            continue
                                        else:
                                            processing[str(asunum)] = True                                        

                                        if reqError == True:
                                            break
                                        asu = sus.get([asunum])
                                        if asu[0]['status'] == 'P':
                                            if (not asu[0]['polling']) or timeToLog:
                                                rslog.write(['Download of SU ' + str(asu[0]['sunum'])  + ' is pending.'])
                                            done = False
                                        elif asu[0]['status'] == 'E':
                                            rslog.write(['Download of SU ' + str(asu[0]['sunum'])  + ' has errored-out.'])
                                            errMsg = asu[0]['errmsg']
                                            reqError = True
                                        else:
                                            rslog.write(['Download of SU ' + str(asu[0]['sunum'])  + ' has completed.'])
                                    
                                    if done:
                                        # There are no pending downloads for this request. Set this request's status to 'C' or 'E', and decrement
                                        # refcount on each SU.
                                        if reqError:
                                            rslog.write(['Request number ' + str(arequest['requestid']) + ' for SUNUM(s) ' + ','.join([ str(asunum) for asunum in arequest['sunums'] ]) + ' errored-out.'])
                                            requests.setStatus([arequest['requestid']], 'E', errMsg)
                                        else:
                                            rslog.write(['Request number ' + str(arequest['requestid']) + ' for SUNUM(s) ' + ','.join([ str(asunum) for asunum in arequest['sunums'] ]) + ' completed successfully.'])
                                            requests.setStatus([arequest['requestid']], 'C')

                                        # These next two calls can modify the db state! Put them in a transaction so that they form an atomic
                                        # operation. We do not want an interruption to cause the first to happen, but not the second.
                                        try:
                                            cursor.execute('BEGIN')
                                            requests.updateDB([arequest['requestid']])
                                            
                                            # Remove duplicates from list first. We do not need to preserve the order of the SUNUMs
                                            # before calling decrementRefcount() since that function uses a hash lookup on the SUNUM
                                            # to find the associated refcount.
                                            
                                            sus.decrementRefcount(list(set(sunums)))
                                            cursor.execute('END')
                                        except psycopg2.Error as exc:
                                            # Handle database-command errors.
                                            raise Exception('dbUpdate', exc.diag.message_primary)
                                            
                                # Right here is where we can find orphaned sus records and delete them. We have a list of all reachable SUs now that we've 
                                # iterated through the pending requests. We now iterate through ALL sus records and delete any that are not reachable.
                                xxx
                
                                # For each 'N' request in the request table, start a new set of downloads (if there is no download currently running -
                                # i.e., no SU record) or increment the refcounts on the downloads (if there are downloads currently running - i.e.,
                                # an SU record exists). But Before starting a new download, make sure that requested SU is not already online.
                                # Due to race conditions, a request could have caused a download to occur needed by another request whose state is 'N'.
                                requests.refresh() # Clients may have added requests to the queue.
                                reqsNew = requests.getNew()

                                for arequest in reqsNew:
                                    timeNow = datetime.now(arequest['starttime'].tzinfo)
                                    if timeNow > arequest['starttime'] + requests.getTimeout():
                                        rslog.write(['Request number ' + str(arequest['requestid']) + ' timed-out.'])
                                        requests.setStatus([arequest['requestid']], 'E', 'Request timed-out.')
                                        try:
                                            cursor.execute('BEGIN')
                                            requests.updateDB([arequest['requestid']])
                                            cursor.execute('END')
                                        except psycopg2.Error as exc:
                                            # Handle database-command errors.
                                            raise Exception('dbUpdate', exc.diag.message_primary)
                                        
                                        continue
                                    
                                    sunums = arequest['sunums']
                                    rslog.write(['Found a new download request, id ' + str(arequest['requestid']) + ' for SUNUMs ' + ','.join([str(asunum) for asunum in sunums]) + '.'])
                                    
                                    # Get all SU records for which a download is already in progress.
                                    unknown = []
                                    known = []
                                    processing = {} # The SUs in sunums that are currently being processed. Use this to avoid duplicate SUs.
                                    skipRequest = False

                                    for asunum in sunums:
                                        if str(asunum) in processing:
                                            # Skip duplicates.
                                            rslog.write(['Skipping request for SU ' + str(asunum) + ' - this is a duplicate SU.'])
                                            continue
                                        else:
                                            processing[str(asunum)] = True
                                            
                                        try:
                                            asu = sus.get([asunum]) # Will raise if asunum is unknown.
                                            
                                            # If the SU is in the 'E' or 'C' state, then we cannot start this request. We must wait until
                                            # this SU has been cleared out of the sus table when the pending requests are processed.
                                            if asu[0]['status'] != 'P':
                                                rslog.write(['Deferring request, id ' + str(arequest['requestid']) + '. At least one previous request for this SU must be completed first.'])
                                                skipRequest = True
                                                break
                                            
                                            rslog.write(['A download for SU ' + str(asunum)+ ' is already in progress.'])
                                            known.append(asunum)
                                        except Exception as exc:
                                            if len(exc.args) != 2:
                                                raise # Re-raise
                                                
                                            etype = exc.args[0]
                                            msg = exc.args[1]
                    
                                            if etype == 'unknownSunum':
                                                unknown.append(asunum)
                                                
                                    if skipRequest:
                                        continue
 
                                    # Increment the refcount on all SU records for the SUs being requested by the new request. This modifies the
                                    # sus object.
                                    sus.incrementRefcount(known)
                                    
                                    offlineSunums = SuTable.offline(unknown, arguments.binpath, rslog)
                                    offlineSunumsDict = dict([ (str(asunum), True) for asunum in offlineSunums ])
                                    
                                    dlsToStart = []
                                    toComplete = []
                                    for asunum in unknown:
                                        if str(asunum) in offlineSunumsDict:
                                            rslog.write(['SU ' + str(asunum) + ' is offline - will start a download'])
                                            dlsToStart.append(asunum)
                                        else:
                                            rslog.write(['SU ' + str(asunum) + ' is online already - will NOT start a download.'])
                                            toComplete.append(asunum)
                                    
                                    # Insert a new SU record for all unknown SUs that are already online. These calls modify the sus object.
                                    sus.insert(toComplete)
                                    sus.setStatus(toComplete, 'C')
                                        
                                    # Start downloads for all unknown, offline SUs
                                    siteSunums = {}
                                    for asunum in dlsToStart:
                                        siteURL = sites.getURL(asunum)
                                        
                                        if siteURL not in siteSunums:
                                            siteSunums[siteURL] = []
                                        
                                        siteSunums[siteURL].append(asunum)
                                        
                                    for url in siteSunums.iterkeys():
                                        if len(siteSunums[url]) > 0:
                                            # Chunk is a list of SUNUMs (up to 64 of them).
                                            siteSunums[url].sort()
                                            chunker = Chunker(siteSunums[url], 64)
                                            for chunk in chunker:
                                                # We want to always insert a record for each SU into the SU table. Do not provide the insertRec
                                                # argument to do so. This call creates new SU-table records, so it modifies the sus object.
                                                processSUs(url, chunk, sus, requests, arequest, arguments.dbuser, arguments.binpath, rslog)
                                    
                                    # The new request has been fully processed. Change its status from 'N' to 'P'.
                                    # This call modifies the requests object.
                                    requests.setStatus([arequest['requestid']], 'P')

                                    # At this point, both the requests and sus object have been modified, but have not been flushed to disk.
                                    # Flush them, but do this inside a transaction so that the first does not happen without the second.
                                    try:
                                        cursor.execute('BEGIN')
                                        sus.updateDB(sunums)
                                        requests.updateDB([arequest['requestid']])
                                        cursor.execute('END')
                                    except psycopg2.Error as exc:
                                        # Handle database-command errors.
                                        raise Exception('dbUpdate', exc.diag.message_primary)

                                # Delete all request-table records whose state is 'D'. It doesn't matter if this operation gets interrupted. If
                                # that happens, then these delete-pending records will be deleted the next time this code runs uninterrupted.
                                reqsToDelete = requests.getDelete()
                                requests.deleteDB(reqsToDelete)
                            finally:
                                # Always release the lock, even if an unhandled exception crops up.
                                sus.releaseLock()
                           
                            # Must poll for new requests to appear in requests table.
                            time.sleep(1)
                            loopN += 1
                            # I wonder if Python throws an exception if loopN rolls-over. Does it roll-over at the 32-bit or 64-bit boundary? 
                            if loopN >= 0x7FFFFFFF:
                                loopN = 0
                            # End of main loop.
                        
                        # Save the db state when exiting.
                        rslog.write(['Remote-sums daemon is exiting. Saving database tables.'])
                        try:
                            cursor.execute('BEGIN')
                            sus.updateDB()
                            requests.updateDB()
                            cursor.execute('END')
                        except psycopg2.Error as exc:
                            # Handle database-command errors.
                            raise Exception('dbUpdate', exc.diag.message_primary)

            except psycopg2.DatabaseError as exc:
                # Closes the cursor and connection
                
                # Man, there is no way to get an error message from any exception object that will provide any information why
                # the connection failed.
                print('Unable to connect to the database (no, I do not know why).', file=sys.stderr)
    
                # No need to close cursor - leaving the with block does that.
                rv = RET_DBCONNECT

            except psycopg2.Error as exc:
                # Handle database-command errors.
                print(exc.diag.message_primary, file=sys.stderr)
                rv = RET_DBCOMMAND

        # Lock was released
    except Exception as exc:
        if len(exc.args) != 2:
            raise # Re-raise
        
        etype = exc.args[0]
        msg = exc.args[1]
       
        if etype == 'drmsLock':
            rslog.write(['Error locking file: ' + lockFile + '\n' + msg])
            rv = RET_LOCK
        elif etype == 'CmdlParser-ArgUnrecognized' or etype == 'CmdlParser-ArgBadformat':
            rslog.write([msg])
            rv = RET_INVALIDARGS
        elif etype == 'sitetableRead':
            rslog.write(['Unable to load site table: ' + msg])
            rv = RET_SITETABLE_LOAD
        elif etype == 'sutableRead':
            rslog.write(['Unable to read from storage-unit table: ' + msg])
            rv = RET_SUTABLE_READ
        elif etype == 'sutableWrite':
            rslog.write(['Unable to write to storage-unit table: ' + msg])
            rv = RET_SUTABLE_WRITE
        elif etype == 'reqtableRead':
            rslog.write(['Unable to read from storage-unit-request table: ' + msg])
            rv = RET_REQTABLE_READ
        elif etype == 'reqtableWrite':
            rslog.write(['Unable to write to storage-unit-request table: ' + msg])
            rv = RET_REQTABLE_WRITE
        elif etype == 'badLogfile':
            print('Cannot access log file: ' + msg, file=sys.stderr)
            rv = RET_LOGFILE
        elif etype == 'badLogwrite':
            print('Cannot access log file: ' + msg, file=sys.stderr)
            rv = RET_LOGFILE
        elif etype == 'findOffline':
            rslog.write(['Cannot determine online disposition: ' + msg])
            rv = RET_OFFLINE
        elif etype == 'getRetention':
            rslog.write(['Cannot obtain retention value: ' + msg])
            rv = RET_GETRETENTION
        elif etype == 'unknownRequestid':
            rslog.write(['Oops! ' + msg])
            rv = RET_UKNOWNREQUEST
        elif etype == 'unknownSunum':
            rslog.write(['Oops! ' + msg])
            rv = RET_UKNOWNSU
        elif etype == 'noReference':
            rslog.write([msg])
            rv = RET_UKNOWNSU
        elif etype == 'unknownSitecode':
            rslog.write([msg])
            rv = RET_UKNOWNSITECODE
        elif etype == 'knownSunum':
            rslog.write([msg])
            rv = RET_DUPLICATESUNUM
        elif etype == 'dbUpdate':
            rslog.write([msg])
            rv = RET_DBUPDATE
        else:
            rslog.write(['Unhandled exception. Remote-sums daemon is exiting. Rolling back uncommitted database changes. '])
            raise # Re-raise

if rslog:
    rslog.write(['Exiting with return status ' + str(rv)])
# Will not exit process if threads are still running. Set global shutdown flag that threads are monitoring. When they see the flag, they
# will terminate too.
gShutDown = True
sys.exit(rv)

