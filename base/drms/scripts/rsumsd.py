#!/usr/bin/env python3

import sys

if sys.version_info < (3, 2):
    raise Exception('You must run the 3.2 release, or a more recent release, of Python.')

import re
import os
import stat
import filecmp
import logging
import psycopg2
import threading
import fcntl
from datetime import datetime, timedelta, timezone
import urllib.request
import json
import signal
import time
from copy import deepcopy
import shutil
import psycopg2
import random
import argparse
import inspect
from queue import Queue, Empty, Full
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../../../include'))
from drmsparams import DRMSParams
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../../../base/libs/py'))
from drmsCmdl import CmdlParser
from drmsLock import DrmsLock
from subprocess import check_output, check_call, CalledProcessError, Popen, PIPE, TimeoutExpired

# This script runs as a daemon at the site that has requested an SU that does not belong to the site. It is responsible for contacting
# the owning site and requesting the path to the desired SUs. The owning site must be running the rs.sh CGI to respond to the requesting
# site's request.

# There are three database tables: 1., a DRMS site table, 2., a request table, and 3., an SU table (sunum, starttime, status, errmsg)
# The site table (sitename, sitecode, baseurl) provides
# the information needed to query the providing site for the information needed to scp the requested SUs to the requesting site. The URL to the cgi
# program that provides scp information is formed by appending "rs.py" to baseurl. There are two parameters for this cgi: 1., "requestid", and 2., "sunums".
# During the initial request to the providing site, the requesting site will provide a requestid of "none", and a comma-separated list of SUNUMs
# in the sunums argument. Should the providing site have all the requested SUs online, then it will return the scp information needed to access those
# SUs, and a status of "complete". If, however, the SUs are not all online, the initial request will start an asynchronous tape-read of the offline SUs,
# returning a request ID that identifies the initial request, and a status of "pending". The requesting site must then poll for completion by
# periodically calling the cgi with a status request. To make a status request, the requestid argument contains the requestid returned by the
# inital CGI call, and the sunums argument contains "none". While the data are not ready, the status request returns a status of "pending". When
# the data are online, the status request returns a status of "complete".
#
# The request table (requestid, sunums, status) is populated by drms_storageunit.c. For all SUs that are offline and are not owned by the running
# DRMS/SUMS, the code inserts a record into the request table. The requestid is a UUID (within the running DRMS/SUMS) generated by a sequence table.
# The list of SUNUMs is put in sunums, and the initial status is set to 'N' (New request). drms_storageunit.c chunks such SUNUMs into
# manageable-sized requests. After inserting one or more such records into the request table, drms_storageunit.c then polls these records,
# waiting for the status to become 'C' (Complete request). After that happens, drms_storageunit.c then calls SUM_get() again on these SUs
# to obtain their paths. This daemon, rsumsd.py, periodically and reads all records in the request table. For each SU in each 'N' record
# (a single request, which could be requesting multiple SUs) the daemon first checks if the SU is already being processed. If so, then
# the SU table is not modified. The status of the record in the request table is set to 'P'. If the SU is not in the SU table, then
# this can mean one of two things. The daemon has never processed this SU, or the daemon has already processed this SU. When the daemon has completed
# processing an SU, it deletes the record for the SU from the SU table. If the latter is true, the daemon should not re-process the same SU. To distinguish
# between these two possibilities, the daemon first checks to see if the SU is already present in SUMS (it calls show_info -o sunum=SUNUM).
# If the SU is online, then the daemon does nothing. But if it is offline, then the daemon inserts a record for the SU into the SU table, and starts
# processing that SU. The status of that SU-table record is set to 'P', as is the status of the request record containing that SUNUM.
#
# For each SU in each 'P' request record, the daemon searches for records in the SU table. If one or more such records exist in the SU table, then
# the request record is left in the pending state. The next time the daemon scans the request records, it will again check the SU table looking
# for completion of all SUs. When that occurs, the status of the request record is set to 'C', indicating that the request is complete. The
# drms_storageunit.c code will then call SUMS to get the newly created paths to the requested SUs.

# Locks and thread synchronization
# The main thread looks for new and pending requests in the requests table. Since there is only a single thread accessing the requests
# table, there is no need to lock the requests table or its individual requests.
#
# The Storage Unit status, on the other hand, is accessed by both the Downloader threads and the ScpWorker threads. The latter queries the
# former for 'working' SUs - these are SUs that a Downloader thread has requested that an ScpWorker thread download. Each SU is assigned to a 
# single ScpWorker. Care must be taken so that two or more ScpWorkers do not operate on the same SU. The change of an SU's status from
# W to D by the ScpWorker thread must not be interrupted by another ScpWorker's call to getNextNWorking(). If an ScpWorker calls
# getNextNWorking() (which returns SUs with a status of W), but does not change the SUs statuses to D before a second ScpWorker
# calls getNextNWorking(), then both ScpWorkers could get assigned the same SU. The solution is for each ScpWorker to lock each SU
# before it checks its status for W, then change the status to D, then release the SU lock. To facilitate this locking, each ScpWorker
# thread first locks the SU Table, then it iterates through all SUs, locking each one, then checking its status. Once it collects
# all SUs with a status of W, it releases the SU Table lock, but it continues to hold on to the SU locks so it can change the statuses
# from W to D without interruption by the Downloader thread (see next paragraph).

# Both the Downloader and ScpWorker can change the status of an SU. Each thread must ensure that it does not overwrite a status change made
# by the other thread. If an ScpWorker sees an SU with a status of W, it will set the status to D before starting an scp. In the meantime, 
# the Downloader could set the status to S to signify a that the worker should be stopped. Without locks, the change to S by the 
# Downloader could be overwritten by the change to D by the ScpWorker. The solution is for both threads to acquire the SU lock, then 
# read the status before changing the status. So the ScpWorker thread will acquire the lock, see the W, set the status to D and then 
# start the scp and release the SU lock. The Downloader will acquire the SU lock before changing the status to S. In this manner, 
# the Downloader's change to S cannot be overwritten by the ScpWorker's change of status from W to D.

# SU status life cycle: 
#   dispatcher thread sets to 'P' (in Dispather::run()) - pending
#   Downloader sets to 'W' - waiting (to be assigned to an ScpWorker)
#   ScpWorker sets to 'D' - ScpWorker is downloading the SU
#   Scpworker sets to 'F' - ScpWorker has finished downloading, back to Downloader
#   Downloader sets to 'C' - complete
#   If an error or time-out happens anywhere in this life cycle, then the status is set to 'E'

# You can measure the total rate of download for a rsumsd.py session like this:
# 1. start up rsumsd.py anew with the --loglevel=debug flag, first moving or deleting the existing log
# 2. make many Remote SUMS requests; the rsums-clientd.py program is one way to do this
# 3. stop rsumsd.py with the kill -2 command and wait for rsumsd.py to finish processing the existing requests
# 4. run this command, first replacing rslog_20180530.txt with the log file created during the current run:
#   grep -Ire 'Payload is' rslog_20180530.txt | perl -ne 'my($input) = $_; if ($input =~ m/(\S+)\s(\S+)\s.+Payload\sis\s(\d+)[.]/) { print $1 . " " . " " . $2 . " " . " " . $3 . "\n"; }' | awk '{ if (beg == "") { beg = $1 " " $2 }; end = $1 " " $2; s+=$3} END {print beg " to " end " " s}'
# 5. the first two columns of the output of this command are a begin date and time, followed by 'to', followed by 
#    the end date and time, followed by the total number of bytes downloaded and ingested into SUMS


RET_SUCCESS = 0
RET_UNKNOWN_ERROR = 1
RET_UNKOWN_DRMSPARAMETER = 2
RET_INVALID_REMOTE_SUMS_ARGUMENT = 3
RET_INVALID_ARGUMENT = 4
RET_SU_NOT_REFERENCED = 5
RET_WORKER_REFERENCE_ERROR = 6
RET_UNABLE_TO_ACQUIRE_LOCK = 7
RET_UNABLE_TO_LOCK_OBJECT = 8
RET_UNABLE_TO_READ_SUTABLE = 9
RET_UNABLE_TO_WRITE_SUTABLE = 10
RET_UNABLE_TO_READ_REQTABLE = 11
RET_UNABLE_TO_WRITE_REQTABLE = 12
RET_UNABLE_TO_READ_SITETABLE = 13
RET_DUPLICATE_SUNUM = 14
RET_UNKNOWN_SUNUM = 15
RET_ERROR_CALLING_SUMS_API = 16
RET_UNKNOWN_REQUESTID = 17
RET_UNABLE_TO_GET_RETENTION = 18
RET_INVALID_SUNUM = 19
RET_UNKNOWN_SITE_CODE = 20
RET_UNABLE_TO_DOWNLOAD_SU = 21
RET_SHUTDOWN_REQUESTED = 22
RET_NO_SUS_TO_DOWNLOAD = 23
RET_DOWNLOADER = 24
RET_SUPATH_CGI = 25
RET_UNABLE_TO_START_THREAD = 26
RET_QUEUE_FULL = 27
RET_DUPLICATE_DISPATCHER_TYPE = 28
RET_TOO_MANY_THREADS = 29
RET_UNABLE_TO_CONNECT_TO_DB = 30
RET_UNEXPECTED_DB_RESPONSE = 31
RET_USER_TERMINATED = 32

LOG_FILE_BASE_NAME = 'rslog'

SUM_MAIN = 'public.sum_main'
SUM_PARTN_ALLOC = 'public.sum_partn_alloc'

# decreasing priority is by increasing index
REQTYPE_CODES = [ 'U', 'M', 'G' ]
REQTYPE_TEXT = [ 'USER', 'MIRROR', 'GENERIC' ] # generic implies that the system does not specify a request type (it is an older system that did not differentiate request types)
REQTYPE_DOWNLOADER = [ 'HighPriorityDownloader', 'Downloader', 'Downloader' ]

def terminator(signo, frame):
    # Raise the SystemExit exception (which will be caught by the __exit__() method below).
    sys.exit(0)

class TerminationHandler(object):
    def __new__(cls, thContainer):
        return super(TerminationHandler, cls).__new__(cls)

    def __init__(self, thContainer):
        self.container = thContainer
        arguments = thContainer[0]
        self.pidStr = thContainer[1]
        self.log = thContainer[2]
        
        self.lockFile = arguments.lockfile
        self.dbname = arguments.dbname
        self.dbuser = arguments.dbuser
        self.dbhost = arguments.dbhost
        self.dbport = arguments.dbport
        self.conn = None
        
        self.sumsdbname = arguments.sumsdbname
        self.sumsdbuser = arguments.sumsdbuser
        self.sumsdbhost = arguments.sumsdbhost
        self.sumsdbport = arguments.sumsdbport
        self.sumsconn = None
        
        self.savedSignals = None

        super(TerminationHandler, self).__init__()
        
    def __enter__(self):
        self.enableInterrupts()

        # Acquire locks.
        self.rsLock = DrmsLock(self.lockFile, self.pidStr)
        self.rsLock.acquireLock()
        
        # Make main DB connection to RS database. We also have to connect to the SUMS database, so connect to that too.
        # The connections are NOT in autocommit mode. If changes need to be saved, then conn.commit() must be called.
        # Do this instead of using BEGIN and END/COMMIT statements, cuz I don't know if the psycopg2/libpq interaction
        # supports this properly.
        try:
            self.conn = psycopg2.connect(database=self.dbname, user=self.dbuser, host=self.dbhost, port=self.dbport)
            rslog.writeInfo([ 'Connected to DRMS database ' + self.dbname + ' on ' + self.dbhost + ':' + str(self.dbport) + ' as user ' + self.dbuser + '.' ])

            self.sumsconn = psycopg2.connect(database=self.sumsdbname, user=self.sumsdbuser, host=self.sumsdbhost, port=self.sumsdbport)
            rslog.writeInfo([ 'Connected to SUMS database ' + self.sumsdbname + ' on ' + self.sumsdbhost + ':' + str(self.sumsdbport) + ' as user ' + self.sumsdbuser + '.' ])            
        except psycopg2.DatabaseError as exc:
            self.__exit__(*sys.exc_info()) # clean up
            raise DBConnectionException('Unable to connect to a database.')
        except psycopg2.Error as exc:
            self.__exit__(*sys.exc_info()) # clean up
            raise DBConnectionException('Unable to connect to a database.')

        return self

    # Normally, __exit__ is called if an exception occurs inside the with block. And since SIGINT is converted
    # into a KeyboardInterrupt exception, it will be handled by __exit__(). However, SIGTERM will not - 
    # __exit__() will be bypassed if a SIGTERM signal is received. Use the signal handler installed in the
    # __enter__() call to handle SIGTERM.
    def __exit__(self, etype, value, traceback):
        self.log.writeDebug([ 'TerminationHandler.__exit__() called' ])
        if etype is not None:
            # If the context manager was exited without an exception, then etype is None
            import traceback
            self.log.writeDebug([ traceback.format_exc(5) ])

        print('Remote SUMS shutting down...')
        self.finalStuff()
        
        # Clean up lock
        try:     
            self.rsLock.releaseLock()   
            self.rsLock.close()
            self.rsLock = None
        except IOError:
            pass
            
        self.log.writeDebug([ 'Exiting TerminationHandler.' ])
        
        if etype == SystemExit:
            print('and done')
            raise TerminationException('Termination signal handler called.')
            
    def saveSignal(self, signo, frame):
        if self.savedSignals == None:
            self.savedSignals = []

        self.savedSignals.append((signo, frame))
        self.log.writeDebug([ 'saved signal ' +  str(signo) ])

    def disableInterrupts(self):
        signal.signal(signal.SIGINT, self.saveSignal)
        signal.signal(signal.SIGTERM, self.saveSignal)
        signal.signal(signal.SIGHUP, self.saveSignal)
        
    def enableInterrupts(self):
        signal.signal(signal.SIGINT, terminator)
        signal.signal(signal.SIGTERM, terminator)
        signal.signal(signal.SIGHUP, terminator)
        
        if type(self.savedSignals) is list:
            for signalReceived in self.savedSignals:
                terminator(*signalReceived)
        
        self.savedSignals = None

    def finalStuff(self):
        self.log.writeInfo([ 'halting threads' ])
        
        # shut-down Dispatchers
        Dispatcher.lock.acquire()
        try:
            for dispatcher in Dispatcher.tList:
                # send lastitem queue item to dispatchers
                lastitem = DispatcherQueueItem(cgi=None, sunums=None, sutable=None, dbuser=None, request=None, binpath=None, hastapesys=None, tmpdir=None, lastitem=True, log=self.log)                
                dispatcher.queue.put_nowait(lastitem)
                self.log.writeInfo([ 'waiting for Dispatcher ' + dispatcher.name + ' to halt' ])
        finally:
            Dispatcher.lock.release()

        while True:
            Dispatcher.lock.acquire()
            try:
                if len(Dispatcher.tList) > 0:
                    dispatcher = Dispatcher.tList[0]
                else:
                    break
            finally:
                Dispatcher.lock.release()

            if dispatcher and isinstance(dispatcher, (Dispatcher)) and dispatcher.isAlive():
                # wait for pending Dispatcher tasks to complete
                dispatcher.queue.join()
                dispatcher.join()

        # Shut-down ScpWorker threads. Send the sdEvent to all threads first, then wait after they have ALL received the message.
        # Otherwise, later threads could try to download SUs whose download was aborted by earlier threads.
        gotLock = False
        try:
            gotLock = ScpWorker.lock.acquire()
            if gotLock:
                for scpWorker in ScpWorker.tList:
                    self.log.writeInfo([ 'telling Scp Worker (ID ' + str(scpWorker.id) + ') to halt' ])
                    scpWorker.stop()
        finally:
            if gotLock:
                ScpWorker.lock.release()

        while True:
            gotLock = False
            scpWorker = None
            try:
                gotLock = ScpWorker.lock.acquire()
                # got lock - can't get here otherwise

                if len(ScpWorker.tList) > 0:
                    scpWorker = ScpWorker.tList[0]
                else:
                    break
            except:
                break
            finally:
                if gotLock:
                    ScpWorker.lock.release()

            if scpWorker and isinstance(scpWorker, (ScpWorker)) and scpWorker.isAlive():
                # can't hold worker lock here - when the worker terminates, it acquires the same lock
                self.log.writeInfo([ 'waiting for Scp Worker (ID ' + str(scpWorker.id) + ') to halt' ])
                scpWorker.join() # will block, possibly for ever

        # shut-down HighPriorityDownloader threads
        gotLock = False
        try:
            gotLock = HighPriorityDownloader.lock.acquire()
            if gotLock:
                for downloader in HighPriorityDownloader.tList:
                    self.log.writeInfo([ 'Waiting for Downloader (SUNUM ' + str(downloader.su.sunum) + ') to halt.' ])
                    downloader.stop()
        finally:
            if gotLock:
                HighPriorityDownloader.lock.release() 

        while True:
            gotLock = False
            try:
                gotLock = HighPriorityDownloader.lock.acquire()
                # got lock - can't get here otherwise

                if len(HighPriorityDownloader.tList) > 0:
                    downloader = HighPriorityDownloader.tList[0]
                else:
                    break 
            finally:
                if gotLock:
                    HighPriorityDownloader.lock.release()
                    
            if downloader and isinstance(downloader, (HighPriorityDownloader)) and downloader.isAlive():
                downloader.join() 
        
        # shut-down Downloader threads
        gotLock = False
        try:
            gotLock = Downloader.lock.acquire()
            if gotLock:
                for downloader in Downloader.tList:
                    self.log.writeInfo([ 'Waiting for Downloader (SUNUM ' + str(downloader.su.sunum) + ') to halt.' ])
                    downloader.stop()
        finally:
            if gotLock:
                Downloader.lock.release() 

        while True:
            gotLock = False
            try:
                gotLock = Downloader.lock.acquire()
                # got lock - can't get here otherwise

                if len(Downloader.tList) > 0:
                    downloader = Downloader.tList[0]
                else:
                    break 
            finally:
                if gotLock:
                    Downloader.lock.release()
                    
            if downloader and isinstance(downloader, (Downloader)) and downloader.isAlive():
                downloader.join()

        if self.sumsconn:
            self.sumsconn.close()
            self.sumsconn = None
                
        if self.conn:
            self.conn.close()
            self.conn = None
    
        self.log.flush()
        

    def rsConn(self):
        return self.conn

    def sumsConn(self):
        return self.sumsconn


class SumsDrmsParams(DRMSParams):
    def __init__(self):
        super(SumsDrmsParams, self).__init__()

    def get(self, name):
        val = super(SumsDrmsParams, self).get(name)

        if val is None:
            raise DrmsParamsException('Unknown DRMS parameter: ' + name + '.')
        return val


class Arguments(object):

    def __init__(self, parser):
        # This could raise in a few places. Let the caller handle these exceptions.
        self.parser = parser
        
        # Parse the arguments.
        self.parse()
        
        # Set all args.
        self.setAllArgs()
        
    def parse(self):
        try:
            self.parsedArgs = self.parser.parse_args()      
        except Exception as exc:
            if len(exc.args) == 2:
                type, msg = exc
                  
                if type != 'CmdlParser-ArgUnrecognized' and type != 'CmdlParser-ArgBadformat':
                    raise # Re-raise

                raise RSArgsException(msg)
            else:
                raise # Re-raise

    def setArg(self, name, value):
        if not hasattr(self, name):
            # Since Arguments is a new-style class, it has a __dict__, so we can
            # set attributes directly in the Arguments instance.
            setattr(self, name, value)
        else:
            raise RSArgsException('Attempt to set an argument that already exists: ' + name + '.')

    def setAllArgs(self):
        for key,val in list(vars(self.parsedArgs).items()):
            self.setArg(key, val)
        
    def getArg(self, name):
        try:
            return getattr(self, name)
        except AttributeError as exc:
            raise RSArgsException('Unknown argument: ' + name + '.')
            
    def dump(self, log):
        attrList = []
        for attr in sorted(vars(self)):
            attrList.append('  ' + attr + ':' + str(getattr(self, attr)))
        log.writeDebug([ '\n'.join(attrList) ])
        
    @classmethod
    def checkArg(cls, argName, exc, default, **kwargs):
        val = None
        if argName in kwargs:
            val = kwargs[argName]
        elif exc is not None:
            raise exc
        else:
            val = default
        return val


class Log(object):
    """Manage a logfile."""
    def __init__(self, file, level, formatter):
        self.fileName = file
        self.log = logging.getLogger()
        self.log.setLevel(level)
        self.fileHandler = logging.FileHandler(file)
        self.fileHandler.setLevel(level)
        self.fileHandler.setFormatter(formatter)
        self.log.addHandler(self.fileHandler)
        
    def close(self):
        if self.log:
            if self.fileHandler:
                self.log.removeHandler(self.fileHandler)
                self.fileHandler.flush()
                self.fileHandler.close()
                self.fileHandler = None
            self.log = None
            
    def flush(self):
        if self.log and self.fileHandler:
            self.fileHandler.flush()
            
    def getLevel(self):
        # Hacky way to get the level - make a dummy LogRecord
        logRecord = self.log.makeRecord(self.log.name, self.log.getEffectiveLevel(), None, '', '', None, None)
        return logRecord.levelname
        
    def __prependFrameInfo(self, msg):
        frame, fileName, lineNo, fxn, context, index = inspect.stack()[2]
        return os.path.basename(fileName) + ':' + str(lineNo) + ': ' + msg

    def writeDebug(self, text):
        if self.log:
            for line in text:                
                self.log.debug(self.__prependFrameInfo(line))
            self.fileHandler.flush()
            
    def writeInfo(self, text):
        if self.log:
            for line in text:
                self.log.info(self.__prependFrameInfo(line))
        self.fileHandler.flush()
    
    def writeWarning(self, text):
        if self.log:
            for line in text:
                self.log.warning(self.__prependFrameInfo(line))
            self.fileHandler.flush()
    
    def writeError(self, text):
        if self.log:
            for line in text:
                self.log.error(self.__prependFrameInfo(line))
            self.fileHandler.flush()
            
    def writeCritical(self, text):
        if self.log:
            for line in text:
                self.log.critical(self.__prependFrameInfo(line))
            self.fileHandler.flush()

class IntervalLogger(object):
    """create one object per loop"""
    def __init__(self, log, logInterval):
        self.log = log
        self.logInterval = logInterval
        self.lastWriteTime = None

    def timeToLog(self):        
        if self.lastWriteTime is None:
            return True
        else:
            timeNow = datetime.now(timezone.utc)
            if timeNow > self.lastWriteTime + self.logInterval:
                return True
            else:
                return False
            
    def updateLastWriteTime(self):
        if self.timeToLog():
            # update last print time only if the interval between last print and now has elapsed
            self.lastWriteTime = datetime.now(timezone.utc)

    def writeDebug(self, text):
        if self.timeToLog():
            self.log.writeDebug(text)

    def writeInfo(self, text):
        if self.timeToLog():
            self.log.writeInfo(text)

    def writeWarning(self, text):
        if self.timeToLog():
            self.log.writeWarning(text)

    def writeError(self, text):
        if self.timeToLog():
            self.log.writeError(text)

    def writeCritical(self, text):
        if self.timeToLog():
            self.log.writeCritical(text)


class RemoteSumsException(Exception):

    def __init__(self, msg):
        super(RemoteSumsException, self).__init__(msg)
        self.msg = msg # also in args[0] due to base-class constructor
        self.retcode = RET_UNKNOWN_ERROR

class DrmsParamsException(RemoteSumsException):

    def __init__(self, msg):
        super(DrmsParamsException, self).__init__(msg)
        self.retcode = RET_UNKOWN_DRMSPARAMETER
        
class RSArgsException(RemoteSumsException):

    def __init__(self, msg):
        super(RSArgsException, self).__init__(msg)
        self.retcode = RET_INVALID_REMOTE_SUMS_ARGUMENT

class InvalidArgumentException(RemoteSumsException):

    def __init__(self, msg):
        super(InvalidArgumentException, self).__init__(msg)
        self.retcode = RET_INVALID_ARGUMENT
        
class NoSUReferenceException(RemoteSumsException):

    def __init__(self, msg):
        super(NoSUReferenceException, self).__init__(msg)
        self.retcode = RET_SU_NOT_REFERENCED
        
class WorkerReferenceException(RemoteSumsException):

    def __init__(self, msg):
        super(WorkerReferenceException, self).__init__(msg)
        self.retcode = RET_WORKER_REFERENCE_ERROR

class LockException(RemoteSumsException):

    def __init__(self, msg):
        super(LockException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_ACQUIRE_LOCK
        
class LockAndHoldException(RemoteSumsException):

    def __init__(self, msg):
        super(LockAndHoldException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_LOCK_OBJECT

class SutableReadException(RemoteSumsException):

    def __init__(self, msg):
        super(SutableReadException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_READ_SUTABLE

class SutableWriteException(RemoteSumsException):

    def __init__(self, msg):
        super(SutableWriteException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_WRITE_SUTABLE
        
class ReqtableReadException(RemoteSumsException):

    def __init__(self, msg):
        super(ReqtableReadException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_READ_REQTABLE
        
class ReqtableWriteException(RemoteSumsException):

    def __init__(self, msg):
        super(ReqtableWriteException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_WRITE_REQTABLE
        
class SitetableReadException(RemoteSumsException):

    def __init__(self, msg):
        super(SitetableReadException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_READ_SITETABLE
        
class DuplicateSUException(RemoteSumsException):

    def __init__(self, msg):
        super(DuplicateSUException, self).__init__(msg)
        self.retcode = RET_DUPLICATE_SUNUM

class UnknownSunumException(RemoteSumsException):

    def __init__(self, msg):
        super(UnknownSunumException, self).__init__(msg)
        self.retcode = RET_UNKNOWN_SUNUM
        
class SumsAPIException(RemoteSumsException):

    def __init__(self, msg):
        super(SumsAPIException, self).__init__(msg)
        self.retcode = RET_ERROR_CALLING_SUMS_API
        
class UnknownRequestidException(RemoteSumsException):

    def __init__(self, msg):
        super(UnknownRequestidException, self).__init__(msg)
        self.retcode = RET_UNKNOWN_REQUESTID

class GetRetentionException(RemoteSumsException):

    def __init__(self, msg):
        super(GetRetentionException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_GET_RETENTION
        
class InvalidSunumException(RemoteSumsException):

    def __init__(self, msg):
        super(InvalidSunumException, self).__init__(msg)
        self.retcode = RET_INVALID_SUNUM

class UnknownSitecodeException(RemoteSumsException):

    def __init__(self, msg):
        super(UnknownSitecodeException, self).__init__(msg)
        self.retcode = RET_UNKNOWN_SITE_CODE
        
class ScpSUException(RemoteSumsException):

    def __init__(self, msg):
        super(ScpSUException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_DOWNLOAD_SU
        
class ShutDownException(RemoteSumsException):

    def __init__(self, msg):
        super(ShutDownException, self).__init__(msg)
        self.retcode = RET_SHUTDOWN_REQUESTED
        
class NoSusForDlException(RemoteSumsException):

    def __init__(self, msg):
        super(NoSusForDlException, self).__init__(msg)
        self.retcode = RET_NO_SUS_TO_DOWNLOAD
        
class DownloaderException(RemoteSumsException):

    def __init__(self, msg):
        super(DownloaderException, self).__init__(msg)
        self.retcode = RET_DOWNLOADER

class SUPathCGIException(RemoteSumsException):

    def __init__(self, msg):
        super(SUPathCGIException, self).__init__(msg)
        self.retcode = RET_SUPATH_CGI
        
class RSIOException(RemoteSumsException):

    def __init__(self, msg):
        super(RSIOException, self).__init__(msg)
        self.retcode = RET_IO_ERROR
        
class StartThreadException(RemoteSumsException):

    def __init__(self, msg):
        super(StartThreadException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_START_THREAD

class QueueFullException(RemoteSumsException):

    def __init__(self, msg):
        super(QueueFullException, self).__init__(msg)
        self.retcode = RET_QUEUE_FULL
        
class DuplicateDispatcherType(RemoteSumsException):

    def __init__(self, msg):
        super(DuplicateDispatcherType, self).__init__(msg)
        self.retcode = RET_DUPLICATE_DISPATCHER_TYPE
        
class MaxThreadsException(RemoteSumsException):

    def __init__(self, msg):
        super(MaxThreadsException, self).__init__(msg)
        self.retcode = RET_TOO_MANY_THREADS
        
class DBConnectionException(RemoteSumsException):

    def __init__(self, msg):
        super(DBConnectionException, self).__init__(msg)
        self.retcode = RET_UNABLE_TO_CONNECT_TO_DB
        
class DBResponseException(RemoteSumsException):

    def __init__(self, msg):
        super(DBResponseException, self).__init__(msg)
        self.retcode = RET_UNEXPECTED_DB_RESPONSE
        
class TimeoutException(RemoteSumsException):

    def __init__(self, msg):
        super(TimeoutException, self).__init__(msg)
        
        # do not set retcode - this error is never fatal

class TerminationException(RemoteSumsException):

    def __init__(self, msg):
        super(TerminationException, self).__init__(msg)
        self.retcode = RET_USER_TERMINATED

        
class StorageUnit(object):
    def __init__(self, sunum, series, retention, starttime, refcount, status, errmsg):
        self.sunum = sunum
        self.series = series
        self.retention = retention
        self.starttime = starttime
        self.refcount = refcount
        self.status = status
        self.errmsg = errmsg
        
        # not saved in the DB
        self.giveUpTheGhost = False
        self.dirty = False
        self.new = False
        self.path = None
        self.suSize = None
        self.worker = None
        
    def setDirty(self, value):
        if not isinstance(value, (bool)):
            raise InvalidArgumentException('setDirty(): argument must be a bool')
        
        self.dirty = value
        
    def getSunum(self):
        return self.sunum
        
    def getSeries(self):
        return self.series
            
    def setSeries(self, value):
        if not isinstance(value, (str)):
            raise InvalidArgumentException('setSeries(): argument must be a str')

        self.series = value
        self.setDirty(True)
        
    def getRetention(self):
        return self.retention
        
    def setRetention(self, value):
        if not isinstance(value, (int)):
            raise InvalidArgumentException('setRetention(): argument must be an integer')
            
        self.retention = value
        self.setDirty(True)
        
    def getStarttime(self):
        return self.starttime
    
    def setStarttime(self, value):
        if not isinstance(value, (datetime)):
            raise InvalidArgumentException('setStarttime(): argument must be a datetime')
            
        self.starttime = value
        self.setDirty(True)
        
    def touch(self):
        self.setStarttime(datetime.now(timezone.utc))
        
    def incrementRefcount(self):
        if self.giveUpTheGhost:
            # cannot increment refcount on an SU that has already been marked for deletion; it is as if
            # the SU does not exist any more
            raise NoSUReferenceException('cannot increment refcount on unreferenced SU record ' + str(self.sunum))

        self.refcount += 1
        self.setDirty(True)
        
        return self.refcount
        
    def decrementRefcount(self):
        if self.giveUpTheGhost:
            raise NoSUReferenceException('cannot decrement refcount on unreferenced SU record ' + str(self.sunum))
                    
        self.refcount -= 1
        if self.refcount == 0:
            self.giveUpTheGhost = True

        self.setDirty(True)
        
        return self.refcount
    
    def getStatus(self):
        return self.status
    
    # Set properties that are saved to the DB.
    def setStatus(self, codeValue, msgValue):
        if not isinstance(codeValue, (str)):
            raise InvalidArgumentException('setStatus(): fist argument must be a str.')
            
        if not isinstance(msgValue, (str)) and msgValue is not None:
            raise InvalidArgumentException('setStatus(): second argument must be a str or None.')
            
        self.status = codeValue
        if msgValue is not None:
            self.errmsg = msgValue
        else:
            self.errmsg = ''

        self.setDirty(True)
        
    # properties that are NOT saved to the DB
    def getNew(self):
        return self.new
    
    def setNew(self, value):
        if not isinstance(value, (bool)):
            raise InvalidArgumentException('setNew(): argument must be a bool')
            
        self.new = value
        
    def getPath(self):
        path = None
        if hasattr(self, 'path'):
            path = self.path
        return path
        
    def setPath(self, value):
        if not isinstance(value, (str)) and value is not None:
            raise InvalidArgumentException('setPath(): argument must be a str or None')
            
        self.path = value
        
    def getSize(self):
        return self.suSize
            
    def setSize(self, value):
        if not isinstance(value, (int)):
            raise InvalidArgumentException('setSize(): argument must be an int')
            
        self.suSize = value
    
    def getWorker(self):
        return self.worker
        
    def setWorker(self, value):
        if not isinstance(value, (Downloader)):
            raise InvalidArgumentException('setWorker(): argument must be a Downloader')
            
        if self.worker:
            raise WorkerReferenceException('cannot set worker for SU ' + str(self.sunum) + '; worker already exists')
            
        self.worker = value
        
    def removeWorker(self):
        self.worker = None
        
    def stopWorker(self):
        if hasattr(self, 'worker') and self.worker and isInstance(self.worker, (Downloader)) and self.worker.isAlive():
            self.worker.stop()
            if self.worker.isAlive():
                # Give the worker 15 seconds to self-terminate.
                self.worker.join(15)
            if self.worker.isAlive():
                # Apparently, there is no way to kill a thread from another thread. So, we are just going to
                # orphan the thread (so it doesn't use up our maxThreads quota).
                try:
                    self.worker.lock.acquire()
                    if self.worker in self.worker.tList:
                        self.worker.tList.remove(self.worker) # This thread is no longer one of the running threads.
                        if len(self.worker.tList) <= self.worker.maxThreads - 1:
                            # Fire event so that main thread can add new SUs to the download queue.
                            self.worker.eventMaxThreads.set()
                            # Clear event so that main will block the next time it calls wait.
                            self.worker.eventMaxThreads.clear()
                finally:
                    self.worker.lock.release()

            self.removeWorker()        


class SuTable:
    rsConn = None
    rsDbLock = None # There is one global lock for the rs connection. Since the main thread and the Downloader and ScpWorker threads
                    # all share the rs connection, they all need to use the same lock.

    sumsConn = None
    sumsDbLock = None # Since all Downloader threads and the main thread share the same connection, their cursors 
                      # on these connections are not isolated. Use a lock to ensure a consistent view in the
                      # offline() method.
    
    def __init__(self, tableName, timeOut, log):
        self.tableName = tableName
        self.timeOut = timeOut # A timedelta object - the length of time to wait for a download to complete.
        self.lock = threading.Lock()
        self.log = log
        self.suDict = {}
        self.queue = Queue(0) # non-blocking, infinite sized
        self.suMap = {} # map an SU to a ReqTable request

    def read(self):
        # sus(sunum, starttime, refcount, status, errmsg)
        cmd = 'SELECT sunum, series, retention, starttime, refcount, status, errmsg FROM ' + self.tableName
    
        try:
            gotRsDbLock = SuTable.rsDbLock.acquire()
            if gotRsDbLock:
                with SuTable.rsConn.cursor() as cursor:
                    cursor.execute(cmd)
            
                    for record in cursor:
                        sunumStr = str(record[0])

                        self.suDict[sunumStr] = {}
                        sunum = record[0]         # integer
                        series = record[1]        # text
                        retention = record[2]     # integer
                        # Whoa! pyscopg returns timestamps as datetime.datetime objects already!
                        starttime = record[3]     # datetime.datetime
                        refcount = record[4]      # integer
                        status = record[5]        # text
                        errmsg = record[6]        # text

                        su = StorageUnit(sunum, series, retention, starttime, refcount, status, errmsg)

                        # Not read from or saved to database.
                        su.setDirty(False)
                        su.setNew(False)
                        su.setPath(None)              # The server path of the SU to be downloaded.
                        # worker is already None
                        self.suDict[sunumStr] = su
        except psycopg2.Error as exc:
            raise SutableReadException(exc.diag.message_primary)
        finally:
            SuTable.rsConn.rollback() # We read from the DB only, so no need to commit anything.
            if gotRsDbLock:
                SuTable.rsDbLock.release()

    def tryRead(self):
        nAtts = 0
        while True:
            try:
                self.read()
                break
            except SutableReadException:                
                if nAtts > 10:
                    raise # Re-raise

            nAtts += 1
            time.sleep(1)
            
    def getUpdateDBSql(self, sunums=None):
        sql = []

        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False, filter=None) # want to get giveUpTheGhost sus
        try:
            if len(missingSunums) > 0:
                # the caller provided the sunums argument and it was not empty, and some of the provided sunums were invalid
                sunumStr = ','.join([ str(sunum) for sunum in missingSunums] )
                self.log.writeWarning([ 'SuTable.getUpdateDBSql() called with invalid SUNUMs: ' + sunumStr + '; skipping' ])

            for su in sus:
                if su.giveUpTheGhost:
                    sql.append('DELETE FROM ' + self.tableName + ' WHERE sunum = ' + str(su.sunum))
                    del self.suDict[ str(su.sunum) ]
                elif su.dirty:
                    if su.new:
                        sql.append('INSERT INTO ' + self.tableName + '(sunum, series, retention, starttime, refcount, status, errmsg) VALUES(' + str(su.sunum) + ",'" + su.series + "', " + str(su.retention) + ", '" + su.starttime.strftime('%Y-%m-%d %T%z') + "', " + str(su.refcount) + ", '" + su.status + "', '" + su.errmsg + "')")
                    else:
                        sql.append('UPDATE ' + self.tableName + " SET series='" + su.series + "', retention=" + str(su.retention) + ", starttime='" + su.starttime.strftime('%Y-%m-%d %T%z') + "', refcount=" + str(su.refcount) + ", status='" + su.status + "', errmsg='" + su.errmsg + "' WHERE sunum=" + str(su.sunum))

                    su.setDirty(False)
                    su.setNew(False)
        finally:
            self.releaseLock()
                
        return sql
    
    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes. Do not call rsConn.commit().
    #
    # ACQUIRES THE SU TABLE LOCK.
    # returns True if the DB was changed (in a uncommitted transaction)
    def updateDB(self, sql):
        if len(sql) > 0:
            # execute the SQL
            try:
                cmd = ';\n'.join(sql)

                self.log.writeDebug([ 'executing DB command: ' + cmd ])
                with SuTable.rsConn.cursor() as cursor:
                    cursor.execute(cmd)
                # The cursor has been closed, but the transaction has not been committed, as designed.
                self.log.writeDebug([ 'DB command succeeded: ' + cmd ])
            except psycopg2.Error as exc:
                import traceback
            
                SuTable.rsConn.rollback()
                self.log.writeError([ traceback.format_exc(5) ])
                raise SutableWriteException(exc.diag.message_primary)
            
            return True
        else:
            return False
        
    # This WILL commit changes to the db.
    def updateDbAndCommit(self, sunums=None):
        sql = self.getUpdateDBSql(sunums)

        SuTable.rsDbLock.acquire()
        try:
            if self.updateDB(sql):
                SuTable.rsConn.commit()
                self.log.writeDebug([ 'committed RS DB changes' ])
            else:
                self.log.writeDebug([ 'no SU changes made to DB' ])
        except:
            SuTable.rsConn.rollback()
            self.log.writeDebug([ 'rolled-back RS DB changes' ])
        finally:
            SuTable.rsDbLock.release()

    def acquireLock(self):
        return self.lock.acquire()
        # self.log.writeDebug(['Acquired SU-Table lock.'])
    
    def releaseLock(self):
        self.lock.release()
        # self.log.writeDebug(['Released SU-Table lock.'])
    
    # can be called from multiple threads; must have SU Table lock, or lockTable must be True
    def insert(self, **kwargs):
        sunums = Arguments.checkArg('sunums', None, None, **kwargs)
        lockTable = Arguments.checkArg('lockTable', None, True, **kwargs)
    
        gotTableLock = False
        try:
            # Get lock because we are modifying self.suDict.
            if lockTable:
                gotTableLock = self.acquireLock()
 
            for asunum in sunums:
                sunumStr = str(asunum)
        
                if sunumStr in self.suDict:
                    raise DuplicateSUException('SU-table record already exists for SU ' + sunumStr + '.')
                
                # sets refcount to 1
                su = StorageUnit(asunum, '', -1, datetime.now(timezone.utc), 1, 'P', '')

                su.setDirty(True)
                # Set the new flag (so that the record will be INSERTed into the SU database table instead of UPDATEd).
                su.setNew(True)
        
                self.suDict[sunumStr] = su
        finally:
            if lockTable and gotTableLock:
                self.releaseLock()
    
    # main thread only
    def newSUs(self, **kwargs):        
        sunums = Arguments.checkArg('sunums', None, None, **kwargs)

        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False, filter=SuTable.removeGhosts)
        try:            
            # increment refcount of existing SUs
            list(map((lambda su : su.incrementRefcount()), sus))

            # create new SU objects for SUs that do not currently exist
            for sunum in missingSunums:
                # sets refcount to 1
                su = StorageUnit(sunum, '', -1, datetime.now(timezone.utc), 1, 'P', '')

                su.setDirty(True)
                # Set the new flag (so that the record will be INSERTed into the SU database table instead of UPDATEd).
                su.setNew(True)
    
                self.suDict[str(su.sunum)] = su
        finally:            
            self.releaseLock()

    def setStatus(self, sunums, code, msg=None):
        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False, filter=SuTable.removeGhosts)
        try:
            for su in sus:
                su.setStatus(code, msg)
        finally:
            self.releaseLock()

    def setSeries(self, sunums, series):
        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False, filter=SuTable.removeGhosts)
        try:
            for su in sus:
                su.setSeries(series)
        finally:
            self.releaseLock()

    def setRetention(self, sunums, retention):    
        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False, filter=SuTable.removeGhosts)
        try:
            for su in sus:
                su.setRetention(retention)
        finally:
            self.releaseLock()

    def setStarttime(self, sunums, starttime):
        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False, filter=SuTable.removeGhosts)
        try:
            for su in sus:
                su.setStarttime(starttime)
        finally:
            self.releaseLock()

    def incrementRefcount(self, sunums):
        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False, filter=SuTable.removeGhosts)
        try:
            for su in sus:
                refCount = su.incrementRefcount()
                self.log.writeDebug([ 'incremented refcount for ' + str(su.sunum) + '; refcount is now ' + str(refCount) ])
        finally:
            self.releaseLock()

    def decrementRefcount(self, sunums):
        sus, missingSunums = self.getSUs(sunums=sunums, releaseTableLock=False, filter=SuTable.removeGhosts)
        try:
            for su in sus:
                refCount = su.decrementRefcount()
                self.log.writeDebug([ 'decremented refcount for ' + str(su.sunum) + '; refcount is now ' + str(refCount) ])
        finally:
            self.releaseLock()

    def setWorker(self, sunum, worker):
        sunumStr = str(sunum)

        sus, missingSunums = self.getSUs(sunums=[ sunum ], releaseTableLock=False, filter=SuTable.removeGhosts)
        try:
            if len(sus) == 1:
                su = sus[0]
                su.setWorker(worker)
            else:
                raise WorkerReferenceException('cannot set worker for SU ' + str(self.sunum) + '; SU does not exist')
        finally:
            self.releaseLock()

    # class private, to prevent code outside this class from calling this method without first locking the table;
    # we need to lock the table since it reads self.suDict
    def __get(self, sunums=None):
        # DOES NOT acquire table lock; this method is called by SUTable.getSUs(), which acquires the
        # table lock; does not filter-out SUs with the giveUpTheGhost attribute since callers of this
        # function may need to act on those SUs
        foundSUs = []
        notfoundSunums = []
        
        if sunums is None:
            for sunumStr, su in self.suDict.items():
                foundSUs.append(su)
        else:
            for asunum in sunums:
                sunumStr = str(asunum)
    
                try:
                    if not sunumStr in self.suDict or not self.suDict[sunumStr]:
                        raise UnknownSunumException('(__get) no SU-table record exists for SU ' + sunumStr)
                    foundSUs.append(self.suDict[sunumStr])
                except:
                    notfoundSunums.append(asunum)

        return (foundSUs, notfoundSunums)

    # some SUs may not exist; return a tuple - the first element is a list of existing SUs, and the second element is
    # a list of invalid SUNUMs
    def getSUs(self, **kwargs):
        lockTable = Arguments.checkArg('lockTable', None, True, **kwargs)
        releaseTableLock = Arguments.checkArg('releaseTableLock', None, True, **kwargs)
        sunums = Arguments.checkArg('sunums', None, None, **kwargs)
        filter = Arguments.checkArg('filter', None, None, **kwargs)

        sus = [] # known SUs
        missingSunums = [] # missing SUs plus ghosts

        if lockTable:
            self.acquireLock()
        try:
            # lock acquired (can't get here otherwise)
            sus, missingSunums = self.__get(sunums)
            
            if filter:
                filteredSus, deletedSus = filter(sus)
                if len(deletedSus) > 0:
                    missingSunums.extend(deletedSus)

                sus = filteredSus
        finally:
            # Always release lock.
            if lockTable and releaseTableLock:
                self.releaseLock()
                
        return (sus, missingSunums)

    # Returns a list of SU objects.
    # NOT THREAD SAFE! This method is called by the main thread on start-up, before any other threads have been started.
    def getPending(self):
        pending = []
        
        for sunumStr, su in self.suDict.items():                
            if su.status == 'P':
                su.touch()
                pending.append(su)

        # Sorts in place - and returns None. The SUs will be sorted by starttime later, before Downloader threads are created
        # for them.
        pending.sort(key=lambda ansu : ansu.sunum)

        return pending
        
    # Returns a list of SU objects.
    # NOT THREAD SAFE! This method is called by the main thread on start-up, before any other threads have been started.
    def getWorking(self):
        working = []
        
        for sunumStr, su in self.suDict.items():                
            if su.status == 'W':
                su.touch()
                working.append(su)

        # Sorts in place - and returns None. The SUs will be sorted by starttime later, before Downloader threads are created
        # for them.
        working.sort(key=lambda ansu : ansu.sunum)

        return working
    
    # Returns num SU entries whose status is 'W'. If fewer than num W entries exist, then all W SU entries are returned.
    # Must acquire SU table lock before calling this method. There is no need to lock the individual SUs because the ScpWorker
    # threads must acquire the SU Table lock before calling getNextNWorking(). No other ScpWorker thread can 
    # change a W to a D while this ScpWorker is collecting SUs with a W status.
    #
    # Sort by start time - process the oldest first.
    #
    # All SUs returned MUST have the same scpUser, scpHost, and scpPort.
    def getNextNWorkingSUs(self, id, num):
        nworking = []
        scpUser = None
        scpHost = None
        scpPort = None
        scpInfoSet = False

        # get lock because we are reading self.suDict
        self.acquireLock()
        try:
            # do a double sort (priority, start-time)
            sortedSUs = sorted(list(self.suDict.values()), key=lambda su : (0 if hasattr(su, 'worker') and isinstance(su.worker, (HighPriorityDownloader)) else 100, su.starttime.strftime('%Y-%m-%d %T')))
            it = iter(sortedSUs)
            try:
                while num > 0:
                    su = next(it)
                    try:
                        if su.status == 'W':
                            su.touch()
                            if su.worker is None:
                                raise WorkerReferenceException('no worker thread assigned to SU ' + str(su.sunum))
                            if scpInfoSet == False:
                                scpUser = su.worker.scpUser
                                scpHost = su.worker.scpHost
                                scpPort = su.worker.scpPort
                                scpInfoSet = True

                            if su.worker.scpUser == scpUser and su.worker.scpHost == scpHost and su.worker.scpPort == scpPort:
                                nworking.append(su)
                                num -= 1
                    except:
                        # remove su from nworking (if we appended it)
                        if su in nworking:
                            nworking.pop()
                    finally:
                        pass
            except StopIteration:
                pass
        except:
            import traceback
            self.log.writeError([ traceback.format_exc(5) ])
            nworking = []

        return (nworking, (scpUser, scpHost, scpPort))      

    def getTimeout(self):
        return self.timeOut

    def addRequestToSUMap(self, sunum, requestID):
        if str(sunum) not in self.suMap:
            self.suMap[str(sunum)] = []

        self.suMap[str(sunum)].append(requestID)
        
    def removeRequestFromSUMap(self, su, requestID):
        if str(su.sunum) in self.suMap:
            self.suMap[str(su.sunum)].remove(requestID)
            if len(self.suMap[str(su.sunum)]) == 0:
                del self.suMap[str(su.sunum)]                

    @classmethod
    def offline(cls, sunums, log):
        rv = []        

        if len(sunums) > 0:
            # query the SUMS db and check to see which of the SUs in sunums are present in the sum_main/sum_partn_alloc table
            cmd = "SELECT T1.ds_index, T1.online_loc, T1.online_status, T1.archive_status, T1.offsite_ack, T1.history_comment, T1.owning_series, T1.storage_group, T1.bytes, T1.create_sumid, T1.creat_date, T1.username, COALESCE(T1.arch_tape, 'N/A'), COALESCE(T1.arch_tape_fn, 0), COALESCE(T1.arch_tape_date, '1958-01-01 00:00:00'), COALESCE(T1.safe_tape, 'N/A'), COALESCE(T1.safe_tape_fn, 0), COALESCE(T1.safe_tape_date, '1958-01-01 00:00:00'), COALESCE(T2.effective_date, '195801010000'), coalesce(T2.status, 0), coalesce(T2.archive_substatus, 0) FROM " + SUM_MAIN + " AS T1 LEFT OUTER JOIN " + SUM_PARTN_ALLOC + " AS T2 ON (T1.ds_index = T2.ds_index) WHERE T1.ds_index IN (" + ','.join([ str(asunum) for asunum in sunums ]) + ')'

            try:
                gotSumsDbLock = SuTable.sumsDbLock.acquire()
                if gotSumsDbLock:
                    with SuTable.sumsConn.cursor() as cursor:
                        knownSUs = {} # bitmap of SUs known to the SUMS db.
                        try:                    
                            cursor.execute(cmd)
                            log.writeDebug([ 'Successfully queried SUMS db for known SUs.' ])
                        
                            # Put each SU in the result into the bitmap.
                            for row in cursor:
                                knownSUs[str(row[0])] = True
                        
                            # Determine which SUs for which we are going to initiate Downloaders that are not already in SUMS.
                            for ansunum in sunums:                        
                                if str(ansunum) not in knownSUs:
                                    rv.append(ansunum)
                        except psycopg2.Error as exc:
                            # Handle database-command errors. These are all due to problems communicating with the SUMS db.
                            raise SumsAPIException(exc.diag.message_primary + ': ' + cmd + '.') 
                        finally:
                            # Not making changes, so rollback always.
                            SuTable.sumsConn.rollback()
            finally:
                if gotSumsDbLock:
                    SuTable.sumsDbLock.release()

        return rv
    
    # must call from a getSU...() method
    @classmethod
    def removeGhosts(cls, sus):
        retKept = []
        retRemoved = []

        for su in sus:
            if not su.giveUpTheGhost:
                retKept.append(su)
            else:
                retRemoved.append(su)

        return (retKept, retRemoved)


class ReqTable:
    '''
    '''
    rsConn = None
    rsDbLock = None # There is one global lock for the rs connection. Since the main thread and the Downloader and ScpWorker threads
                    # all share the rs connection, they all need to use the same lock.

    def __init__(self, tableName, timeOut, log):
        self.tableName = tableName
        self.timeOut = timeOut
        self.log = log
        self.reqDict = {}
    
    def read(self):
        # to support SU priority, we had to add a column at some point; not all releases have this column; as a result, we do not know the exact set of columns; so basically we have to deal with a PITA
        try:
            gotRsDbLock = ReqTable.rsDbLock.acquire()
            if gotRsDbLock:
                with ReqTable.rsConn.cursor() as cursor:
                    cmd1 = 'SELECT * FROM ' + self.tableName + ' LIMIT 0'
                    cursor.execute(cmd1)
                    cols = [ desc[0] for desc in cursor.description ]
                    
                    # now we gotta check to make sure all columns are there (but 'type' might not be there, since it was added after remote SUMS went public)
                    if not all(acol in cols for acol in [ 'requestid', 'dbhost', 'dbport', 'dbname', 'starttime', 'sunums', 'status', 'errmsg' ]):
                        raise ReqtableReadException('at least one request table column is missing')
                    
                    cmd2 = 'SELECT ' + ','.join(cols) + ' FROM ' + self.tableName                
                    cursor.execute(cmd2)
        
                    for record in cursor:
                        # psycopg2 converts db type to Python types:
                        # requestid --> integer
                        # dbhost --> text
                        # dbport -> integer
                        # dbname -> text
                        # type --> text
                        # starttime --> datetime.datetime
                        # sunums --> text
                        # status --> text
                        # errmsg --> text

                        requestidStr = str(record[0])

                        self.reqDict[requestidStr] = {}
                        
                        for c, v in zip(cols, record):
                            if c.lower() == 'sunums':
                                self.reqDict[requestidStr][c] = [ int(asunum) for asunum in v.split(',') ]
                            elif c.lower() == 'type':
                                # ensure this is a valid type
                                if v not in REQTYPE_CODES:
                                    raise ReqtableReadException('unknown request type ' + v)
                                self.reqDict[requestidStr][c] = dict(zip(REQTYPE_CODES, REQTYPE_TEXT))[v]
                            else:
                                self.reqDict[requestidStr][c] = v
                                
                        # if type does not exist, set it to generic
                        if 'type' not in self.reqDict[requestidStr]:
                            self.reqDict[requestidStr]['type'] = 'GENERIC'
                        
                        # internal attributes
                        self.reqDict[requestidStr]['todispatch'] = self.reqDict[requestidStr]['sunums'].copy() # as sunums as dispatched, they are removed from the 'todispatch' list
                        self.reqDict[requestidStr]['complete'] = []
                        self.reqDict[requestidStr]['dirty'] = False
        except psycopg2.Error as exc:
            raise ReqtableReadException(exc.diag.message_primary)
        finally:
            ReqTable.rsConn.rollback()
            
            if gotRsDbLock:
                ReqTable.rsDbLock.release()

    def tryRead(self):
        nAtts = 0
        while True:
            try:
                self.read()
                break
            except ReqtableReadException:
                if nAtts > 10:
                    raise # Re-raise

            nAtts += 1
            time.sleep(1)

    # This method finds 'N' records inserted since the last time it was run (or since the table was first read). It ignores
    # all other changes to the database table (made from outside this program) that have happened. To read those changes,
    # shut down this program, then make the changes, then start this program again.
    def refresh(self):
        # save attributes not saved in the db
        saved = {}
        for (key, val) in self.reqDict.items():
            if 'todispatch' not in saved:
                saved['todispatch'] = {}
                
            if 'complete' not in saved:
                saved['complete'] = {}
                
            saved['todispatch'][key] = val['todispatch']
            saved['complete'][key] = val['complete']
    
        # delete existing items from self
        self.reqDict = {}
        
        # Read the table from the database anew.
        self.tryRead()
        
        # we have to restore the things that do not stick in the db (but only for pending requests)
        # no need to hold a lock since only the main thread accesses the request status
        for (key, val) in self.reqDict.items():
            if self.reqDict[key]['status'] != 'N':
                self.reqDict[key]['todispatch'] = saved['todispatch'][key]
                self.reqDict[key]['complete'] = saved['complete'][key]

    def getUpdateDBSql(self, requestids=None):
        sql = []

        if requestids:
            # Update the specified records.
            for arequestid in requestids:
                requestidStr = str(arequestid)
            
                if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                    self.log.writeWarning([ 'no request-table record exists for ID ' + requestidStr + '; skipping' ])
                
                if self.reqDict[requestidStr]['dirty']:
                    self.log.writeDebug([ 'updating req table DB for request ' + requestidStr ])
                    # The only columns that this daemon will modify are status and errmsg.
                    sql.append('UPDATE ' + self.tableName + " SET status='" + self.reqDict[requestidStr]['status'] + "', errmsg='" + self.reqDict[requestidStr]['errmsg'] + "' WHERE requestid=" + requestidStr)
                    
                    self.reqDict[requestidStr]['dirty'] = False
        else:
            for requestidStr in self.reqDict:
                if self.reqDict[requestidStr]['dirty']:
                    self.log.writeDebug([ 'updating req table DB for request ' + requestidStr ])
                    # The only columns that this daemon will modify are status and errmsg.
                    sql.append('UPDATE ' + self.tableName + " SET status='" + self.reqDict[requestidStr]['status'] + "', errmsg='" + self.reqDict[requestidStr]['errmsg'] + "' WHERE requestid='" + requestidStr + "'")
                    
                    self.reqDict[requestidStr]['dirty'] = False
                    
        return sql

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes.
    # no lock needed for the requests table (only the main thread access it)
    # returns True if the DB was changed (inside the current, uncommitted transaction), False otherwise
    def updateDB(self, sql):        
        if len(sql) > 0:
            try:
                cmd = ';\n'.join(sql)
                self.log.writeDebug([ 'executing DB command: ' + cmd])
                with ReqTable.rsConn.cursor() as cursor:
                    cursor.execute(cmd)
                # The cursor has been closed, but the transaction has not been committed, as designed.
            except psycopg2.Error as exc:
                import traceback
                
                self.log.writeError([ traceback.format_exc(5) ])
                ReqTable.rsConn.rollback()
                self.log.writeDebug([ 'rolling-back req table DB update' ])
                raise ReqtableWriteException(exc.diag.message_primary)
                
            return True
        else:
            return False
                    
    # This WILL commit changes to the db.
    def updateDbAndCommit(self, requestids=None):
        sql = self.getUpdateDBSql(requestids)
        
        ReqTable.rsDbLock.acquire()
        try:
            if self.updateDB(sql):
                ReqTable.rsConn.commit()
                self.log.writeDebug([ 'committed RS DB changes' ])
            else:
                self.log.writeDebug([ 'no request changes made to DB' ])
        except:
            self.log.writeDebug([ 'rolled-back RS DB changes' ])
            ReqTable.rsConn.rollback()
        finally:
            ReqTable.rsDbLock.release()

    # This will NOT commit database changes. You are generally going to want to do this as part of a larger db change. Commit the changes
    # after all changes that form the atomic set of changes. Do not call rsConn.commit().
    def deleteDB(self, requestids):
        if len(requestids) > 0:
            for arequestid in requestids:
                requestidStr = str(requestid)
                
                if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                    raise UnknownRequestidException('No request-table record exists for ID ' + requestidStr + '.')

                del self.reqDict[requestidStr]
            
            reqidLstStr = ','.join(requestids)
            
            cmd = 'DELETE FROM ' + self.tableName + ' WHERE requestid=' + reqidLstStr
            
            needsRollback = True
            try:
                gotRsDbLock = ReqTable.rsDbLock.acquire()
                if gotRsDbLock:
                    with ReqTable.rsConn.cursor() as cursor:
                        cursor.execute(cmd)
                    needsRollback = False
                    # The cursor has been closed, but the transaction has not been committed, as designed.
            except psycopg2.Error as exc:
                raise ReqtableWriteException(exc.diag.message_primary + ': ' + cmd)
            finally:
                if needsRollback:
                    ReqTable.rsConn.rollback()
                if gotRsDbLock:
                    ReqTable.rsDbLock.release()

    def setStatus(self, requestids, code, msg=None):
        for arequestid in requestids:
            requestidStr = str(arequestid)
        
            if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                raise UnknownRequestidException('No request-table record exists for ID ' + requestidStr + '.')
            
            self.reqDict[requestidStr]['status'] = code
            if msg:
                self.reqDict[requestidStr]['errmsg'] = msg
            else:
                self.reqDict[requestidStr]['errmsg'] = ''
            
            # Set dirty flag
            self.reqDict[requestidStr]['dirty'] = True

    def get(self, requestids=None):
        toRet = []
    
        if not requestids:
            return [ self.reqDict[key] for (key, val) in self.reqDict.items() ]
        
        for arequestid in requestids:
            requestidStr = str(arequestid)
            
            if not requestidStr in self.reqDict or not self.reqDict[requestidStr]:
                raise UnknownRequestidException('No request-table record exists for ID ' + requestidStr + '.')
    
            toRet.append(self.reqDict[requestidStr])
    
        return toRet        
    
    def getPending(self):
        pendLst = []

        for requestidStr, reqObj in self.reqDict.items():
            if reqObj['status'] == 'P':
                pendLst.append(reqObj)

        # Sort by start time. Sorts in place - and returns None.
        pendLst.sort(key=lambda dict : dict['starttime'].strftime('%Y-%m-%d %T'))
    
        return pendLst
    
    def getNew(self):
        newLst = []                
                
        for requestidStr, reqObj in self.reqDict.items():
            if reqObj['status'] == 'N':
                newLst.append(reqObj) # reqObj is a dictionary

        # sort by request (priority, start-time), in place
        newLst.sort(key=ReqTable.sortByPriorityAndTime)
        return newLst

    def getDelete(self):
        deleteLst = []
                
        for requestidStr, reqObj in self.reqDict.items():
            if reqObj['status'] == 'D':
                deleteLst.append(reqObj)
                
        deleteLst.sort(key=lambda dict : dict['requestid'])

        return deleteLst

    def getTimeout(self):
        return self.timeOut
    
    @classmethod
    def sortByPriorityAndTime(cls, requestDict):
        # return tuple (priority-index, start-time)
        return (dict(zip(REQTYPE_TEXT, list(range(len(REQTYPE_TEXT)))))[requestDict['type']], requestDict['starttime'].strftime('%Y-%m-%d %T'))


# The site information is stored in a public database table at Stanford. It is accessible by all remote sites
# with the rssites.sh cgi. To obtain information about all sites, the rssites.sh cgi is called with no parameters.
# Otherwise, information about a single site can be obtained by by providing the site name to the 'site' argument.
# The information is stored in drms.rs_sites on hmidb.
class SiteTable:
    def __init__(self, url, log):
        self.url = url # rssites.sh URL
        self.log = log
        self.siteDict = {} # Keyed by name.
        self.siteMap = {} # Map from str(code) to name.

    def read(self):
        natt = 0
        while True:
            try:
                self.log.writeDebug([ 'opening URL ' + self.url ])
                with urllib.request.urlopen(self.url) as response:
                    siteInfoStr = response.read().decode('UTF-8')
                    natt = 0
                break
            except urllib.error.URLError as exc:
                # we want to try again, until we time-out
                natt += 1
                if natt > 2:
                    raise SitetableReadException("unable to access URL " + self.url)
                if type(exc.response) is str:
                    msg = exc.response
                else:
                    msg = ''
                log.writeWarning([ 'failed to access site-table URL (' + self.url + '); trying again.' ])
                time.sleep(1)

        # siteInfoStr is a string, that happens to be json.
        siteInfo = json.loads(siteInfoStr)
        
        if siteInfo['status'] != 'success':
            raise SitetableReadException("Failure calling cgi '" + self.url + "'.")

        # siteInfo is a dictionary, keyed by site name. Each dictionary entry is a dictionay, with two keys: code and baseurl.
        for asite, info in siteInfo.items():
            if asite == 'status':
                # Skip status.
                continue
            self.siteDict[asite] = {}
            self.siteDict[asite]['name'] = asite
            self.siteDict[asite]['code'] = info['code']
            self.siteDict[asite]['baseurl'] = info['baseurl']
            self.siteDict[asite]['cgi-supath'] = info['cgi-supath']
            self.siteMap[str(self.siteDict[asite]['code'])] = asite

            self.log.writeInfo([ 'Reading site info for ' + asite + ': code => ' + str(self.siteDict[asite]['code']) + ', baseurl => ' + self.siteDict[asite]['baseurl'] + ', cgi-supath => ' + self.siteDict[asite]['cgi-supath'] ])

    def tryRead(self):
        nAtts = 0
        while True:
            try:
                self.read()
                break
            except SitetableReadException:
                if nAtts > 10:
                    raise # Re-raise

            nAtts += 1
            time.sleep(1)

    @staticmethod
    def getCode(sunum):
        code = sunum >> 48
        if code & 0xC000 != 0:
            raise InvalidSunumException('The site-code value of SUNUM ' + sunum + ' is out of range (valid range is 0 to 16383).')

        return code

    def getBaseURL(self, sunum):
        code = SiteTable.getCode(sunum)
        
        if not str(code) in self.siteMap or not self.siteMap[str(code)]:
            raise UnknownSitecodeException('There is no site in the site table for code ' + str(code) + '.')
        
        name = self.siteMap[str(code)]
        url = self.siteDict[name]['baseurl']
        return url
        
    def getSuPathCGI(self, sunum):
        code = SiteTable.getCode(sunum)
        
        if not str(code) in self.siteMap or not self.siteMap[str(code)]:
            raise UnknownSitecodeException('There is no site in the site table for code ' + str(code) + '.')

        name = self.siteMap[str(code)]
        url = urllib.parse.urljoin(self.siteDict[name]['baseurl'], self.siteDict[name]['cgi-supath'])
        return url
    
    
class Chunker(object):
    def __init__(self, list, chSize):
        self.chunks = []
        iChunk = -1
        nElem = 1
        
        for elem in list:
            if iChunk == -1 or nElem % chSize == 0:
                iChunk += 1
                self.chunks.append([])
    
            self.chunks[iChunk].append(elem)
            nElem += 1
    
    def __iter__(self):
        return self.iterate()
    
    # Iterate through chunks.
    def iterate(self):
        i = 0
        while i < len(self.chunks):
            yield self.chunks[i]
            i += 1
            
class ScpWorker(threading.Thread):
    tList = [] # A list of running thread IDs.
    maxThreads = 64
    scpNeeded = threading.Event() # event fired by main when a Downloader thread has changed the state of an SU from 'P' to 'W'
    lock = threading.Lock() # Guard tList.
    
    def __init__(self, id, suTable, arguments, log):
        threading.Thread.__init__(self)
        self.id = id
        self.suTable = suTable
        self.tmpdir = arguments.tmpdir
        self.arguments = arguments
        self.log = log
        self.sdEvent = threading.Event()

    def run(self):
        gotSULock = False
        maxNumSUs = self.arguments.scpMaxNumSUs
        maxPayloadSUs = self.arguments.scpMaxPayload
        scpTimeOut = self.arguments.scpTimeOut
        doDownload = False
        lastDownloadTime = None
        
        self.log.writeDebug([ 'running ScpWorker ' + str(self.id) ])

        try:
            # the finally clause ensures that this thread will remove itself from the static list of threads
            # before it terminates
            while not self.sdEvent.isSet():
                sunums = []
                paths = []

                # Look for an SU whose status is 'W' (which means that a Downloader thread is requesting an ScpWorker thread perform a 
                # download for it). If we find one, set status to 'D' and download the SU. When the download is complete, set the status
                # to 'F' so the requesting Downloader thread can clean-up and set the status to 'C' for the main thread to handle
                # 
                # acquires SU table lock
                (workingSUs, (user, host, port)) = self.suTable.getNextNWorkingSUs(self.id, maxNumSUs)
                try:
                    # no SU in workingSUs can have errored out at this point
                    susToDownload = []
                    doDownload = False
                    numSUs = len(workingSUs)
                    payload = sum([ su.suSize for su in workingSUs ])
                    currentTime = datetime.now(timezone.utc)

                    if numSUs > 0:
                        self.log.writeDebug([ 'examining ' + str(numSUs) + ' working SUs' ])
                        doDownload = payload > maxPayloadSUs or numSUs == maxNumSUs
                    
                        # Now we need to modify workingSUs if the payload would be too large, or there would be too many SUs for this scp.
                        payload = 0
                        numSUs = 0
                        for su in workingSUs:
                            if (payload + su.suSize > maxPayloadSUs and numSUs > 0) or numSUs + 1 > maxNumSUs:
                                break
                        
                            susToDownload.append(su)
                            payload += su.suSize
                            numSUs += 1                    
                    
                        self.log.writeDebug([ 'doDownload calc (payload, maxPayLoadSUs, numSUs, maxNumSUs, currentTime, lastDownloadTime, scpTimeOut): ' + str(payload) + ',' + str(maxPayloadSUs) + ',' + str(numSUs) + ',' + str(maxNumSUs) + ',' + str(currentTime) + ',' + str(lastDownloadTime) + ',' + str(scpTimeOut) + ')' ])

                        if doDownload:                            
                            # Set lastDownloadTime. We will keep setting this, until we complete the scp - that is the best place to
                            # set it, but errors before that could cause us to not set it.
                            lastDownloadTime = datetime.now(timezone.utc)
                        else:
                            # Now it could be that at least one SU has been waiting a long time. If that is true, then 
                            # do a download.
                            if lastDownloadTime is None:
                                lastDownloadTime = datetime.now(timezone.utc)
                            
                            if currentTime - lastDownloadTime > scpTimeOut:
                                doDownload = True
                    else:
                        doDownload = False
                
                    if doDownload:
                        self.log.writeInfo([ 'ScpWorker ' + str(self.id) + ' - Time for a download! Collected ' + str(len(susToDownload)) + ' for download; payload is ' + str(payload) ])
                    
                        # all SUs are locked so no other thread modifies the SUs while we are processing the download
                        for su in susToDownload:                        
                            sunums.append(su.sunum)                            
                            serverPath = su.worker.path
                            if not serverPath:
                                raise ScpSUException('server SU path is not known')
                            paths.append(serverPath)
                    
                            # Set status to D to prevent another ScpWorker from processing the download. Must do this
                            # before the SU Table lock is released, otherwise another ScpWorker could grab the same
                            # SU that this ScpWorker just grabbed.
                            self.log.writeInfo([ 'ScpWorker setting SU ' + str(su.sunum) + ' status to D' ])
                            su.setStatus('D', None)
                                
                        if len(sunums) == 0:
                            doDownload = False
                finally:
                    # release SU Table lock - now other ScpWorkers can look for W SUs
                    self.suTable.releaseLock()

                if doDownload:
                    try:
                        self.log.writeInfo([ 'ScpWorker ' + str(self.id) + ' downloading SUs ' + ','.join([ str(asunum) for asunum in sunums ]) + '.' ])                        

                        # Don't forget to make the temporary directory first.
                        if not os.path.exists(self.tmpdir):
                            self.log.writeInfo([ 'Creating temporary download directory ' + self.tmpdir + '.' ])
                            os.mkdir(self.tmpdir)

                        lastDownloadTime = datetime.now(timezone.utc)
                    
                        cmd = 'scp -r -P ' + port + ' ' + user + '@' + host + ':"' + ' '.join(paths) + '" ' + self.tmpdir
                        self.log.writeInfo([ 'ScpWorker ' + str(self.id) + ' running ' + cmd + '.' ])
                        try:
                            # check_call(cmdList)
                            # The scp process will inherit stdin, stdout, and stderr from this script.
                            # proc = Popen(cmdList, stdout=PIPE, stderr=PIPE)
                            proc = Popen(cmd, shell=True, stdout=PIPE, stderr=PIPE, start_new_session=True)
                        except OSError as exc:
                            import traceback
                            self.log.writeError([ traceback.format_exc(5) ])
                            raise ScpSUException('Cannot run scp command.')
                        except ValueError as exc:
                            import traceback
                            self.log.writeError([ traceback.format_exc(5) ])
                            raise ScpSUException('scp command called with invalid arguments.')

                        # Poll for completion
                        while True:
                            # The Python documentation is confusing at best. I think we have to look at the proc.returncode attribute
                            # to determine if the child process has completed. None means it hasn't. If the value is not None, then 
                            # the child process has terminated, and the value is the child process's return code.
                            lastDownloadTime = datetime.now(timezone.utc)
                        
                            proc.poll()
                            if proc.returncode is not None:                        
                                # the scp has completed
                                out, err = proc.communicate()
                                self.log.writeInfo([ 'ScpWorker ' + str(self.id) + ' - scp process exited with return code ' + str(proc.returncode) + '.' ])
                                lastDownloadTime = datetime.now(timezone.utc)
                                if proc.returncode != 0:
                                    msg = 'Command "' + cmd + '" returned non-zero status code ' + str(proc.returncode) + '.'
                                    if err is not None:
                                        self.log.writeError([ 'scp stderr msg: ' + err.decode('UTF8') ])
                                    raise ScpSUException(msg)
                                break

                            atLeastOneGoodSU = False

                            # this locks and releases the SU Table
                            sus, missingSunums = self.suTable.getSUs(sunums=sunums, filter=SuTable.removeGhosts)
                            for su in sus:
                                # check for SU download time-out; we keep doing the download, unless all SUs have timed out
                                timeNow = datetime.now(su.starttime.tzinfo)
                                if timeNow > su.starttime + self.suTable.getTimeout():
                                    self.log.writeInfo([ 'download of SUNUM ' + str(su.sunum) + ' timed-out in ScpWorker' ])
                                    # communicate result to Worker - the Worker will see a D status (and no shutdown event), and know that
                                    # there was a download time-out
                                    scpComplete = su.worker.getScpComplete()
                                    with scpComplete:
                                        scpComplete.notify()
                                else:
                                    atLeastOneGoodSU = True

                            if self.sdEvent.isSet():
                                # kill the download and also exit the ScpWorker thread.
                                self.log.writeDebug([ 'ScpWorker ' + str(self.id) + ' received sdEvent; killing scp'])
                                proc.kill()

                                try:
                                    proc.communicate(timeout=4)
                                    self.log.writeInfo([ 'successfully killed ScpWorker ' + str(self.id) + ' download' ])
                                except TimeoutExpired:
                                    self.log.writeWarning([ 'unable to kill scp for ScpWorker ' + str(self.id) ])
                                
                                raise ShutDownException('ScpWorker ' + str(self.id) + ' is observing the global shutdown and exiting now')
                        
                            if not atLeastOneGoodSU:
                                # go on to the next set of requested SUs; don't exit the ScpWorker thread
                                proc.kill()
                                raise NoSusForDlException('the downloads of all SUs in the payload have been either canceled or have timed-out')

                            time.sleep(1) # In scp process poll loop.
                            # end proc-wait loop

                        # this locks and releases the SU Table
                        sus, missingSunums = self.suTable.getSUs(sunums=sunums, filter=SuTable.removeGhosts)
                        for su in sus:
                            self.log.writeInfo([ 'ScpWorker setting SU ' + str(su.sunum) + ' status to F' ])
                            su.setStatus('F', None)
                            scpComplete = su.worker.getScpComplete()
                            with scpComplete:
                                scpComplete.notify()

                        self.log.writeInfo([ 'ScpWorker ' + str(self.id) + ' - scp command succeeded for SUs ' + ','.join([ str(asunum) for asunum in sunums ]) ])
                    except ScpSUException as exc:                        
                        # These errors should not cause the ScpWorker thread to exit. Set status to 'E'.
                        self.log.writeError([ exc.args[0] ])
                        
                        # this locks and releases the SU Table
                        sus, missingSunums = self.suTable.getSUs(sunums=sunums, filter=SuTable.removeGhosts)
                        for su in sus:
                            self.log.writeInfo([ 'ScpWorker setting SU ' + str(su.sunum) + ' status to E' ])
                            su.setStatus('E', exc.args[0])
                            scpComplete = su.worker.getScpComplete()
                            with scpComplete:
                                scpComplete.notify()
                    except NoSusForDlException as exc:
                        # the SU statuses have already been updated with a non-P status
                        self.log.writeInfo([ exc.args[0] ])
                    except ShutDownException as exc:
                        self.log.writeInfo([ exc.args[0] ])
                        # do not communicate anything back to Downloaders since they will see the shutdown event and 
                        # then check the SU status (which could be D, F, or E)
                else:
                    # There were fewer than scpBatchSize requests for an SU download. Wait for more with ScpWorker.scpNeeded.wait().
                    # Set a timeout so we can gracefully exit if the shutdown event has been triggered (just in case this thread
                    # blocks on wait - when the shutdown happens, the scpNeeded event will be triggered, however).
                
                    # It could be the case that the last Downloader has fired scpNeeded, but there still aren't enough SUs
                    # to trigger a download. If that is the case, then we must let scpNeeded time-out before we do check to see
                    # if it is time to do a download. If the scpNeeded.wait() timeout is long, then we won't check for the 
                    # ScpWorker timeout for a long time, even though the ScpWorker timeout might be short.
                    timeOutToUse = min(scpTimeOut, timedelta(seconds=10))
                
                    try:
                        ScpWorker.scpNeeded.wait(timeOutToUse.total_seconds())
                    except RuntimeError:
                        pass
        finally:
            # This thread is about to terminate. 
            # We need to check the class tList variable to update it, so we need to acquire the lock.
            try:
                ScpWorker.lock.acquire()
                ScpWorker.tList.remove(self) # This thread is no longer one of the running threads.
                self.log.writeInfo([ 'Scp Worker (ID ' +  str(self.id) + ') halted.' ])            
            finally:
                ScpWorker.lock.release()        
        
    # Called from main thread
    def stop(self):
        self.log.writeInfo([ 'Stopping ScpWorker ' + str(self.id) + ' - (it may take 10 seconds for the ScpWorker to stop).' ])
        
        # Fire event to stop thread.
        self.sdEvent.set()
        self.log.writeDebug([ 'Set sdEvent in ScpWorker ' + str(self.id) + '.' ])
        
        # Fire scpNeeded event so that the ScpWorker thread will not block on wait.
        ScpWorker.scpNeeded.set()
    
    @staticmethod
    def newThread(id, suTable, arguments, log):
        worker = ScpWorker(id, suTable, arguments, log)
        ScpWorker.tList.append(worker)
        worker.start()

class DownloaderCompleteQueueItem(object):
    def __init__(self, **kwargs):
        self.su = kwargs['su']

    @classmethod
    def addCompleteQueueItemToQueue(cls, **kwargs):
        su = kwargs['su']
        queue = kwargs['queue']
        log = kwargs['log']

        qItem = cls(su=su)
    
        # no need to hold SU Table lock since the queue implementation handles multi-thread access to the queue
        try:
            queue.put_nowait(qItem) # non-blocking
        except:
            log.writeError([ 'unable to put downloader complete item for SU ' + str(su.sunum) + ' in queue' ])
    

# Downloads a single SU. Ingests it into SUMs (SUMS allows to ingestion of a single SU at a time only.). Updates
# the SU table status for that SU.
# The main thread sets the SU status to 'P'. The Downloader thread sets that status to 'W' to request a ScpWorker
# thread to download the SU. The ScpWorker thread sets the status to 'D' while it is processing the download. When
# the download is complete, the ScpWorker thread sets the status back to 'P'.
class Downloader(threading.Thread):
    sumsConn = None
    sumsDbLock = None # Since all Downloader threads share the same connection, their cursors on these connections
                      # are not isolated. Use a lock to ensure that only one Download is modifying SUMS at one time.

    tList = [] # A list of running thread IDs.
    maxThreads = 16 # Default. Can be overriden with the Downloader.setMaxThreads() method.
    eventMaxThreads = threading.Event() # Event fired when the number of threads decreases.
    lock = threading.Lock() # guard tList

    def __init__(self, **kwargs):
        threading.Thread.__init__(self)
        self.su = kwargs['su']
        self.path = kwargs['path']
        self.suTable = kwargs['sutable']
        self.scpUser = kwargs['scpuser'] # the linux user that has access to the SU
        self.scpHost = kwargs['scphost'] # the machine hosting the SU
        self.scpPort = kwargs['scpport'] # the port on the machine hosting the SU
        self.binPath = kwargs['binpath']
        self.hastapesys = kwargs['hastapesys']
        self.tmpdir = kwargs['tmpdir']
        self.log = kwargs['log']
        self.sunum = self.su.sunum
        self.sdEvent = threading.Event()
        self.scpCompleteLock = threading.RLock()
        self.scpComplete = threading.Condition(self.scpCompleteLock)

    def run(self):
        # Sub-out the download to an ScpWorker instance. To do that, set the SU status to 'W'. The ScpWorker
        # that is used will set the status to 'D' so that no other ScpWorker attempt to download the SU 
        # as well. When the ScpWorker completes the download, it will set the status to 'P' again.        
        suDlPath = None
        sudir = None
        
        setErrorStatus = False
        cleanUpSUDir = False
        
        retentionCached = None
        seriesCached = None
        
        try:        
            # the finally clause will remove this thread from tList; that must happen, else we could 
            # hang on shut-down
            try:
                suStatus = None

                # this SU cannot have been removed from the SU Table at this point; that can only happen
                # after this thread sets the SU status to C or E; so, there is no chance that the SU has been orphaned and
                # there is no need to check for that
                retentionCached = self.su.getRetention()
                seriesCached = self.su.getSeries()
                
                self.log.writeInfo([ 'Downloader is running for SU ' + str(self.sunum) ])

                if self.su.getStatus() != 'P':
                    raise DownloaderException('SU ' + str(self.sunum) + ' is not pending')
            
                suDlPath = os.path.join(self.tmpdir, 'D' + str(self.sunum))

                scpDlNotified = False
                
                if self.sdEvent.isSet():
                    raise ShutDownException('downloader thread for SU ' + str(self.sunum) + ' is observing the global shutdown and exiting now')

                with self.scpComplete:
                    # Let an ScpWorker thread handle the download. We do that by setting the status to 'W'.
                    # Upon recovery from a daemon shutdown, we may start certain SUs in the W state, in which
                    # case we do not need to set the status to W.
                    self.log.writeInfo([ 'setting SU ' + str(self.sunum) + " status to W" ])

                    # the ScpWorker learns of the source path, the SU size, the scp user, etc., from su.worker
                    self.su.setStatus('W', None)

                    # wake up an ScpWorker
                    ScpWorker.scpNeeded.set()
                    # clear event so that main will block the next time it calls wait
                    ScpWorker.scpNeeded.clear()

                    # wait for the ScpWorker thread to finish downloading the SU; timeout if we have been waiting too long;
                    # the ScpWorker thread itself will check for a download timeout and notify() the Downloader if that happens;
                    # we know a download time happens if the status is D and there was no shut down event (which we just checked above);
                    # no need to check for shutdown event here since the ScpWorker thread will respond to one, killing pending
                    # downloads and notify()ing waiting Downloader threads so that wait() will return
                    if not self.scpComplete.wait(timeout=self.suTable.getTimeout().seconds + 120):
                        self.log.writeWarning([ 'downloader for SU ' + str(self.sunum) + ' timed-out' ])
                        raise DownloaderException('the download of SU ' + str(self.sunum) + ' timed-out')                            
                    else:
                        # download complete (ScpWorker can no longer modify SU obj)
                        pass

                # the download has completed (it is in self.tmpdir), or it has errored-out, or a shut-down is being observed
            
                # if a shut-down is being observed, then the SU status must be W (waiting for scp thread) or F (scp download finished) or 
                # E (error); if there is no shut-down happening, then the status must be F or E.
                suStatus = self.su.getStatus()
                if self.sdEvent.isSet():
                    # normally, we'd raise, but we may have already finished the download; if so, we can ingest into SUMS quickly
                    # before terminating
                    self.log.writeInfo([ 'shutdown happening while downloading SU ' + str(self.sunum) ])
                    # if status == 'F', then go ahead and save the SU in SUMS; below, set status to C; this SU was successfully downloaded
                    # if status == 'E', the download failed, and if status == 'W', then we pretend the download never started (although
                    # it could have started, but got canceled by the shutdown)
                    if suStatus == 'F':
                        self.log.writeInfo([ 'shutdown occurred after ScpWorker successfully downloaded SU ' + str(self.sunum) ])
                    elif suStatus == 'D':
                        # the shutdown event happened while a scp was in progress
                        self.log.writeInfo([ 'shutdown called while download of SU ' + str(self.sunum) + ' was in progress' ])
                        raise ShutDownException('downloader thread for SU ' + str(self.sunum) + ' is observing the global shutdown and exiting now')
                    elif suStatus == 'W':
                        self.log.writeInfo([ 'shutdown called before ScpWorker could download SU ' + str(self.sunum) ])
                        raise ShutDownException('downloader thread for SU ' + str(self.sunum) + ' is observing the global shutdown and exiting now')
                    elif suStatus == 'E':
                        raise DownloaderException('the download of SU ' + str(self.sunum) + ' errored-out')
                    else:
                        # unexpected status
                        raise DownloaderException('unexpected status ' + suStatus + ' for the download of SU ' + str(self.sunum))
                else:
                    # the ScpWorker finished processing the SU download, and that was not due to a shutdown event
                    if suStatus == 'F':
                        self.log.writeInfo([ 'ScpWorker successfully downloaded SU ' + str(self.sunum) ])
                    elif suStatus == 'D':
                        # a download timeout occurred
                        self.log.writeInfo([ 'shutdown called while download of SU ' + str(self.sunum) + ' was in progress' ])
                        raise DownloaderException('the download of SU ' + str(self.sunum) + ' timed-out')
                    elif suStatus == 'E':
                        raise DownloaderException('the download of SU ' + str(self.sunum) + ' errored-out')
                    else:
                        # unexpected status
                        raise DownloaderException('unexpected status ' + suStatus + ' for the download of SU ' + str(self.sunum))

                # At this point, we need to allocate (mkdir) a new SU directory, move the downloaded SU content into this SUDIR, 
                # then commit the newly created SU into SUMS. The previous incarnations of remote-sums-type code all used the SUMS
                # API to achieve the first and last steps. To use the SUMS API, code need to be written in C and it needs to link
                # to the SUMS library. The first remote-sums code did this by running a DRMS module, wherein all three steps were
                # performed. The JMD uses vso_sum_alloc (a DRMS module with access to the SUMS API) to allocate the SU directory, 
                # then it copies the downloaded SU content into the directory, and then it calls vso_sum_put to commit the SU.
                # However, at a high rate of download, the SUMS API seems to have problems, resulting in the vso_sum_alloc and/or
                # vso_sum_put calls to hang for minutes. We have not been able to track down this issue, but it appears to have
                # something to do with either saturation of socket resources and/or RPC resources and/or SUMS queues.
            
                # This script by-passes SUMS altogether to avoid the issues with SUMS and/or DRMS modules hanging under higher load.
                # The first step in by-passing SUMS is to perform the equivalent of the SUM_open() API call. Then we can call the
                # equivalent of the SUM_alloc2() call to allocate a new SU directory, followed by the copying of the download SU
                # content into this new SU directory. Then we can call the equivalent of the SUM_put() API call to commit the 
                # SU, and then we can call the equivalent of the SUM_close() API call to end the SUMS session.
            
                # We need to connect to the SUMS database before we can modify SUMS objects.
                # The DB transaction is NOT in autocommit mode.
                #
                # Do not put a lock around these operations. It takes about 5 to 8 seconds to complete these SUMS DB 
                # operations. If every thread has to acquire and hold this lock for 5 to 8 seconds, throughput will
                # suffer. 
                #
                # And there is no reason to lock these operations. Each Downloader thread
                # operates on a unique set of rows in the SUMS DB tables being modified. The original
                # SUMS maintained a single connection to the SUMS DB. In response to each API function call,
                # SUMS would manipulate the SUMS DB and then it would commit the change. Since each
                # SUMS client makes multiple SUMS API function calls during its run, and SUMS responds to each
                # request as it arrives in its 'inbox', without any regard to sorting by client,
                # the DB manipulations made by clients are interleaved. Therefore, there is no need
                # for one Downloader thread to perform all DB manipulations without interruption from
                # other Downloader threads.
                #
                # The various cursors held by different Downloaders are not isolated (they operate within the same transaction
                # across all Downloader threads), so the following DB manipulations can be interrupted. If an error 
                # happens somewhere in this chain of events, we need to undo the manipulations performed before the
                # error occurred.
                #
                # PG and psycopg2 do not allow multiple concurrent transactions in a single connection. So, I guess
                # we have to serialize each manipulation (by putting a lock around each one).
                with self.sumsConn.cursor() as cursor:
                    allOK = False
                    openDone = False
                    alloc2Done = False
                    putDone = False
                    closeDone = False
                
                    try: 
                        # Put all of this in one transaction. If everything is good, commit the transaction. If an 
                        # exception occurs, roll back.
            
                        ##### SUM_open() port #####
                        try:
                            gotSumsDbLock = self.sumsDbLock.acquire()
                        
                            # This increments the sequence that supplies the sumid and inserts that sumid into the sum_open table.
                            cmd = "SELECT NEXTVAL('public.sum_seq')"
                            cursor.execute(cmd)
                            records = cursor.fetchall()
                            if len(records) != 1:
                                raise SumsAPIException('Unexpected response when fetching sumid from sequence.')
                
                            sumid = records[0][0]

                            currentTimeStr = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            cmd = 'INSERT INTO public.sum_open(sumid, open_date) VALUES (' + str(sumid) + ", '" + currentTimeStr + "')"
                            cursor.execute(cmd)
                            self.sumsConn.commit()
                        finally:
                            if gotSumsDbLock:
                                self.sumsDbLock.release()
                        ##### SUM_open() port - end #####
                        openDone = True
                        self.log.writeInfo([ 'Successfully called SUM_open() port for SU ' +  str(self.sunum) ])
                        self.log.writeInfo([ 'sumid is ' + str(sumid) + '.' ])
    
                        ##### SUM_alloc2() port #####
                        try:
                            gotSumsDbLock = self.sumsDbLock.acquire()

                            #   First, find a partition that has enough available space for the size of the SU to be downloaded.
                            cmd = 'SELECT PARTN_NAME FROM public.sum_partn_avail WHERE AVAIL_BYTES >= 1024 AND PDS_SET_NUM = 0'
                            cursor.execute(cmd)
                            records = cursor.fetchall()
                            if len(records) < 1:
                                raise SumsAPIException('Cannot allocate a new Storage Unit in SUMS - out of space.')
            
                            partitions = []
                            for rec in records:
                                partitions.append(rec[0])
            
                            #   Second, randomly choose one of the partitions to put the new SU into. We want to spread the write load over available 
                            #   partitions.
                            randIndex = random.randint(0, len(partitions) - 1)
                            partition = partitions[randIndex]
                            sudir = os.path.join(partition, 'D' + str(self.sunum))
                            os.mkdir(sudir)
                            os.chmod(sudir, 0O2755)

                            #   Third, insert a record into the sum_partn_alloc table for this SU. status is DARW, which is 1. effective_date is "0".
                            cmd = "INSERT INTO public.sum_partn_alloc(wd, sumid, status, bytes, effective_date, archive_substatus, group_id, safe_id, ds_index) VALUES ('" + sudir + "', '" + str(sumid) + "', 1, 1024, '0', 0, 0, 0, 0)"
                            cursor.execute(cmd)
                            self.sumsConn.commit()
                        finally:
                            if gotSumsDbLock:
                                self.sumsDbLock.release()
                        ##### SUM_alloc2() port - end #####
                        alloc2Done = True
                        self.log.writeInfo([ 'Successfully called SUM_alloc2() for SU ' +  str(self.sunum) ])
            
                        #    Fourth, move the downloaded SU files into the chosen SUMS partition. SUM_alloc2() code calls mkdir, so we cannot
                        #    move the top-level D___ directory into the SUMS partition. Instead we have to move, recursively,  all files and directories in 
                        #    the downloaded D___ directory into the SUMS D___ directory.
                        files = os.listdir(suDlPath)
                        self.log.writeInfo([ 'Moving downloaded SU content from ' + suDlPath + ' into allocated SU (' + sudir  + ').' ])

                        try:
                            for afile in files:
                                src = os.path.join(suDlPath, afile)
                                self.log.writeDebug([ 'moving ' + src + ' to ' + sudir ])
                                shutil.move(src, sudir)
                        except shutil.Error as exc: 
                            import traceback
                            self.log.writeError([ traceback.format_exc(5) ])
                            raise RSIOException('Unable to move SU file ' + afile + ' into SUdir ' + sudir + '.')

                        self.log.writeInfo([ 'Move of SU ' + str(self.sunum) + ' content succeeded.' ])
            
                        ##### SUM_put() port #####
                        try:
                            gotSumsDbLock = self.sumsDbLock.acquire()

                            # The original SUM_put() call called "chmown" to change the ownership of the
                            # files in the SU dir to the SUM_MANAGER. However, this is not necessary since rsumsd.py is run by the 
                            # SUM_MANAGER.
            
                            #   First, chmod all directories to 0755. All regular files get their user/group/other read enabled, and their
                            #   user write enabled, and their group and other write disabled.
                            for root, dirs, files in os.walk(sudir):
                                for adir in dirs:
                                    fullPath = os.path.join(root, adir)
                                    os.chmod(fullPath, 0O0755)
                                for afile in files:
                                    fullPath = os.path.join(root, afile)
                                    st = os.stat(fullPath)
                                    newMod = st.st_mode | stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH | stat.S_IWUSR & ~stat.S_IWGRP & ~stat.S_IWOTH
                                    os.chmod(fullPath, newMod)
                    
                            #   Second, update SUMS sum_main database table - Calculate SU dir number of bytes, set online status to 'Y', set archstatus to 'N', 
                            #   set offsiteack to 'N', set dsname to seriesname, set storagegroup to tapegroup, set storageset to tapegroup / 10000,
                            #   set username to getenv('USER') or nouser if no USER env, set mode to TEMP + TOUCH, set apstatus: if SUMS_TAPE_AVAILABLE ==>
                            #   DAAP (4), else DADP (2), set archsub ==> DAAEDDP (32), set effective_date to tdays in the future (with format "%04d%02d%02d%02d%02d").
                            #   Insert all of this into sum_main.
                            numBytes = os.path.getsize(sudir) + sum([ os.path.getsize(fullPath) for fullPath in [ os.path.join(root, afile) for root, dirs, files in os.walk(sudir) for afile in files ] ]) + sum([ os.path.getsize(fullPath) for fullPath in [ os.path.join(root, adir) for root, dirs, files in os.walk(sudir) for adir in dirs ] ])
                            if self.hastapesys:
                                apStatus = 4 # DAAP
                            else:
                                apStatus = 2 # DADP

                            createDate = datetime.now()
                            createDateStr = createDate.strftime('%Y-%m-%d %H:%M:%S')
                            expDate = createDate + timedelta(days=retentionCached)
                            effDate = expDate.strftime('%Y%m%d%H%M')

                            # storage_group is the tape group. It should come from the series definition, but remote sites have been using 0 for years.            
                            cmd = "INSERT INTO public.sum_main(online_loc, online_status, archive_status, offsite_ack, history_comment, owning_series, storage_group, storage_set, bytes, ds_index, create_sumid, creat_date, access_date, username) VALUES ('" + sudir + "', 'Y', 'N', 'N', '', '" + seriesCached + "', 0, 0, " + str(numBytes) + ', ' + str(self.sunum) + ', ' + str(sumid) + ", '" + createDateStr + "', '" + createDateStr + "', '" + os.getenv('USER', 'nouser') + "')"
                            cursor.execute(cmd)
            
                            self.log.writeInfo([ 'Successfully inserted record into sum_main for SU ' + str(self.sunum) + '.' ])

                            #    Third, update SUMS sum_partn_alloc table - Insert a new row into sum_partn_alloc for this SU. The SUM_alloc2() port will result in
                            #    a row in sum_partn_alloc with a ds_index of 0, which does not make sense to me. But the SUM_close() port will delete
                            #    that row. By the time this thread terminates, there will be only a single row for this SU in sum_partn_alloc. substatus is DAAEDDP (32).
                            #    But first, delete any existing DADP (delete pending) rows for this sunum if the status of the SU for the new row is DADP.
                            if apStatus == 2:
                                # We do this simply to ensure that we do not have two sum_partn_alloc records with status DADP (delete pending).
                                cmd = 'DELETE FROM public.sum_partn_alloc WHERE ds_index = ' + str(self.sunum) + ' AND STATUS = 2'
                                cursor.execute(cmd)
                                self.log.writeInfo([ 'Successfully deleted old DADP record from sum_partn_alloc for SU ' + str(self.sunum) + '.' ])
            
                            cmd = "INSERT INTO public.sum_partn_alloc(wd, sumid, status, bytes, effective_date, archive_substatus, group_id, safe_id, ds_index) VALUES ('" + sudir + "', " + str(sumid) + ', ' + str(apStatus) + ', ' + str(numBytes) + ", '" + effDate + "', 32, 0, 0, " + str(self.sunum) + ')'
                            cursor.execute(cmd)
                            self.log.writeInfo([ 'Successfully inserted record into sum_partn_alloc for SU ' + str(self.sunum) + '.' ])
                            self.sumsConn.commit()
                        finally:
                            if gotSumsDbLock:
                                self.sumsDbLock.release()
                        ##### SUM_put() port - end #####
                        putDone = True
                        self.log.writeInfo([ 'Successfully called SUM_put() for SU ' + str(self.sunum) ])
            
                        ##### SUM_close() port #####
                        try:
                            gotSumsDbLock = self.sumsDbLock.acquire()

                            # Delete sum_partn_alloc records for read-only partitions (status == 8) and read-write partitions (status == 1).
                            cmd = 'DELETE FROM public.sum_partn_alloc WHERE sumid = ' + str(sumid) + ' AND (status = 8 OR status = 1)'
                            cursor.execute(cmd)
                            self.log.writeInfo([ 'Successfully deleted read-only and read-write records from sum_partn_alloc for SU ' + str(self.sunum) + '.' ])
            
                            # Delete the temporary ds_index = 0 records created during the SUM_put() port. I still do not know why this record
                            # was created in the first place.
                            cmd = 'DELETE FROM public.sum_open WHERE sumid = ' + str(sumid)
                            cursor.execute(cmd)
                            self.sumsConn.commit()
                        finally:
                            if gotSumsDbLock:
                                self.sumsDbLock.release()

                        ##### SUM_close() port - end #####
                        closeDone = True
                        self.log.writeInfo([ 'Successfully called SUM_close() for SU ' + str(self.sunum) ])
                        self.log.writeInfo([ 'Successfully deleted temporary (ds_index == 0) records from sum_open for SU ' + str(self.sunum) + '.' ])
                    
                        allOK = True
                    except psycopg2.Error as exc:
                        # Handle database-command errors. These are all due to problems communicating with the SUMS db.
            
                        # Clean-up
                        if os.path.exists(sudir):
                            shutil.rmtree(sudir)
                        if os.path.exists(suDlPath):
                            shutil.rmtree(suDlPath)
                        raise SumsAPIException(exc.diag.message_primary + ': ' + cmd + '.') 
                    except Exception as exc:
                        # Clean-up
                        if os.path.exists(sudir):
                            shutil.rmtree(sudir)
                        if os.path.exists(suDlPath):
                            shutil.rmtree(suDlPath)
                        raise
                    finally:
                        # the cursor still exists
                        if not allOK:
                            # undo manipulations that were successfully performed; these could raise, in which
                            # case we've done the best we can; let the enclosing exception handler set the
                            # download status for this SU to error
                            if openDone:
                                cmd = 'DELETE FROM public.sum_open WHERE sumid = ' + str(sumid)
                                cursor.execute(cmd)
                            if alloc2Done:
                                cmd = "DELETE FROM public.sum_partn_alloc WHERE wd = '" + sudir + "'"
                                cursor.execute(cmd)
                            if putDone:
                                # if putDone, then alloc2Done, so the record was already deleted from sum_partn_alloc; don't
                                # do that here.
                                cmd = 'DELETE FROM public.sum_main WHERE ds_index = ' + str(self.sunum)
                                cursor.execute(cmd)
                            if closeDone:
                                # nothing to clean up if close succeeds
                                pass

                # Remove temporary directory.
                self.log.writeInfo([ 'removing empty temporary download directory ' + suDlPath ])
                try:
                    if os.path.exists(suDlPath):
                        shutil.rmtree(suDlPath)
                except OSError as exc:
                    raise RSIOException(exc.strerror)
           
                self.log.writeInfo([ 'removal of temporary directory ' + suDlPath + ' succeeded' ])
                self.log.writeDebug([ 'downloader for SU ' + str(self.sunum) + ' terminating; unsetting worker' ])
                self.su.removeWorker()
                self.log.writeInfo([ 'setting SU ' + str(self.sunum) + ' status to complete' ])
                self.su.setStatus('C', None)
            except ShutDownException as exc:
                # the status can be P, W, or D here - we should set it to E since the download never completed
                msg = [ exc.args[0] ]
                setErrorStatus = True
                cleanUpSUDir = True
            except DownloaderException as exc:
                # we have not yet set an appropriate status - this should always be E 
                msg = [ exc.args[0] ]
                setErrorStatus = True
                cleanUpSUDir = True
            except RemoteSumsException as exc:
                import traceback

                msg = [ exc.args[0], traceback.format_exc(5) ]
                setErrorStatus = True
                cleanUpSUDir = True
            except Exception as exc:
                # catch all remaining exceptions
                import traceback

                msg = [ 'Unknown exception.', traceback.format_exc(5) ]
                setErrorStatus = True
                cleanUpSUDir = True

            # if this code raises, the outer-most finally clause will execute, removing this thread from the
            # tList
            if setErrorStatus:
                # set SU status to E
                self.log.writeError([ 'setting SU ' + str(self.sunum) + ' status to E' ])
                self.log.writeError(msg)
                self.su.setStatus('E', msg[0]) # do not put traceback strings into DB (weird chars in tracebacks mess things up)

            if cleanUpSUDir:                
                # Must clean-up SU dir and the downloaded files.
                if sudir and os.path.exists(sudir):
                    shutil.rmtree(sudir)
                if suDlPath and os.path.exists(suDlPath):
                    shutil.rmtree(suDlPath)
            
            # update SU table (write-out status, error or success, to the DB)
            # this is a no-op if no SUs were actually modified
            self.log.writeDebug([ 'downloader for SU ' + str(self.sunum) + ' updating SU table with final status' ])
            self.suTable.updateDbAndCommit([ self.sunum ])
        finally:
            # this thread is about to terminate

            # no need to acquire the SU Table lock since the status is accessed by exactly one thread at a time
            DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=self.su, queue=self.suTable.queue, log=self.log)
            self.log.writeDebug([ 'downloader (' + str(self.sunum) + ') successfully added a DownloaderCompleteQueueItem' ])

            # We need to check the class tList variable to update it, so we need to acquire the lock.
            try:
                self.lock.acquire()

                self.log.writeDebug([ 'downloader for SU ' + str(self.sunum) + ' terminating; unsetting worker' ])
                self.su.removeWorker()
                
                self.tList.remove(self) # This thread is no longer one of the running threads.
                self.log.writeInfo([ 'downloader (SUNUM ' + str(self.sunum) + ') halted' ])
                # Use <= because we don't know if we were able to reach Downloader.maxThreads thread running due 
                # to system-resource limitations.
                if len(self.tList) <= self.maxThreads - 1:
                    # Fire event so that main thread can add new SUs to the download queue.
                    self.log.writeDebug([ 'OK to start new download threads' ])
                    self.eventMaxThreads.set()
                    # Clear event so that main will block the next time it calls wait.
                    self.eventMaxThreads.clear()
            finally:
                self.lock.release()

    def getScpComplete(self):
        return self.scpComplete

    # called from main thread only
    def stop(self):
        self.log.writeInfo([ 'Stopping Downloader (SUNUM ' + str(self.sunum) + '). It may take 10 seconds for Downloader to stop.' ])
        
        # Fire event to stop thread.
        self.sdEvent.set()

    # the Dispatcher calls newThread() and it is holding the table lock (must hold table lock so that there is no contention among 
    # the different dispatchers (which call queue.put()) and the main thread (which calls queue.get());
    # must acquire Downloader lock BEFORE calling newThread() since newThread() will append to tList (the Downloader threads will delete from tList as they complete).
    @classmethod
    def newThread(cls, **kwargs):
        dl = cls(**kwargs)
        su = kwargs['su']

        try:
            su.setWorker(dl)
            cls.tList.append(dl)
            dl.start()
        except (RuntimeError, Exception) as exc:
            # cannot start a new thread, so rollback and re-raise so the calling thread can handle the error
            if dl in cls.tList:
                cls.tList.remove(dl) # error if dl does not exist in list
            su.removeWorker() # noop if SU has no worker

            if isinstance(exc, RuntimeError):
                raise StartThreadException('cannot start a new ' + dl.downloaderType.__name__ + ' thread due to system resource limitations')
            else:
                import traceback
                raise StartThreadException(traceback.format_exc(5))

    @classmethod
    def setMaxThreads(cls, maxThreads):
        cls.maxThreads = maxThreads


class HighPriorityDownloader(Downloader):
    '''
    there are only two priorities - a low-priority downloader (class Downloader), and a high-priority downloader (class HighPriorityDownloader);
    the two types of downloaders really have their own set of downloader threads; 
    '''
    tList = [] # a list of running thread IDs
    maxThreads = 16
    eventMaxThreads = threading.Event() # Event fired when the number of threads decreases.
    lock = threading.Lock() # Guard tList.
    
    def __init__(self, **kwargs):
        super(HighPriorityDownloader, self).__init__(**kwargs)
            
def readTables(sus, requests, sites):
    if sus:
        sus.tryRead()

    if requests:
        requests.tryRead()
    
    if sites:
        sites.tryRead()
        
# series (text) - name of the series whose retention 
# request (ReqTable::reqDict[requestidStr] object) - Contains the dbhost, dbport, dbname that identifies the
#    database that contains the series.

def getRetention(series, dbuser, dbname, dbhost, dbport, log):
    # et the retention from the db; we have the host/port/dbname information from the request
    newSuRetention = -1
    ns, tab = series.split('.')

    try:
        # We need to get information from the DRMS database, which might not be the same database as the remote SUMS database.
        # The class variable ReqTable.rsConn is the connection to the remote SUMS database.
        with psycopg2.connect(user=dbuser, database=dbname, host=dbhost, port=dbport) as conn:
            with conn.cursor() as cursor:
                # We want the new-SU retention too, not the staging retention. So extract the bottom 15 bits.
                cmd = "SELECT retention & x'00007FFF'::int AS retention FROM " + ns + ".drms_series WHERE seriesname ILIKE '" + series + "'"
                log.writeInfo(['Obtaining new-SU retention for series ' + series + ': ' + cmd])

                try:
                    cursor.execute(cmd)
                    if cursor.rowcount == 0:
                        raise GetRetentionException('series ' + series + ' does not exist')
                    newSuRetention = cursor.fetchone()[0]
                    log.writeInfo([ 'retention for series ' + series + ' is ' + str(newSuRetention) ])
                except psycopg2.Error as exc:
                    # Handle database-command errors.
                    raise GetRetentionException(exc.diag.message_primary)
        # The connection is read-only, so there is not need to commit a transaction.
    except psycopg2.DatabaseError as exc:
        # Closes the cursor and connection

        # Man, there is no way to get an error message from any exception object that will provide any information why
        # the connection failed.
        msg = 'unable to connect to the database (no, I do not know why)'
        raise GetRetentionException(msg)

    return newSuRetention

class DispatcherQueueItem(object):
    def __init__(self, **kwargs):
        # cgi - the cgi-supath URL (e.g., http://jsoc.stanford.edu/cgi-bin) from which SU paths can be obtained.
        # sunums - a list of sorted SUNUMs to download.
        # sutable - the SU table object that represents the SU database table.
        # dbuser - the DB user that rsumsd.py connects as
        # request - ReqTable::dict[requestidStr] object.
        # binPath - the local path to the binaries needed to ingest the downloaded SU into SUMS. This is mostly likely the path to
        #           the DRMS binaries (one binary needed is vso_sum_alloc)
        # hastapesys - does the DRMS have a tape system
        # tmpdir - the directory to which SUs are temporarily downloaded
        # log - the log to write messages to.
        self.cgi = kwargs['cgi']
        self.sunums = kwargs['sunums']
        self.sutable = kwargs['sutable']
        self.dbuser = kwargs['dbuser']
        request = kwargs['request']
        if request:
            self.requestID = request['requestid']
            self.reqtype = request['type']
            self.dbname = request['dbname']
            self.dbhost = request['dbhost']
            self.dbport = request['dbport']
        self.binpath = kwargs['binpath']
        self.hastapesys = kwargs['hastapesys']
        self.tmpdir = kwargs['tmpdir']
        if 'lastitem' in kwargs:
            self.lastitem = kwargs['lastitem']
        else:
            self.lastitem = False
        self.log = kwargs['log']

class Dispatcher(threading.Thread):
    '''
    starts a Downloader for each SU in the sunums list; the SUs all originate from one site
    '''
    tList = [] # a list of running thread IDs
    reqTypeMap = {}
    lock = threading.Lock() # guard tList
    
    def __init__(self, **kwargs):
        threading.Thread.__init__(self, target=self.processRequest)
        self.name = kwargs['name']
        self.log = kwargs['log']
        self.downloaderType = kwargs['downloaderType']
        self.queue = Queue(16) # non-blocking, one per Dispatcher instance

    def processRequest(self):
        try:
            queueItem = None
            while True:
                errorOut = False

                try:
                    # pop a DispatcherQueueItem from the queue (time-out after 2 seconds - if a timeout occurs, then the queue was empty )              
                    queueItem = self.queue.get(timeout=2)
                except Empty:                
                    # check for stop event
                    continue
                    
                if queueItem.lastitem:
                    # shutdown
                    self.queue.task_done()
                    break

                requestID = queueItem.requestID

                # process the SUs for the source site represented by its url
                workingSus = {}

                try:
                    sus, missingSunums = queueItem.sutable.getSUs(releaseTableLock=False, sunums=queueItem.sunums, filter=SuTable.removeGhosts)
                    try:
                        # because the main thread cannot check to see if an SU is in the dispatch queue AND insert into 
                        # the dispatch queue atomically, it may put the same SU into different dispatch queue items; 
                        # however, we do not want to start more than one Downloader for an SU; instead, increase the
                        # refcount if we detect this condition; the first SU dispatched will get a Downloader, but the second one
                        # will not
                        if len(sus) > 0:
                            # attempt to reprocess an SU whose processing has already started
                            self.log.writeInfo([ 'incrementing refcount for ' + ','.join([ str(su.sunum) for su in sus ]) ])
                            list(map((lambda su : su.incrementRefcount()), sus))
                            for su in sus:
                                self.log.writeDebug([ '[ processRequest() ]adding SU ' + str(su.sunum) + ' to suMap' ])
                                queueItem.sutable.addRequestToSUMap(sunum, requestID)

                        for sunum in missingSunums:
                            self.log.writeInfo([ 'inserting a new SU table record for ' + str(sunum) ])
                            # create a new SU table record for this SU (the SU Table is locked); will set status to P
                            queueItem.sutable.insert(sunums=[ sunum ], lockTable=False)
                            self.log.writeDebug([ 'successfully inserted SU ' + str(sunum) ])
                            sus, missingSunums = queueItem.sutable.getSUs(lockTable=False, releaseTableLock=False, sunums=[ sunum ], filter=SuTable.removeGhosts)
                            workingSus[str(sunum)] = sus[0]
                            # set the worker to indicate that a Downloader should exist; at this point, it does not, but the
                            # call to Downloader.newThread() will set it; the main thread will catch the error that
                            # we added an SU to the SU Table, but no Downloader was ever created
                            self.log.writeDebug([ '[ processRequest() ]adding SU ' + str(sus[0].sunum) + ' to suMap' ])
                            queueItem.sutable.addRequestToSUMap(sunum, requestID)
                    finally:
                        # no longer need SU table lock
                        queueItem.sutable.releaseLock()
                        
                    # save the newly added SU
                    queueItem.sutable.updateDbAndCommit()
                    sunumLst = ','.join(list(workingSus.keys()))
                    values = { 'requestid' : 'none', 'sunums' : sunumLst, 'N' : 1 }
                    data = urllib.parse.urlencode(values)
                    url = queueItem.cgi + '?' + data

                    natt = 0
                    while True:
                        try:
                            self.log.writeInfo([ 'requesting paths for SUNUMs ' + sunumLst + '; URL is ' + url ])
                            with urllib.request.urlopen(url) as response:    
                                dlInfoStr = response.read().decode('UTF-8')
                                natt = 0
                                break
                        except urllib.error.URLError as exc:
                            # we want to try again, until we time-out
                            natt += 1
                            if natt > 10:
                                raise SUPathCGIException('unable to access URL ' + url + '; skipping')
                            if type(exc.response) is str:
                                msg = exc.response
                            else:
                                msg = ''
                            self.log.writeWarning([ 'unable to obtain SU info from provider (' + msg + '); trying again' ])
                            time.sleep(1)

                    dlInfo = json.loads(dlInfoStr)
    
                    if dlInfo['status'] == 'complete':
                        # All of the requested SUs are online at the providing site.
                        paths = dlInfo['paths']

                        # Start a download for each SU. If we cannot start the download for any reason, then set the SU status to 'E'.
                        retentions = {}
                        for (sunum, path, series, suSize) in paths:
                            skip = False

                            try:
                                su = workingSus[str(sunum)]
                            except KeyError:
                                self.log.writeWarning([ 'SUNUM ' + str(sunum) + ' returned by SU-path CGI is not recognized; skipping ' ])
                                # no need to acquire the SU Table lock since the status is accessed by exactly one thread at a time
                                DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=su, queue=queueItem.sutable.queue, log=self.log)
                                self.log.writeDebug([ 'successfully added a DownloaderCompleteQueueItem for SU ' +  str(sunum)])
                                skip = True

                            if not skip:
                                if path is None:
                                    # A path of None means that the SUNUM was invalid. We want to set the SU status to 'E'.
                                    msg = 'SU ' + str(sunum) + ' is not valid at the providing site'
                                    su.setStatus('E', msg)
                                    self.log.writeWarning([ msg ])
                                    skip = True
                                elif path == '':
                                    # An empty-string path means that the SUNUM was valid, but that the SU referred to was offline (it may or
                                    # may be archived). Regardless, RS will not attempt to perform an export request to obtain the path.
                                    # ART - I need to figure out how to place the SUNUM in SUMS so that its archive flag is N (not archived).
                                    msg = 'SU ' + str(sunum) + ' refers to an SU that is valid at the providing site, but it is offline and cannot be downloaded'
                                    su.setStatus('C', msg)
                                    self.log.writeWarning([ msg ])
                                    skip = True

                            if not skip:
                                if suSize is None:
                                    suSize = 0

                                if series in retentions:
                                    retention = retentions[series]
                                else:
                                    # request provides the host, port, and dbname to use with jsoc_info to fetch the retention value
                                    try:
                                        retention = getRetention(series, queueItem.dbuser, queueItem.dbname, queueItem.dbhost, queueItem.dbport, self.log) 
                                        retentions[series] = retention
                                    except GetRetentionException:
                                        su.setStatus('E', 'unable to get retention for SU ' + str(sunum))
                                        # no need to acquire the SU Table lock since the status is accessed by exactly one thread at a time
                                        skip = True

                            if skip:
                                # must put a DownloaderCompleteQueueItem in SU Table queue since a Downloader will not be started
                                # for this SU
                                # no need to acquire the SU Table lock since the status is accessed by exactly one thread at a time
                                DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=su, queue=queueItem.sutable.queue, log=self.log)
                                self.log.writeDebug([ 'successfully added a DownloaderCompleteQueueItem for SU ' +  str(sunum)])
                                continue

                            # save series and retention
                            su.setSeries(series)
                            su.setRetention(retention)
                            su.setSize(suSize)
                    
                            # either HighPriorityDownloader or Downloader
                            # cls = dict(zip(REQTYPE_TEXT, [ globals()[dcls] for dcls in REQTYPE_DOWNLOADER ]))[request.reqtype]

                            # ok to stop the Dispatcher here - it can't really do anything if there are no Downloaders available; 
                            # and if the main thread adds new requests, they will go into the Dispatcher queue
                            # if we are saturated with downloads, wait here while the Downloader threads complete;
                            # if Remote SUMS is shutting down, then we'll break out of the enclosing loops
                            # ok to hold SU lock too - the only other threads trying to obtain the SU lock are the Scp Workers, and they
                            # do not block on the lock (if they cannot acquire lock immediately, they skip the SU)
                            while True:
                                self.downloaderType.lock.acquire()
                                try:                                    
                                    if len(self.downloaderType.tList) < self.downloaderType.maxThreads:
                                        self.log.writeInfo([ 'instantiating a ' + self.downloaderType.__name__ + ' for SU ' + str(su.sunum) ])

                                        # assign new worker to su
                                        self.downloaderType.newThread(su=su, path=path, sutable=queueItem.sutable, scpuser=dlInfo['scpUser'], scphost=dlInfo['scpHost'], scpport=dlInfo['scpPort'], binpath=queueItem.binpath, hastapesys=queueItem.hastapesys, tmpdir=queueItem.tmpdir, log=self.log)
                                        break
                                except StartThreadException as exc:
                                    self.log.writeError([ exc.args[0] ])
                                    # ran out of system resources - could not start new thread. Just wait for a thread slot to become free

                                    # do not remove su-->request map item since we need that info in the main thread to properly
                                    # update the request's complete attribute                                    
                                finally:
                                    self.downloaderType.lock.release()

                                self.log.writeDebug([ 'Dispatcher thread waiting for thread slot for SU ' + str(su.sunum) ])
                                self.downloaderType.eventMaxThreads.wait()
                                # we woke up, but we do not know if there are any open threads in the thread pool; loop and check
                                # tList again

                        # end loop over SUs
                        
                        # for each SU that was requested, but for which no path was given in the response, update its SU-table record with an error status.
                        pathInResp = set([ sunum for (sunum, path, series, suSize) in paths ])
        
                        for sunumStr, su in workingSus.items():
                            if su.sunum not in pathInResp:
                                su.setStatus('E', 'providing site cannot provide a path for SU ' + str(su.sunum))
                    elif dlInfo['status'] == 'pending':
                        # one or more of the requested SUs is offline; this can no longer happen (rs.sh is called
                        # with the N=1 argument now)!! Do not perform an export request!; there are a limited number ofexport-request 
                        # slots (at the JSOC); since a request for an offline SU entails an asynchronous tape read, performing these requests, 
                        # making a request for a large number of SUs could saturate the export system for days;
                        # log an error if we get here.
                        self.log.writeInfo([ 'request includes one or more SUs that are offline at the providing site; an export request was started to put them online' ])
                        for sunumStr, su in workingSus.items():
                            su.setStatus('E', 'an export request was started - this is no longer allowed')
                    else:
                        # Error of some kind.
                        # Update the SU-table status of the SUs to 'E'.
                        for sunumStr, su in workingSus.items():
                            su.setStatus('E', 'unable to obtain paths from providing site; ' + dlInfo['statusMsg'])
                except RemoteSumsException as exc:
                    # there was a problem with this queue item; the finally statement will call task_done(), and then we go on to the
                    # next queue item
                    self.log.writeWarning([ exc.msg ])
                    errorOut = True
                except ValueError: # it would be better to use JSONDecodeError, but that is not available till Py 3.5
                    self.log.writeWarning([ 'not properly formatted JSON in response to ' + url ])
                    errorOut = True
                # all other exceptions are fatal and should raise, terminating the dispatcher thread
                finally:
                    if errorOut:
                        for sunumStr, su in workingSus.items():
                            su.setStatus('E', 'SU ' + str(su.sunum) + ': setting status to E')
                        
                    self.queue.task_done()
            # end of while loop; thread is terminating
        finally:        
            if queueItem is not None and queueItem.sutable is not None:
                queueItem.sutable.updateDbAndCommit()
        
            # this thread is about to terminate; we need to check the class tList variable to update it, so we need to acquire the lock
            Dispatcher.lock.acquire()
            try:
                Dispatcher.tList.remove(self) # this thread is no longer one of the running threads.
                self.log.writeInfo([ 'Dispatcher ' + self.name + ' halted' ])            
            finally:
                Dispatcher.lock.release()

    @classmethod
    def getDispatcher(cls, reqtype):
        dispType = dict(zip(REQTYPE_TEXT, [ globals()[dcls] for dcls in REQTYPE_DOWNLOADER ]))[reqtype]
        return cls.reqTypeMap[dispType.__name__]

    # called from the main thread only
    @classmethod
    def addSUChunk(cls, **kwargs):
        reqtable = kwargs['reqtable']
        log = kwargs['log']
        item = DispatcherQueueItem(**kwargs)
        
        dispatcher = cls.getDispatcher(item.reqtype)

        try:
            # add to the queue - the call will NOT block if queue is full; this allows caller to try again later
            dispatcher.queue.put_nowait(item)

            # update the request's todispatch list (the main thread is the only one to modify request items - no need for locking)
            request = reqtable.get([ item.requestID ])[0]
            request['todispatch'] = [ sunum for sunum in request['todispatch'] if sunum not in item.sunums ]
            log.writeDebug([ 'request ' + str(request['requestid']) + ' (obj ' + str(id(request)) + ')' + ' now has these un-dispatched SUs: ' + ','.join([ str(sunum) for sunum in request['todispatch'] ]) ])
        except Full:
            raise QueueFullException('cannot add Request to Dispatcher queue - it is full')            

    @classmethod
    def new(cls, **kwargs):
        if kwargs['downloaderType'].__name__ in cls.reqTypeMap:
            raise DuplicateDispatcherType('Dispatcher type ' + kwargs['reqType'].__name__ + ' already exists')
    
        dispatcher = cls(**kwargs)
        cls.reqTypeMap[dispatcher.downloaderType.__name__] = dispatcher
        cls.tList.append(dispatcher)

        try:
            dispatcher.start()
        except RuntimeError:
            # cannot start a new thread, so rollback and re-raise so the calling thread can handle the error
            cls.tList.remove(dispatcher)

            raise StartThreadException('cannot start a new Dispatcher thread due to system resource limitations')
        
        return dispatcher


class LogLevelAction(argparse.Action):
    def __call__(self, parser, namespace, value, option_string=None):
        valueLower = value.lower()
        if valueLower == 'critical':
            level = logging.CRITICAL
        elif valueLower == 'error':
            level = logging.ERROR
        elif valueLower == 'warning':
            level = logging.WARNING
        elif valueLower == 'info':
            level = logging.INFO
        elif valueLower == 'debug':
            level = logging.DEBUG
        else:
            level = logging.ERROR

        setattr(namespace, self.dest, level)


def updateDbAndCommit(log, rsConn, rsDbLock, reqTable, suTable, reqIDs, sunums):
    # lock the SU table, the SUs, and access to the DB until the SU table SQL has been run so that nothing changes out from under us;
    # no need to lock anything having to do with the requests table - it is accessed by a single thread only
    # we acquire the DB Lock so that our transaction cannot get polluted - we do not want another thread committing the
    # transaction (all cursors share the same transaction)
    
    suSql = suTable.getUpdateDBSql(sunums)
    rqSql = reqTable.getUpdateDBSql(reqIDs)
    
    rsDbLock.acquire() # do not allow other threads to commit the DB changes in the middle of this
    try:
        # neither of these calls commits changes to the DB
        log.writeDebug([ 'updating the DB with SU table changes (SUs ' + ','.join([ str(sunum) for sunum in sunums ]) + ')' ])
        suTable.updateDB(suSql)
        log.writeDebug([ 'updating the DB with request table changes (request ' + ','.join(str(reqID) for reqID in reqIDs) + ')' ])
        reqTable.updateDB(rqSql)
        
        log.writeDebug([ 'committing Req-table and SU-table changes to DB' ])
        rsConn.commit()
        log.writeDebug([ 'successfully committed Req and SU changes' ])
    except:
        import traceback
        
        log.writeWarning([ 'failed to commit Req and SU changes; changed rolled back' ])
        log.writeWarning([ traceback.format_exc(5) ])
        rsConn.rollback() # it could be that the first call succeeds and the second fails - we need to rollback the first too
        # continue on with the next request (do not terminate)
    finally:
        rsDbLock.release()
        
def getSUSites(sunums, sites, request, log):
    '''
    input:
      sunums - a list of SU integers
      sites - the sites table (DRMS sites that provide SUs)
      request - the request dictionary for a specific request
      log - rsumsd output log
    
    returns a 2-tuple:
      first element - a dictionary where they key is a source site CGI, and the value is a list of SUs that the site serves
      second element - a list of currently online SUs
    '''
    siteSUs = {}
    onlineSUs = []

    offlineSUs = SuTable.offline(sunums, log)

    for sunum in sunums:
        if sunum in offlineSUs:
            log.writeInfo([ 'SU ' + str(sunum) + ' is offline - will start a download' ])
        else:
            log.writeInfo([ 'SU ' + str(sunum) + ' is online already - will NOT start a download.' ])
            onlineSUs.append(sunum)

    for sunum in offlineSUs:
        try:
            siteCGI = sites.getSuPathCGI(sunum)
        except UnknownSitecodeException as exc:                        
            # Skip this request - invalid SU.
            msg = 'uknown site code for SU ' + str(sunum) + '; skipping SU for request ' + str(request['requestid'])
            log.writeWarning([ msg ])
            continue

        if siteCGI not in siteSUs:
            siteSUs[siteCGI] = []

        siteSUs[siteCGI].append(sunum)
        
    return (siteSUs, onlineSUs)

# called from the main thread only
def dispatchSUs(sunums, sites, request, sutable, reqtable, dbuser, binpath, tapesysexists, tmpdir, log):
    # siteSunums is a dictionary where key is the site CGI, and the value is a list of unknown, offline SUs that
    # the site serves;
    # toComplete is a list of undispatched, but online remote SUs    
    siteSunums, onlineSunums = getSUSites(sunums, sites, request, log)

    for cgi, sunumList in siteSunums.items():
        if len(sunumList) > 0:
            # Chunk is a list of SUNUMs (up to 64 of them).
            sunumList.sort()
            chunker = Chunker(sunumList, 64)
            for chunk in chunker:
                try:
                    # will NOT block if there are no spots in the Dispatcher queue
                    Dispatcher.addSUChunk(cgi=cgi, sunums=chunk, reqtable=reqtable, sutable=sutable, dbuser=dbuser, request=request, binpath=binpath, hastapesys=tapesysexists, tmpdir=tmpdir, log=log)
                    log.writeInfo([ 'added an item to the dispatcher queue for SU chunk: ' + ','.join([ str(ansunum) for ansunum in chunk ]) ])
                except QueueFullException as exc:
                    # non-blocking put failed (because queue was full);
                    # none of the SUs in this chunk will appear in the SU Table (and they will not have Downloaders);
                    # the todispatch list mechanism will ensure these SUs get dispatched during the check on pending request
                    log.writeInfo([ 'dispatcher queue full; for request' + str(request['requestid']) + ', unable to add SU chunk: ' + ','.join([ str(ansunum) for ansunum in chunk ]) ])
                except RemoteSumsException as exc:
                    # do not die - just reject the request's current chunk; we do not know exactly which SUs made it into the
                    # SU Table, but at least one either did not or it did, but with status E; the request will eventually 
                    # error-out when the other SUs complete (successfully or not)
                    if type(exc.response) is str:
                        log.writeWarning([ exc.response ])
                    log.writeWarning([ 'failed to process SUs ' + ','.join([ str(sunum) for sunum in chunk ]), 'skipping this chunk' ])
                except Exception:
                    import traceback

                    msg = traceback.format_exc(5)
                    log.writeWarning([ msg ])
                    log.writeWarning([ 'failed to process SUs ' + ','.join([ str(sunum) for sunum in chunk ]), 'skipping this chunk' ])
                    
    return onlineSunums


if __name__ == "__main__":
    rv = RET_SUCCESS

    try:
        sumsDrmsParams = SumsDrmsParams()

        parser = CmdlParser(usage='%(prog)s [ -h ] [ sutable=<storage unit table> ] [ reqtable=<request table> ] [ --dbname=<db name> ] [ --dbhost=<db host> ] [ --dbport=<db port> ] [ --binpath=<executable path> ] [ --logfile=<base log-file name> ]')
    
        # Optional parameters - no default argument is provided, so the default is None, which will trigger the use of what exists in the configuration file
        # (which is drmsparams.py).
        parser.add_argument('r', '--reqtable', help='The database table that contains records of the SU-request being processed. If provided, overrides default specified in configuration file.', metavar='<request unit table>', dest='reqtable', default=sumsDrmsParams.get('RS_REQUEST_TABLE'))
        parser.add_argument('s', '--sutable', help='The database table that contains records of the storage units being processed. If provided, overrides default specified in configuration file.', metavar='<storage unit table>', dest='sutable', default=sumsDrmsParams.get('RS_SU_TABLE'))
        parser.add_argument('n', '--nworkers', help='The number of scp worker threads.', metavar='<number of worker threads>', dest='nWorkers', type=int, default=sumsDrmsParams.get('RS_N_WORKERS'))
        parser.add_argument('t', '--tmpdir', help='The temporary directory to use for scp downloads.', metavar='<temporary directory>', dest='tmpdir', default=sumsDrmsParams.get('RS_TMPDIR'))
        parser.add_argument('-N', '--dbname', help='The name of the database that contains the series table from which records are to be deleted.', metavar='<db name>', dest='dbname', default=sumsDrmsParams.get('RS_DBNAME'))
        parser.add_argument('-U', '--dbuser', help='The name of the database user account.', metavar='<db user>', dest='dbuser', default=sumsDrmsParams.get('RS_DBUSER'))
        parser.add_argument('-H', '--dbhost', help='The host machine of the database that contains the series table from which records are to be deleted.', metavar='<db host machine>', dest='dbhost', default=sumsDrmsParams.get('RS_DBHOST'))
        parser.add_argument('-P', '--dbport', help='The port on the host machine that is accepting connections for the database that contains the series table from which records are to be deleted.', metavar='<db host port>', dest='dbport', default=int(sumsDrmsParams.get('RS_DBPORT')))
        parser.add_argument('-b', '--binpath', help='The path to executables run by this daemon (e.g., vso_sum_alloc, vso_sum_put).', metavar='<executable path>', dest='binpath', default=sumsDrmsParams.get('RS_BINPATH'))
        parser.add_argument('-l', '--loglevel', help='Specifies the amount of logging to perform. In order of increasing verbosity: critical, error, warning, info, debug', dest='loglevel', action=LogLevelAction, default=logging.ERROR)
                
        arguments = Arguments(parser)
        
        arguments.setArg('lockfile', sumsDrmsParams.get('RS_LOCKFILE'))
        arguments.setArg('dltimeout', timedelta(seconds=int(sumsDrmsParams.get('RS_DLTIMEOUT'))))
        arguments.setArg('reqtimeout', timedelta(seconds=int(sumsDrmsParams.get('RS_REQTIMEOUT'))))
        arguments.setArg('maxthreads', int(sumsDrmsParams.get('RS_MAXTHREADS')))
        arguments.setArg('scpMaxNumSUs', int(sumsDrmsParams.get('RS_SCP_MAXSUS')))
        arguments.setArg('scpMaxPayload', 1024 * 1024 * int(sumsDrmsParams.get('RS_SCP_MAXPAYLOAD')))
        arguments.setArg('scpTimeOut', timedelta(seconds=int(sumsDrmsParams.get('RS_SCP_TIMEOUT'))))
        arguments.setArg('rsSiteInfoURL', sumsDrmsParams.get('RS_SITE_INFO_URL'))
        arguments.setArg('logdir', sumsDrmsParams.get('RS_LOGDIR'))
        
        arguments.setArg('sumsdbname', sumsDrmsParams.get('DBNAME') + '_sums')
        arguments.setArg('sumsdbuser', sumsDrmsParams.get('SUMS_MANAGER'))
        arguments.setArg('sumsdbhost', sumsDrmsParams.get('SUMS_DB_HOST'))
        arguments.setArg('sumsdbport', int(sumsDrmsParams.get('SUMPGPORT')))
        
        arguments.setArg('tapesysexists', int(sumsDrmsParams.get('SUMS_TAPE_AVAILABLE')) == 1)
        
        pid = os.getpid()

        # Create/Initialize the log file.
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
        rslog = Log(os.path.join(sumsDrmsParams.get('RS_LOGDIR'), LOG_FILE_BASE_NAME + '_' + datetime.now().strftime('%Y%m%d') + '.txt'), arguments.loglevel, formatter)
        rslog.writeCritical([ 'Starting up remote-SUMS daemon.' ])
        rslog.writeCritical([ 'Logging threshold level is ' + rslog.getLevel() + '.' ]) # Critical - always write the log level to the log.
        arguments.dump(rslog)
        
        rslog.writeInfo([ 'Setting download timeout to ' + str(arguments.dltimeout) + ' (the daemon must complete the download within this interval).' ])
        rslog.writeInfo([ 'Setting request timeout to ' + str(arguments.reqtimeout) + ' (the daemon must locate the request within this interval).' ])
        rslog.writeInfo([ 'Setting scp timeout to ' + str(arguments.scpTimeOut) + ' (each ScpWorker waits this long at most before initiating the next scp.).' ])

        thContainer = [ arguments, str(pid), rslog ]
        
        # TerminationHandler opens a DB connection to the RS database (which is the same as the DRMS database, most likely).
        with TerminationHandler(thContainer) as th:
            rsConn = th.rsConn()
            sumsConn = th.sumsConn()

            rsDbLock = threading.RLock() # global
            sumsDbLock = threading.Lock() # global
            
            rslog.writeInfo([ 'Obtained script file lock.' ])

            suTable = arguments.sutable
            reqTable = arguments.reqtable

            suTableObj = None
            reqTableObj = None
            sites = None

            # Read the storage-unit and request tables. Do this only once per daemon run. However, we save this table
            # information every iteration of the daemon loop, just in case a crash happens. After a crash, when
            # the daemon starts up, it will retrieve the latest saved information so the disruption will be minimal.
            # We will have to clean up any pending downloads since the threads managing those downloads will have
            # been lost, and we cannot trust that the downloads completed successfully (although they might have).
            # A fancier implementation would be some kind of download manager that can recover partially downloaded
            # storage units, but who has the time :)

            SuTable.rsConn = rsConn # Class variable
            SuTable.sumsConn = sumsConn # Class variable
            SuTable.rsDbLock = rsDbLock # Class variable
            SuTable.sumsDbLock = sumsDbLock # Class variable
            suTableObj = SuTable(suTable, arguments.dltimeout, rslog)

            ReqTable.rsConn = rsConn # Class variable
            ReqTable.rsDbLock = rsDbLock # Class variable
            reqTableObj = ReqTable(reqTable, arguments.reqtimeout, rslog)
            
            Downloader.sumsConn = sumsConn
            Downloader.sumsDbLock = sumsDbLock # Class variable

            sites = SiteTable(arguments.rsSiteInfoURL, rslog)

            # This function will try to read each table 10 times before giving up (and raising an exception).
            readTables(suTableObj, reqTableObj, sites)

            # Set max number of threads we can process at once.
            Downloader.setMaxThreads(arguments.maxthreads)
            
            ###########################
            # START SCPWORKER THREADS #
            ###########################
            
            # make N threads that handle scp commands; each of the worker threads will use one of these threads to perform
            # the actual scp command; MUST do this here, before 'P' Downloader threads have been
            # started. The ScpWorker threads need the parent Downloader threads to exist before it can process 'W' SUs, but if there
            # are more than maxThreads 'P' SUs, then the Dispatcher code will block until threads free up, and that cannot happen
            # if the ScpWorker threads are not running
            for nthread in range(1, arguments.nWorkers + 1):
                ScpWorker.lock.acquire()
                try:
                    if len(ScpWorker.tList) < ScpWorker.maxThreads:
                        rslog.writeInfo([ 'Instantiating ScpWorker ' + str(nthread) + '.' ])
                        ScpWorker.newThread(nthread, suTableObj, arguments, rslog)
                    else:
                        break # The finally clause will ensure the ScpWorker lock is released.
                finally:
                    ScpWorker.lock.release()
                    
            Dispatcher.lock.acquire()
            try:                                    
                rslog.writeInfo([ 'instantiating the downloader Dispatcher' ])
                dispatcher = Dispatcher.new(name='downloader-dispatcher', downloaderType=Downloader, log=rslog)
                rslog.writeInfo([ 'downloader Dispatcher is running' ])
            
                rslog.writeInfo([ 'instantiating the high-priority download Dispatcher' ])
                highPriorityDispatcher = Dispatcher.new(name='high-priority-downloader-dispatcher', downloaderType=HighPriorityDownloader, log=rslog)
                rslog.writeInfo([ 'high-priority download Dispatcher is running' ])
            except StartThreadException as exc:
                raise StartThreadException('cannot start Dispatcher')
            finally:
                Dispatcher.lock.release()

            ################################
            # RESTART INTERRUPTED REQUESTS #
            ################################

            # we must have already started ScpWorker threads, otherwise the Dispatcher will block if we try to process too
            # many SUs in the following block of code - we'll use up all Downloader threads, and since there are no 
            # ScpWorker threads perform downloads, the Downloader pool will not get restored, and the whole
            # system will block on the Downloader.eventMaxThreads.wait() call
            th.disableInterrupts()
            try:
                # when disabling interrupts, add an exception handler with a finally clause so that we re-enable
                # interrupts when an exception happens (so we can terminate remote sums)
            
                reqsPending = reqTableObj.getPending()
                rslog.writeInfo([ 'there are ' + str(len(reqsPending)) + ' pending requests on start-up'])
                              
                # remove ALL SUs from the SU Table; as we iterate through the pending requests, we will dispatch
                # the request's SUs to Downloaders (which will insert the SUs into the SU Table with a status of P)
                # if an SU exists in the SU Table and it is not part of a pending request, then it is orphaned and
                # should also be deleted; getSUs() locks and releases the SU Table lock
                sus, missingSunums = suTableObj.getSUs(releaseTableLock=False, sunums=None, filter=None)
                try:
                    if sus and len(sus) > 0:
                        rslog.writeInfo([ 'deleting SUs (via decrementRefcount()) from previous run of Remote SUMS: ' + ','.join([ str(su.sunum) for su in sus ]) ])
                        for su in sus:
                            # the existing SUs should all have refcount 1 (since we are starting up Remote SUMS);
                            # so, basically delete all SUs from the sutable
                            su.decrementRefcount()
                finally:
                    suTableObj.releaseLock()
            
                # gotta commit changes to the DB, else we'll get a duplicate SU exception when we attempt to initiate
                # the download of the SUs again
                suTableObj.updateDbAndCommit()
            
                # request is a dictionary
                sunumsSetToComplete = set()
                for request in reqsPending:
                    # use a set() to remove duplicates IN THE SAME REQUEST
                    sunums = list(set(request['todispatch'])) # the SUs that have not been dispatched yet
                    rslog.writeInfo([ 'found an interrupted download request, id ' + str(request['requestid']) + ', for SUNUMs ' + ','.join([str(sunum) for sunum in sunums]) ])
                
                    # returns the set of sunums that were are online already
                    sunumsToSetToComplete = set(dispatchSUs(sunums, sites, request, suTableObj, reqTableObj, arguments.dbuser, arguments.binpath, arguments.tapesysexists, arguments.tmpdir, rslog))
                
                    # insert a new SU record for all unknown SUs that are already online; these calls modify the sus object;
                    # in this case, there was no SU inserted into the SU Table, but at least one request contained the SU; 
                    # if a pending request contains an SU that cannot be found (i.e., it is not in the SU Table), the 
                    # request will error-out; to avoid this, we need to insert the SU in the SU Table; an SU that is online 
                    # is essentially an SU that has downloaded successfully, so as we insert the SU into the SU Table, we 
                    # need to mark the SU complete
                
                    # we want to insert a new SU object if the SU object does not already exist; otherwise, we want to
                    # increment the refcount on the SU object; set the SU statuses to C
                    suTableObj.newSUs(sunums=list(sunumsToSetToComplete))
                    suTableObj.setStatus(list(sunumsToSetToComplete - sunumsSetToComplete), 'C')

                    sus, missingSunums = suTableObj.getSUs(releaseTableLock=False, sunums=list(sunumsToSetToComplete - sunumsSetToComplete), filter=SuTable.removeGhosts)
                    try:
                        for su in sus:
                            # we have to put these sus into the sumap; normally the dispatcher thread does this, but since
                            # these sus were already online, they never got dispatched
                            rslog.writeDebug([ 'adding SU ' + str(su.sunum) + ' to suMap' ])
                            suTableObj.addRequestToSUMap(su.sunum, request['requestid'])
                            
                            # we also have to add a complete queue item in the SU Table queue; normally the Downloader 
                            # thread does this, but a Downloader was not started for these online SUs
                            DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=su, queue=suTableObj.queue, log=rslog)
                            rslog.writeDebug([ 'successfully added a DownloaderCompleteQueueItem for SU ' +  str(su.sunum)])
                    finally:
                        suTableObj.releaseLock()
                
                    # the request object is accessed by the main thread only - no lock needed
                    request['todispatch'] = list(set(request['todispatch']) - sunumsToSetToComplete)
                    
                    sunumsSetToComplete = sunumsSetToComplete | sunumsToSetToComplete

                    # At this point, both the requests table and SU table have been modified, but have not been flushed to disk.
                    # Flush them, but do this inside a transaction so that the first does not happen without the second.
                    updateDbAndCommit(rslog, rsConn, rsDbLock, reqTableObj, suTableObj, [ request['requestid'] ], sunums)
            except:
                raise
            finally:    
                th.enableInterrupts()
            # END RESTART REQUESTS #

            #############
            # MAIN LOOP #
            #############
            ilogger = IntervalLogger(rslog, timedelta(seconds=5))
            # sleep for at least one second between iterations
            while True:
                # For each 'P' request in the request table, check to see if the requested downloads have completed yet.
                
                ############################
                # PROCESS PENDING REQUESTS #
                ############################
                th.disableInterrupts()
                try:
                    # when disabling interrupts, add an exception handler with a finally clause so that we re-enable
                    # interrupts when an exception happens (so we can terminate remote sums)
                    
                    # use a queue so we do not have to worry about SU contention - the only threads that can modify the
                    # SU statuses are the Downloaders and ScpWorkers
                    for inum in range(1, 32):
                        # process at most 32 pending SUs - but don't process until queue is empty since the number of SUs
                        # in the queue could be large

                        # pop a DownloaderCompleteItem from the queue (time-out after 0.5 seconds - if a timeout occurs, then the queue was empty);
                        # the existence of the item implies that the Downloader thread has exited, removing the possibility of thread
                        # contention for this SU;
                        # must acquire Downloader lock since there are several actions that must occur atomically on the put() side of the code
                        completeItem = None
                        try:
                            suTableObj.acquireLock()
                            try:
                                completeItem = suTableObj.queue.get(timeout=0.5)
                                rslog.writeDebug([ 'processing download-complete item for SU ' + str(completeItem.su.sunum)  ])
                            except Empty:
                                # no DownloaderCompleteItem item available; move on to processing new requests
                                break
                            except:
                                raise
                            finally:
                                suTableObj.releaseLock()

                            # check SU download status 
                            # an SU object is created in the Dispatcher thread; read/writes happen in either the Downloader and ScpWorker 
                            # thread (but there is no contention between these two threads); there is no thread contention possible
                            # for the SU contents
                            if completeItem.su.status == 'E':
                                rslog.writeInfo([ 'download of SU ' + str(completeItem.su.sunum)  + ' has errored-out; ' + completeItem.su.errmsg ])
                            elif completeItem.su.status == 'C':
                                rslog.writeInfo([ 'Download of SU ' + str(completeItem.su.sunum)  + ' has completed.' ])
                            elif completeItem.su.status == 'P' or completeItem.su.status == 'W' or completeItem.su.status == 'D':
                                # the Downloader no longer exists, so this is an error
                                completeItem.su.setStatus('E', 'download for SU ' + str(completeItem.su.sunum) + ' did not properly complete')
                            else:
                                # unknown status; set status to 'E'
                                completeItem.su.setStatus('E', 'SU ' + str(completeItem.su.sunum) + ' has an unknown status of ' + completeItem.su.status + '.')

                            # find all requests that refer to this SU with the SU's map to all its requests    
                            for requestID in suTableObj.suMap[str(completeItem.su.sunum)]:
                                # add this SU to the request['complete'] list
                                
                                # we cannot cache the actual request dict because we refresh the set of requests near
                                # the end of the main loop; so we cache the requestID, and then we have to hash into 
                                # the request dict to get the current request dict for that requestID                                
                                request = reqTableObj.get([ requestID ])[0]
                                if completeItem.su.sunum not in request['complete']:
                                    request['complete'].append(completeItem.su.sunum)
                                    rslog.writeDebug([ 'added ' + str(completeItem.su.sunum) + ' to complete list for request ' + str(request['requestid']) ])
                        finally:
                            if completeItem:
                                suTableObj.queue.task_done()

                    # the Downloaders check for orphaned SUs (SUs without workers - no progress can be made) - no 
                    # need to do that here; but we need to check for missing Downloaders
                    reqsPending = reqTableObj.getPending()
                    # check to see if any request has been completely processed
                    sunumsSetToComplete = set()
                    for request in reqsPending:
                        rslog.writeDebug([ 'request sunums: ' + ','.join([ str(sunum) for sunum in request['sunums'] ]) ])
                        rslog.writeDebug([ 'complete SUs: ' + ','.join([ str(sunum) for sunum in request['complete'] ]) ])
                        if len(set(request['sunums']).symmetric_difference(request['complete'])) == 0:
                            # request has completed
                            reqError = False
                        
                            sunums = list(set(request['sunums']))
                            sus, missingSunums = suTableObj.getSUs(releaseTableLock=False, sunums=sunums, filter=SuTable.removeGhosts)
                            try:                       
                                for su in sus:
                                    if su.status == 'E':
                                        reqError = True
                                        break   
                            finally:
                                suTableObj.releaseLock()
                        
                            # this request is done; set this request's status to 'C' or 'E', and decrement the refcount on each SU
                            if reqError:
                                rslog.writeInfo([ 'request number ' + str(request['requestid']) + ' for SUNUM(s) ' + ','.join([ str(sunum) for sunum in sunums ]) + ' errored-out' ])
                                reqTableObj.setStatus([ request['requestid'] ], 'E', errMsg)
                            else:
                                rslog.writeInfo([ 'request number ' + str(request['requestid']) + ' for SUNUM(s) ' + ','.join([ str(sunum) for sunum in sunums ]) + ' completed successfully' ])
                                reqTableObj.setStatus([ request['requestid'] ], 'C')
                            
                            # remove sunum-->request map items
                            suTableObj.acquireLock()
                            try:
                                for su in sus:
                                    suTableObj.removeRequestFromSUMap(su, request['requestid'])
                            finally:
                                suTableObj.releaseLock()
                        
                            # ART - Do not hold rsDbLock here! The functions called may acquire other locks, leading to deadlock.
                            # The rsDbLock should be for executing SQL only.
                            rslog.writeDebug([ 'decrementing refcount for SUs: ' + ','.join([ str(sunum) for sunum in sunums ]) ])
                            # Remove duplicates from list first. We do not need to preserve the order of the SUNUMs
                            # before calling decrementRefcount() since that function uses a hash lookup on the SUNUM
                            # to find the associated refcount. Does not modify SU db table.
                            suTableObj.decrementRefcount(sunums)

                            # commit status changes to the requests and su table (decrementRefcount modified SUs)
                            updateDbAndCommit(rslog, rsConn, rsDbLock, reqTableObj, suTableObj, [ request['requestid'] ], sunums)
                        else:
                            # check to see if any request has undispatched SUs
                            if len(request['todispatch']) > 0:
                                # a Dispatcher asynchronously inserts rows into the SU Table, and it may block waiting for a Downloader;
                                # it may be that for this request, some of the SUs do not appear in the SU Table yet, or if they do, 
                                # they might be lacking a Downloader;
                    
                                # not in SU Table; one of two things is possible:
                                # 1. they are in the Dispatcher queue (not yet being processed by the Dispatcher thread)
                                # 2. the attempt to insert them into the Dispatcher queue failed because the queue was full
                                # if #1 is the case, we do nothing; if #2 is the case, then we need to re-try inserting them 
                                # into the Dispatcher queue - use request to determine which queue to use; since all the SUs in 
                                # missingSunums belong to one request, we can use the todispatch list method to determine
                                # which SUs to put into the dispatch queue
                                sunums = list(set(request['todispatch']) ) # the SUs that have not been dispatched yet        
                                rslog.writeDebug([ 'request ' + str(request['requestid']) + ' (obj ' + str(id(request)) + ')' + ' has un-dispatched SUs: ' + ','.join([ str(sunum) for sunum in sunums ]) ])
                                sunumsToSetToComplete = set(dispatchSUs(sunums, sites, request, suTableObj, reqTableObj, arguments.dbuser, arguments.binpath, arguments.tapesysexists, arguments.tmpdir, rslog))

                                suTableObj.newSUs(sunums=list(sunumsSetToComplete))
                                suTableObj.setStatus(list(sunumsToSetToComplete - sunumsSetToComplete), 'C')

                                sus, missingSunums = suTableObj.getSUs(releaseTableLock=False, sunums=list(sunumsToSetToComplete - sunumsSetToComplete), filter=SuTable.removeGhosts)
                                try:
                                    for su in sus:
                                        # we have to put these sus into the sumap; normally the dispatcher thread does this, but since
                                        # these sus were already online, they never got dispatched
                                        rslog.writeDebug([ 'adding SU ' + str(su.sunum) + ' to suMap' ])
                                        suTableObj.addRequestToSUMap(su.sunum, request['requestid'])
                            
                                        # we also have to add a complete queue item in the SU Table queue; normally the Downloader 
                                        # thread does this, but a Downloader was not started for these online SUs
                                        DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=su, queue=suTableObj.queue, log=rslog)
                                        rslog.writeDebug([ 'successfully added a DownloaderCompleteQueueItem for SU ' +  str(su.sunum)])

                                finally:
                                    suTableObj.releaseLock()

                                request['todispatch'] = list(set(request['todispatch']) - sunumsToSetToComplete)

                                sunumsSetToComplete = sunumsSetToComplete | sunumsToSetToComplete

                                # At this point, both the requests table and SU table have been modified, but have not been flushed to disk.
                                # Flush them, but do this inside a transaction so that the first does not happen without the second.
                                updateDbAndCommit(rslog, rsConn, rsDbLock, reqTableObj, suTableObj, [ request['requestid'] ], list(sunumsToSetToComplete - sunumsSetToComplete))
                            else:
                                # not all SU have been processed, but at the same time all have been dispatched; if the worker attribute
                                # (Downloader) of the SU is not None, then we started a Downloader for this SU; if that Downloader died,
                                # then we need to set the SU status to E

                                # there is the error case where an SU has been dispatched, but no Downloader was ever created (a queue
                                # item was added, but for some reason, the dispatcher never created a Downloader);
                                # sunums are the pending SUs (all SUs have been dispatched)
                                sunums = list(set(request['todispatch']))
                                sus, missingSunums = suTableObj.getSUs(releaseTableLock=False, sunums=sunums, filter=SuTable.removeGhosts)
                                try:
                                    # the sus are in the SU Table, so they should have a Downloader (it is possible that an SU has been dispatched
                                    # but has not yet been assigned a Downloader because the Dispatcher thread has yet to read its queue item)                                    
                                    dispatcher = Dispatcher.getDispatcher(request['type'])

                                    for su in sus:
                                        # we lock the Downloader lock whenever we set/unset the worker in the su object
                                        dispatcher.downloaderType.lock.acquire()
                                        try:
                                            if hasattr(su, 'worker') and su.worker is not None:
                                                # a downloader thread has definitely been started; it should be alive
                                                if not isinstance(su.worker, (Downloader)) or not su.worker.isAlive():
                                                    # set SU status to E
                                                    su.setStatus('E', 'download for SU ' + str(su.sunum) + ' lost its Downloader unexpectedly')
                                        
                                                    # put a complete item in the queue so that the main thread will handle this in the 
                                                    # pending requests section (do no further SU-completion processing here)
                                                    DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=su, queue=suTableObj.queue, log=rslog)
                                                    rslog.writeDebug([ 'successfully added a DownloaderCompleteQueueItem for SU ' +  str(su.sunum)])
                                            
                                        finally:
                                            downloaderType.lock.release()
                                            
                                finally:
                                    suTableObj.releaseLock()
                except:
                    # pass this to the enclosing handler
                    raise
                finally:
                    th.enableInterrupts()
                # For each 'N' request in the request table, start a new set of downloads (if there is no download currently running -
                # i.e., no SU record) or increment the refcounts on the downloads (if there are downloads currently running - i.e.,
                # an SU record exists). But Before starting a new download, make sure that requested SU is not already online.
                # Due to race conditions, a request could have caused a download to occur needed by another request whose state is 'N'.
                
                # END PENDING REQUESTS #

                ########################
                # PROCESS NEW REQUESTS #
                ########################
                th.disableInterrupts()
                try:
                    # when disabling interrupts, add an exception handler with a finally clause so that we re-enable
                    # interrupts when an exception happens (so we can terminate remote sums)
                            
                    reqTableObj.refresh() # Clients may have added requests to the queue.
                    reqsNew = reqTableObj.getNew()

                    # reqsNew contains requests sorted by (priority, start-time)
                    # request is a dictionary
                    sunumsSetToComplete = set()
                    for request in reqsNew:
                        timeNow = datetime.now(request['starttime'].tzinfo)
                        if timeNow > request['starttime'] + reqTableObj.getTimeout():
                            ilogger.writeInfo([ 'Request number ' + str(request['requestid']) + ' timed-out.' ])
                            reqTableObj.setStatus([ request['requestid'] ], 'E', 'Request timed-out.')
                        
                            try:
                                reqTableObj.updateDbAndCommit([ request['requestid'] ])
                            except:
                                import traceback
                            
                                ilogger.writeWarning([ traceback.format_exc(5) ])
                                # swallow the exception and continue with the next request
                                pass
                            continue
                    
                        # use a set() to remove duplicates IN THE SAME REQUEST
                        sunums = list(set(request['todispatch'])) # the SUs that have not been dispatched yet
                        rslog.writeInfo([ 'found a new download request, id ' + str(request['requestid']) + ', for SUNUMs ' + ','.join([ str(sunum) for sunum in sunums ]) ])
                    
                        sunumsToSetToComplete = set(dispatchSUs(sunums, sites, request, suTableObj, reqTableObj, arguments.dbuser, arguments.binpath, arguments.tapesysexists, arguments.tmpdir, rslog))

                        # REGARDLESS IF ANY SUS WERE INSERTED INTO THE SU TABLE (if none got inserted, then no downloads will happen), 
                        # a request was initiated; if any Downloader thread fails, or if at least one was never started, then
                        # the request will fail. So, execution always gets this far, and we should add to the SU table any SUs
                        # that were not 
                    
                        # insert a new SU record for all unknown SUs that are already online; these calls modify the sus object;
                        # in this case, there was no SU inserted into the SU Table, but at least one request contained the SU; 
                        # if a pending request contains an SU that cannot be found (i.e., it is not in the SU Table), the 
                        # request will error-out; to avoid this, we need to insert the SU in the SU Table; an SU that is online 
                        # is essentially an SU that has downloaded successfully, so as we insert the SU into the SU Table, we 
                        # need to mark the SU complete
                        # suTableObj.insert(sunums=list(sunumsToSetToComplete - sunumsSetToComplete))
                    
                        # if we already created an SU obj for this SU, this will increment refcount
                        suTableObj.newSUs(sunums=list(sunumsToSetToComplete))
                        suTableObj.setStatus(list(sunumsToSetToComplete - sunumsSetToComplete), 'C')
                    
                        sus, missingSunums = suTableObj.getSUs(releaseTableLock=False, sunums=list(sunumsToSetToComplete - sunumsSetToComplete), filter=SuTable.removeGhosts)
                        try:
                            for su in sus:
                                # we have to put these sus into the sumap; normally the dispatcher thread does this, but since
                                # these sus were already online, they never got dispatched
                                rslog.writeDebug([ 'adding SU ' + str(su.sunum) + ' to suMap' ])
                                suTableObj.addRequestToSUMap(su.sunum, request['requestid'])

                                DownloaderCompleteQueueItem.addCompleteQueueItemToQueue(su=su, queue=suTableObj.queue, log=rslog)
                                rslog.writeDebug([ 'successfully added a DownloaderCompleteQueueItem for SU ' +  str(su.sunum)])
                        finally:
                            suTableObj.releaseLock()
                        
                        # the request object is accessed by the main thread only - no lock needed
                        request['todispatch'] = list(set(request['todispatch']) - sunumsToSetToComplete)
                        
                        sunumsSetToComplete = sunumsSetToComplete | sunumsToSetToComplete
                    
                        # the new request has been fully processed; change its status from 'N' to 'P';
                        # this call modifies the requests object and it acquires each SU's lock
                        reqTableObj.setStatus([ request['requestid'] ], 'P')

                        # At this point, both the requests table and SU table have been modified, but have not been flushed to disk.
                        # Flush them, but do this inside a transaction so that the first does not happen without the second.
                        updateDbAndCommit(rslog, rsConn, rsDbLock, reqTableObj, suTableObj, [ request['requestid'] ], sunums)
                except:
                    raise
                finally:                    
                    th.enableInterrupts()
                # END PROCESS NEW REQUESTS #

                # Delete all request-table records whose state is 'D'. It doesn't matter if this operation gets interrupted. If
                # that happens, then these delete-pending records will be deleted the next time this code runs uninterrupted.
                # CLIENTS DO NOT APPEAR TO SET REQ STATUS TO D - THIS IS A NO-OP
                reqsToDelete = reqTableObj.getDelete()
                reqTableObj.deleteDB(reqsToDelete)
               
                # Must poll for new requests to appear in requests table.
                time.sleep(1)
                # End of main loop.
            
            # Save the db state when exiting.
            rslog.writeInfo([ 'Remote-sums daemon is exiting. Saving database tables.' ])
            updateDbAndCommit(rslog, rsConn, rsDbLock, reqTableObj, suTableObj, None, None)

        # DB connection was terminated.            
        # Lock was released     
    except TerminationException as exc:
        msg = exc.args[0]
        if rslog:
            rslog.writeInfo([ msg ]) 
    except RemoteSumsException as exc:
        msg = exc.args[0]
        if rslog:
            rslog.writeError([ msg ])
            
        rv = exc.retcode
    except:
        import traceback
        
        msg = traceback.format_exc(5)
        if rslog:
            rslog.writeError([ msg ])
        else:
            print(msg, file=sys.stderr)
        rv = RET_UNKNOWN_ERROR

if rslog:
    rslog.writeInfo([ 'Exiting with return status ' + str(rv) + '.' ])
# Will not exit process if threads are still running. Set global shutdown flag that threads are monitoring. When they see the flag, they
# will terminate too.

logging.shutdown()
sys.exit(rv)
