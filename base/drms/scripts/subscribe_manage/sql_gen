#!/bin/bash
export LD_LIBRARY_PATH=/usr/local/pgsql/lib
pidfile=$0.pid
config_file=../etc/subscription_manager.cfg

. $config_file

#--------------------------------------------------------------------
# sql_gen
# Syntax: ./sql_gen <node> <new subscription, true/false> <subscription information file>
#--------------------------------------------------------------------

#-------------------------------------------------------------------------
# syntax check
#-------------------------------------------------------------------------
if [ $# -eq 6 ]
then
	node=$1
	new_site=$2
	archive=$3
	retention=$4
	tapegroup=$5
	input_file=$6
else
        error="ERROR: Usage: $0 <node> <new subscription, true/false> <subscription information file>"
        echo $error
	exit
fi
logfile=../log/$0.$node.log

#--------------------------------------------------------------------
# Setting up the log
#--------------------------------------------------------------------
echo > $logfile
logwrite () {
        echo `date +"%m-%d-%Y %H:%M:%S - "` "$1" >> $logfile
        if [ ! $2 == "" ]
        then
                echo `date +"%m-%d-%Y %H:%M:%S - "` >> $logfile
        fi
}

logwrite "Starting $0 $1" nl


#------------------------------------------------------------------------
# Checks to see if the schema and tables exist on the webdb
#-------------------------------------------------------------------------
failure=0
logwrite "Setting failure to 0"

# Check to see if the schema "admin" and the table "admin.ns" exist
# check=`psql -p $pg_port -h $pg_host -U $pg_user -c '\dt admin.*' $pg_dbname| grep admin.ns`	
	
#if [ "$check" == "" ]
#then
#	logwrite "Checking for drms_series in $pg_schema failed!" nl
#	failure=1
#	logwrite "Setting failure to 1"
#fi
#unset check

# remove all unsubscribe requests from input_file
cat $input_file | grep -v "unsubscribe" > new_input_file.txt
mv -f new_input_file.txt $input_file

exec < $input_file
	while read line
	do
		# skips blank lines
                if [ ${#line} -eq 0 ]
                then
                	continue
                fi

		set - $line

		#echo "line is [$line]" #remove
		oldIFS="$IFS"
		IFS="${IFS}."
		set - $1
		#echo "[$1] [$2] [$3]" #remove
		pg_schema=$1
		#echo "Schema is $pg_schema" #remove
		echo
		IFS="$oldIFS"
		logwrite "pg_schema is [$pg_schema]"
		logwrite "Executing [psql -p $pg_port -h $pg_host -U $pg_user -c '\dt '$pg_schema'.*' $pg_dbname| grep drms_series]"
		check=`psql -p $pg_port -h $pg_host -U $pg_user -c '\dt '$pg_schema'.*' $pg_dbname| grep drms_series`	
		logwrite "Result is [$check]" nl

		if [ "$check" == "" ]
		then
			logwrite "Checking for drms_series in $pg_schema failed!" nl
			failure=1
			logwrite "Setting failure to 1"
		fi

		unset check
		unset schema
	done

logwrite "Current failure status is [$failure]" nl
if [ $failure -ne 0 ]
then
	# there was a failure, report failure, cleanup and exit
	logwrite "Failure detected!"
	logwrite "Failure process: Removing $node.subscribe_series.subupdate"
	rm -f $node.subscribe_series.subupdate
	logwrite "Failure process: Removing $triggerdir/$node.subscribe_series.cfg"
	rm -f $triggerdir/$node.subscribe_series.cfg
	logwrite "Failure process: removing $subscribers_dir/$node.new" 
	rm -rf $subscribers_dir/$node.new
	logwrite "Failure process: removing $tables_dir/$node.new" 
	rm -f $tables_dir/$node.new.lst
	logwrite "Failure process: removing new entry from $parser_config"
	cat $parser_config | grep -v "$node.new.lst" > $parser_config.new
	mv -f $parser_config.new $parser_config
	logwrite "Failure process: Writing [failure] to $triggerdir/$node.subscribe_series.sqldone" 
	echo "failure" > $triggerdir/$node.subscribe_series.sqldone
	exit
fi

#-------------------------------------------------------------------------
# Reads input file into a few arrays
# Array: schema_table includes <schema>.<name> (for use with createtabstrut script)
# Array: schema includes the <schema> (for use with createns script)
# Array: table includes the <table> (for use with the slony1_dump script)
# All arrays will match eachother via the counter number
#-------------------------------------------------------------------------
counter=0
exec < $input_file
	while read line
	do
		# skips blank lines
                if [ ${#line} -eq 0 ]
                then
                	continue
                fi

		set - $line
		
		sub=$2		
		schema_table[$counter]=$1
		oldIFS="$IFS"
		IFS="${IFS}."
		set - ${schema_table[$counter]}

		schema[$counter]=$1
		table[$counter]=$2

		IFS="$oldIFS"
                counter=$(( $counter + 1 ))
		unset sub
	done

#-------------------------------------------------------------------------
# Checks if there are any new subscriptions, if not, then skip createns, createtabstructure, and sdo_slony1_dump
#-------------------------------------------------------------------------
subcheck=`cat $input_file | grep -v "unsubscribe"`
if [ "$subcheck" == "" ]
then
	logwrite "No new subscriptions, skipping createns, createtabstructure and sdo_slony1_dump" nl
	logwrite "Creating dummy sql files"
	echo > $triggerdir/$node.createns.sql
	echo > $triggerdir/$node.subscribe_series.sql
else

#-------------------------------------------------------------------------
# Execute createns for each schema
#-------------------------------------------------------------------------
counter=0
echo > $triggerdir/$node.createns.sql
while [ "$counter" -lt ${#schema[@]} ]
do
	nextcounter=$(( $counter + 1 ))
	check=`echo "${schema[@]:0:$counter}" | grep ${schema[$counter]}`
	
	if [ "$check" == "" ]
	then
		# If first time finding this schema, execute ./createns
		logwrite "Executing [./createns ns=${schema[$counter]} nsgroup=user dbusr=$pg_user >> $triggerdir/$node.createns.sql]"
		#echo "Createns >>" #remove
		./createns ns=${schema[$counter]} nsgroup=user dbusr=$pg_user >> $triggerdir/$node.createns.sql
		#echo "<<Createns" #remove
		# echo ${schema[$counter]} >> $triggerdir/$node.createns.sql
	fi
	counter=$(( $counter + 1 ))
done

#-------------------------------------------------------------------------
# Execute createtabstruct and slony1_dump
#-------------------------------------------------------------------------
counter=0
echo "BEGIN;" > $triggerdir/$node.subscribe_series.sql
logwrite "Schema_table array is [${schema_table[@]}] and has [${#schema_table[@]}] elements"
while [ "$counter" -lt ${#schema_table[@]} ]
do
	nextcounter=$(( $counter + 1 ))
	check=`echo "${schema_table[@]:0:$counter}" | grep ${schema_table[$counter]}`
	
	if [ "$check" == "" ]
	then
		# If first time finding this schema_table, execute ./createtabstruct
		logwrite "Executing [./createtabstructure in=${schema_table[$counter]} out=${schema_table[$counter]} archive=$archive retention=$retention tapegroup=$tapegroup owner=slony >> $triggerdir/$node.subscribe_series.sql]"
		#echo "Createtabstructure >>" #remove
		./createtabstructure in=${schema_table[$counter]} out=${schema_table[$counter]} archive=$archive retention=$retention tapegroup=$tapegroup owner=slony >> $triggerdir/$node.subscribe_series.sql
		#echo "<< Createtabstructure" #remove
		#echo ${schema_table[$counter]} >> $triggerdir/$node.subscribe_series.sql
	fi
	counter=$(( $counter + 1 ))
done

# Set $new_site to binary boolean
if [ $new_site == "true" ]
then
	new_site_bool=1
else
	new_site_bool=0
fi

# Execute sdo_slony1_dump.sh
logwrite "Executing: [./sdo_slony1_dump.sh $pg_dbname jsoc $pg_port $new_site_bool ${table[@]}]"
#echo "sdo_slony1_dump.sh >>" #remove
./sdo_slony1_dump.sh $pg_dbname jsoc $pg_port $new_site_bool ${table[@]} >> $triggerdir/$node.subscribe_series.sql 2> /dev/null
#echo "<< sdo_slony1_dump.sh" #remove
#echo ${table[@]} >> $triggerdir/$node.subscribe_series.sql

echo "COMMIT;" >> $triggerdir/$node.subscribe_series.sql

#-------------------------------------------------------------------------
# End of check for new subscriptions
#-------------------------------------------------------------------------
fi

#-------------------------------------------------------------------------
# Tar up the sql files then remove them
#-------------------------------------------------------------------------
logwrite "Executing: tar -C $triggerdir/ -czvf $triggerdir/$node.sql.tar.gz $node.createns.sql $node.subscribe_series.sql" nl
tar -C $triggerdir/ -czvf $node.sql.tar.gz $node.createns.sql $node.subscribe_series.sql
logwrite "Removing $node.createns.sql and $node.subscribe_series.sql"
rm -f $triggerdir/$node.createns.sql $triggerdir/$node.subscribe_series.sql

#-------------------------------------------------------------------------
# Renaming the subupdate file to sqldone file in trigger directory for subscriber to find
#-------------------------------------------------------------------------
logwrite "Renaming sqlgen file $node.subscribe_series.subupdate to $triggerdir/$node.subscribe_series.sqldone" nl

mv -f $node.subscribe_series.subupdate $triggerdir/$node.subscribe_series.sqldone

logwrite "Finished running $0"
